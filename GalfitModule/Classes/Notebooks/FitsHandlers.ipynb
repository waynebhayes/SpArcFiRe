{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c33abdbf-5f26-4ca8-b4e9-42f3a8081216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from os.path import join as pj\n",
    "from os.path import exists\n",
    "import subprocess\n",
    "from copy import deepcopy\n",
    "from IPython import get_ipython\n",
    "from astropy.io import fits\n",
    "import gc\n",
    "import psutil\n",
    "\n",
    "import numpy as np\n",
    "import scipy.linalg as slg\n",
    "from scipy.stats import norm, kstest\n",
    "from skimage.draw import disk, ellipse\n",
    "\n",
    "import imageio.v3 as iio\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "422e80ba-e349-474e-a843-75cb28e8079a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For debugging purposes\n",
    "from IPython import get_ipython\n",
    "def in_notebook():\n",
    "    ip = get_ipython()\n",
    "    \n",
    "    if ip:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc86a10-9752-46fe-8f9a-978003abaf84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_HOME_DIR = os.path.expanduser(\"~\")\n",
    "if in_notebook():\n",
    "    _SPARCFIRE_DIR = pj(_HOME_DIR, \"sparcfire_matt\") \n",
    "    _MODULE_DIR    = pj(_SPARCFIRE_DIR, \"GalfitModule\")\n",
    "else:\n",
    "    try:\n",
    "        _SPARCFIRE_DIR = os.environ[\"SPARCFIRE_HOME\"]\n",
    "        _MODULE_DIR = pj(_SPARCFIRE_DIR, \"GalfitModule\")\n",
    "    except KeyError:\n",
    "        if __name__ == \"__main__\":\n",
    "            print(\"SPARCFIRE_HOME is not set. Please run 'setup.bash' inside SpArcFiRe directory if not done so already.\")\n",
    "            print(\"Checking the current directory for GalfitModule, otherwise quitting.\")\n",
    "            \n",
    "        _MODULE_DIR = pj(os.getcwd(), \"GalfitModule\")\n",
    "        \n",
    "        if not exists(_MODULE_DIR):\n",
    "            raise Exception(\"Could not find GalfitModule!\")\n",
    "\n",
    "sys.path.append(_MODULE_DIR)\n",
    "\n",
    "#from Classes.Parameters import *\n",
    "#from Classes.Components import *\n",
    "from Classes.Containers import *\n",
    "from Functions.helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88c556ed-4bbf-4cc4-a519-a8eb6b401b08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HDU:\n",
    "    def __init__(self, \n",
    "                 name   = \"observation\",\n",
    "                 header = {}, \n",
    "                 data   = None\n",
    "                ):\n",
    "        \n",
    "        self._hdu_info = {\n",
    "            \"name\"   : name,\n",
    "            \"header\" : deepcopy(dict(header)),\n",
    "            \"data\"   : deepcopy(np.array(data))\n",
    "        }\n",
    "        \n",
    "# ==========================================================================================================\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._hdu_info.get(\"name\", \"\")\n",
    "    \n",
    "    @name.setter\n",
    "    def name(self, new_name):\n",
    "        self._hdu_info[\"name\"] = new_name\n",
    "        \n",
    "    @property\n",
    "    def header(self):\n",
    "        return self._hdu_info.get(\"header\", {})\n",
    "    \n",
    "    @header.setter\n",
    "    def header(self, new_header):\n",
    "        self._hdu_info[\"header\"] = deepcopy(dict(new_header))\n",
    "        \n",
    "    @property\n",
    "    def data(self):\n",
    "        return self._hdu_info.get(\"data\", \"\")\n",
    "    \n",
    "    @data.setter\n",
    "    def data(self, new_data):\n",
    "        self._hdu_info[\"data\"] = deepcopy(np.array(new_data))\n",
    "        \n",
    "# ==========================================================================================================\n",
    "\n",
    "    def __str__(self):\n",
    "        header_str = \"\"\n",
    "        for k,v in self.header.items():\n",
    "            header_str += f\"{k} = {v}\\n\"\n",
    "            \n",
    "        output_str = f\"{self.name}\\n{header_str}Img size: {np.shape(self.data)}\"\n",
    "        return output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7a88fd3-05d5-43ce-8d6a-f977ce1bfca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FitsFile:\n",
    "    def __init__(self,\n",
    "                 filepath,\n",
    "                 names       = [\"observation\"],\n",
    "                 from_galfit = False,\n",
    "                 wait        = False,\n",
    "                 **kwargs\n",
    "                ):\n",
    "        \n",
    "        self.filepath = filepath\n",
    "        self.all_hdu  = {}\n",
    "        \n",
    "        # Use split over rstrip in case a waveband designation is given\n",
    "        # (rstrip will remove any character that matches in the substring)\n",
    "        # i.e. 12345678910_g would lose the _g for \"_galfit_out.fits\"\n",
    "        # TODO: Replace rstrip with split in the rest of these scripts...\n",
    "        self.gname    = kwargs.get(\"gname\", os.path.basename(filepath).split(\"_galfit_out.fits\")[0])\n",
    "        \n",
    "        assert os.path.splitext(filepath)[-1].lower() == \".fits\", \"File being passed into FitsHandler must be .fits!\"\n",
    "        \n",
    "        try:\n",
    "            file_in = fits.open(filepath)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Can't open to read the file, {filepath}. Check name/permissions/directory.\")\n",
    "            raise(Exception()) \n",
    "\n",
    "        except OSError as ose:\n",
    "            print(f\"Something went wrong! {ose}\")\n",
    "            raise(Exception())\n",
    "            \n",
    "        # FITS starts the index at 0 but GALFIT outputs the observation image at 1\n",
    "        # Also converting the header to a dict to save some trouble\n",
    "        assert_str = f\"Number of HDU names fed to object ({len(names)}) does not match number of HDUs in {filepath} ({len(file_in)})!\"\n",
    "        if from_galfit:\n",
    "            assert len(names) + 1 == len(file_in), assert_str\n",
    "            self.num_imgs = len(file_in) - 1\n",
    "        else:\n",
    "            assert len(names)     == len(file_in), assert_str\n",
    "            self.num_imgs = len(file_in)\n",
    "        \n",
    "        for i, name in enumerate(names):\n",
    "            \n",
    "            index = i\n",
    "            \n",
    "            if from_galfit:\n",
    "                index += 1\n",
    "\n",
    "            header   = deepcopy(dict(file_in[index].header))\n",
    "            data     = deepcopy(file_in[index].data)\n",
    "\n",
    "            hdu = HDU(name = name, header = header, data = data)\n",
    "\n",
    "            self.all_hdu[name] = hdu\n",
    "            \n",
    "        if self.num_imgs == 1:\n",
    "            self.header = self.all_hdu[names[0]].header\n",
    "            self.data   = self.all_hdu[names[0]].data\n",
    "            \n",
    "        self.file = file_in\n",
    "        \n",
    "        # Wait is for continuing to use the file in some other capacity\n",
    "        # i.e. for outputfits below to grab more info\n",
    "        if not wait:\n",
    "            #file_in.close(verbose = True)\n",
    "            self.close()\n",
    "        \n",
    "        #print(\"Did it close?\", file_in.closed)\n",
    "        # assert hdu_num == 4, \"File being passed into FitsHandler has too few output HDUs.\"\n",
    "# ==========================================================================================================\n",
    "\n",
    "    def check_hdu_type(self, hdu):\n",
    "        assert isinstance(hdu, HDU), \"Input HDU is not an HDU class!\"\n",
    "        \n",
    "# ==========================================================================================================\n",
    "    @property\n",
    "    def observation(self):\n",
    "        return self.all_hdu.get(\"observation\", None)\n",
    "    \n",
    "    @observation.setter\n",
    "    def observation(self, new_hdu):\n",
    "        self.check_hdu_type(new_hdu)\n",
    "        self.all_hdu[\"observation\"] = new_hdu\n",
    "\n",
    "# ==========================================================================================================\n",
    "\n",
    "    #def close(self):\n",
    "    #    self.file.close(verbose = True)\n",
    "    #    return\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Destructor for closing FITS files.\"\"\"\n",
    "        \n",
    "        for ext in self.file:\n",
    "            try:\n",
    "                del ext.data\n",
    "                del ext.header\n",
    "            except AttributeError as ae:\n",
    "                pass\n",
    "            gc.collect()\n",
    "\n",
    "        try:\n",
    "            self.file.close(verbose = True)\n",
    "        except Exception as ee:\n",
    "            print(f'Failed to close FITS instance for {self.gname}: {ee}')\n",
    "            print(\"May already be closed...\")\n",
    "\n",
    "# ==========================================================================================================\n",
    "\n",
    "    def to_png(self, cleanup = True, **kwargs): #tmp_fits_path = \"\", tmp_png_path = \"\", out_filename = \"\"):\n",
    "        \n",
    "        gname          = kwargs.get(\"gname\", self.gname)\n",
    "        \n",
    "        # TODO: BAD ASSUMPTION MOVING FORWARD\n",
    "        #tmp_fits_path = kwargs.get(\"tmp_fits_path\", self.filepath)\n",
    "        fits_path      = kwargs.get(\"fits_path\", self.filepath)\n",
    "        # .../galfits -> galfit_png\n",
    "        #tmp_png_dir   = os.path.split(tmp_fits_path)[0].rstrip(\"s\") + \"_png\"\n",
    "        tmp_png_dir    = kwargs.get(\"tmp_png_dir\", \"./\")\n",
    "        tmp_png_path   = pj(tmp_png_dir, gname)\n",
    "        tmp_png_path   = kwargs.get(\"tmp_png_path\", tmp_png_path)\n",
    "        \n",
    "        # TODO: Add starmask into output fits file as an image block\n",
    "#         with fits.open(starmask_path) as sm:\n",
    "#                 starmask_HDU = fits.ImageHDU(data = sm.data, header = sm.header, name = \"STARMASK\")\n",
    "                \n",
    "#         with fits.open(fits_path, mode='update', output_verify='ignore') as fits_hdu:\n",
    "#             fits_hdu.append(starmask_HDU)\n",
    "            \n",
    "        starmask_dir  = kwargs.get(\"starmask_dir\", \"./\")\n",
    "        # Temporarily hardcoding the suffix here\n",
    "        starmask_path = pj(starmask_dir, f\"{gname}_star-rm.fits\")\n",
    "                           \n",
    "        out_png_dir   = kwargs.get(\"out_png_dir\", \"./\")\n",
    "        \n",
    "        capture_output = bool(kwargs.get(\"silent\", False))\n",
    "        \n",
    "        combined_suffix = kwargs.get(\"combined_suffix\", \"combined\")\n",
    "        primary_img_num = kwargs.get(\"primary_img_num\", 1)\n",
    "        \n",
    "        fitspng_param       = \"0.25,1\" #1,150\"\n",
    "        fitspng_param_model = \"0.25,0.75\"\n",
    "            \n",
    "        # Different conventions... 0 is used for model/observation only\n",
    "        if self.num_imgs == 1:\n",
    "            primary_img_num = 0\n",
    "            \n",
    "        else:\n",
    "            if exists(starmask_path):\n",
    "                # copied from below\n",
    "                # ASSUME (for now) that this is doable\n",
    "                # TODO: remove this when starmask is incorporated into fits files\n",
    "                feedme = FeedmeContainer(path_to_feedme = fits_path, header = GalfitHeader())\n",
    "                feedme.from_file(list(self.all_hdu.values())[1].header)\n",
    "                \n",
    "                crop_box = feedme.header.region_to_fit.value\n",
    "                # To adjust for python indexing\n",
    "                # Also, reminder, non-inclusive of end\n",
    "                xbox_min, xbox_max, ybox_min, ybox_max = crop_box[0] - 1, crop_box[1], crop_box[2] - 1, crop_box[3]\n",
    "                \n",
    "                with fits.open(starmask_path) as fits_starmask:\n",
    "                    # masked pixels have value 1, other pixels 0\n",
    "                    # so invert those with a bit of quick math\n",
    "                    starmask_data = np.abs(fits_starmask[0].data - 1)\n",
    "                    starmask_data = starmask_data[xbox_min : xbox_max, ybox_min : ybox_max]\n",
    "\n",
    "                # MODIFIES ORIGINAL RESIDUAL (is this desired?)\n",
    "                with fits.open(fits_path, mode='update', output_verify='ignore') as fits_hdu:\n",
    "                    try:\n",
    "                        fits_hdu[primary_img_num + 2].data *= starmask_data\n",
    "                    except ValueError:\n",
    "                        print(\"Broadcasting issue when attempting to mask the residual array.\")\n",
    "                        print(\"Leaving it alone\")\n",
    "                \n",
    "        im1 = f\"{tmp_png_path}_observation.png\"\n",
    "        im2 = f\"{tmp_png_path}_out.png\"\n",
    "        im3 = f\"{tmp_png_path}_residual.png\"\n",
    "        \n",
    "        # run_fitspng from helper_functions, string path to fitspng program\n",
    "        fitspng_cmd1   = f\"{run_fitspng} -fr \\\"{fitspng_param}\\\" -o {im1} {fits_path}[{primary_img_num}]\"\n",
    "        fitspng_cmd2   = f\"{run_fitspng} -fr \\\"{fitspng_param_model}\\\" -o {im2} {fits_path}[{primary_img_num + 1}]\"            \n",
    "        fitspng_cmd3   = f\"{run_fitspng} -fr \\\"{fitspng_param}\\\" -o {im3} {fits_path}[{primary_img_num + 2}]\"\n",
    "        \n",
    "        cmds             = [fitspng_cmd1, fitspng_cmd2, fitspng_cmd3]\n",
    "        output_png_files = [im1, im2, im3]\n",
    "        \n",
    "        # for n-images\n",
    "        for i in range(primary_img_num + 3, self.num_imgs):\n",
    "            png_name = f\"{tmp_png_path}_image{i}.png\"\n",
    "            \n",
    "            output_png_files.append(png_name)\n",
    "            \n",
    "            cmds.append(\n",
    "                f\"{run_fitspng} -fr \\\"{fitspng_param}\\\" -o {png_name} {fits_path}[{i}]\"\n",
    "            )\n",
    "            \n",
    "        \n",
    "        # sp is from helper_functions, subprocess.run call\n",
    "        for cmd in cmds[:self.num_imgs]:\n",
    "            # We must capture this call to check if the conversion worked\n",
    "            fitspng_out = sp(cmd, capture_output = True)\n",
    "            \n",
    "            if \"error\" in fitspng_out.stderr.lower():\n",
    "                print(\"Skipping fitspng conversion... there is likely a library (libcfitsio) issue.\")\n",
    "                print(f\"Error is:\\n{fitspng_out.stderr}\")\n",
    "                self.combined_png = \"\"\n",
    "                return\n",
    "        \n",
    "        if self.num_imgs == 1:\n",
    "            combined_suffix = \"\"\n",
    "        \n",
    "        # Adding 'magick' to use the portable version in the GalfitModule\n",
    "        run_montage     = shutil.which(\"magick\")\n",
    "        if not run_montage:\n",
    "            run_montage = shutil.which(\"montage\")\n",
    "            if not run_montage:\n",
    "                print(\"Cannot find 'magick' or 'montage' via 'which'.\")\n",
    "                print(\"Proceeding to generate individual pngs without combining them.\")\n",
    "                self.combined_png = \"\"\n",
    "                cleanup = False\n",
    "                \n",
    "        else:\n",
    "            run_montage += \" montage\"\n",
    "            \n",
    "        montage_cmd = run_montage + \" \" + \\\n",
    "                      \" \".join(im_cmd for idx, im_cmd in enumerate(output_png_files)\n",
    "                               if idx + 1 <= self.num_imgs)\n",
    "        \n",
    "        tiling = f\"1x{self.num_imgs}\"\n",
    "        if kwargs.get(\"horizontal\", None):\n",
    "            tiling           = f\"{self.num_imgs}x1\"\n",
    "            combined_suffix += \"_horizontal\"\n",
    "            \n",
    "        # Combining the images using ImageMagick\n",
    "        # If this is a single image, it'll also resize for me so that's why I leave it in\n",
    "        montage_cmd += f\" -tile {tiling} -geometry \\\"175x175+2+2\\\" \" \\\n",
    "                       f\"{pj(out_png_dir, gname)}_{combined_suffix}.png\"\n",
    "        \n",
    "        if run_montage:\n",
    "            _ = sp(montage_cmd, capture_output = capture_output)\n",
    "            self.combined_png    = f\"{pj(out_png_dir, gname)}_{combined_suffix}.png\"\n",
    "        \n",
    "        if cleanup:\n",
    "            _ = rm_files(*output_png_files)\n",
    "        else:\n",
    "            self.observation_png = im1\n",
    "            self.model_png       = im2\n",
    "            self.residual_png    = im3\n",
    "            self.all_png         = output_png_files\n",
    "\n",
    "# ==========================================================================================================\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        \n",
    "        names = self.all_hdu.keys()\n",
    "        \n",
    "        assert_str1 = \"Cannot subtract the data from these two FITS files, they do not contain the same number of HDUs!\"\n",
    "        assert len(self.all_hdu) == len(other.all_hdu), assert_str1\n",
    "        \n",
    "        assert_str2 = \"Cannot subtract the data from these two FITS files, they do not have the same image dimensions!\\n\"\n",
    "        for i, (a, b) in enumerate(zip(self.all_hdu.values(), other.all_hdu.values())):\n",
    "            shape_a = np.shape(a.data)\n",
    "            shape_b = np.shape(b.data)\n",
    "            assert shape_a == shape_b, assert_str2 + f\"At HDU {i}, the images have shapes {shape_a} & {shape_b}.\"\n",
    "            \n",
    "        # Python doesn't care if they're different lengths but\n",
    "        # (for instance in the residual) we don't want to compare one to one\n",
    "        result = {k : a.data - b.data for k, a, b in zip(names, self.all_hdu.values(), other.all_hdu.values())}\n",
    "        \n",
    "        return result\n",
    "\n",
    "# ==========================================================================================================\n",
    "\n",
    "    # def __str__(self):\n",
    "    #     pass\n",
    "        \n",
    "        #return output_str\n",
    "        \n",
    "# ==========================================================================================================\n",
    "\n",
    "    def header_dict(self, name = \"\"):\n",
    "        \n",
    "        if name:\n",
    "            output_dict = dict(self.all_hdu[name].header)\n",
    "        else:\n",
    "            output_dict = {name : dict(hdu.header) for name, hdu in self.all_hdu.items()}\n",
    "            \n",
    "        return output_dict\n",
    "    \n",
    "# =========================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96e7be94-ebe9-43ae-9a9b-420e9486299d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OutputFits(FitsFile):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        filepath,  \n",
    "        load_default = True, \n",
    "        **kwargs\n",
    "    ):\n",
    "            \n",
    "        FitsFile.__init__(\n",
    "            self, \n",
    "            filepath    = filepath,\n",
    "            names       = [\"observation\", \"model\", \"residual\"],\n",
    "            wait        = True,\n",
    "            from_galfit = True,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        # Dict is very redundant here but just for funsies\n",
    "        # FITS header not Feedme header\n",
    "        self.header = deepcopy(dict(self.model.header))\n",
    "        \n",
    "        # Can call the helper directly since we're just using the header dict\n",
    "        #_header.from_file_helper_dict(self.header)\n",
    "        self.feedme = FeedmeContainer(path_to_feedme = filepath, header = GalfitHeader(), load_default = load_default, **kwargs)\n",
    "        self.feedme.from_file(self.header)\n",
    "        \n",
    "        self.data = deepcopy(self.model.data)\n",
    "        \n",
    "        self.bulge_mask = np.ones(np.shape(self.data))\n",
    "        \n",
    "        self.close()\n",
    "        \n",
    "# ==========================================================================================================\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self.all_hdu.get(\"model\", None)\n",
    "    \n",
    "    @model.setter\n",
    "    def model(self, new_hdu):\n",
    "        self.check_hdu_type(new_hdu)\n",
    "        self.all_hdu[\"model\"] = new_hdu\n",
    "        \n",
    "    @property\n",
    "    def residual(self):\n",
    "        return self.all_hdu.get(\"residual\", None)\n",
    "    \n",
    "    @residual.setter\n",
    "    def residual(self, new_hdu):\n",
    "        self.check_hdu_type(new_hdu)\n",
    "        self.all_hdu[\"residual\"] = new_hdu\n",
    "        \n",
    "# ==========================================================================================================\n",
    "        \n",
    "    def generate_bulge_mask(self, sparcfire_csv):\n",
    "        \n",
    "        # Thanks Azra!\n",
    "        bulge_mask = np.ones(np.shape(self.model.data))\n",
    "        \n",
    "        try:\n",
    "            info = pd.read_csv(sparcfire_csv, dtype = str).dropna()\n",
    "        except FileNotFoundError as fe:\n",
    "            print(fe)\n",
    "            return bulge_mask\n",
    "        \n",
    "        if \"rejected\" in info[' fit_state']:\n",
    "            print(f\"SpArcFiRe fit_state 'rejected'. Cannot determine the bulge mask for {self.gname}.\")\n",
    "            return bulge_mask\n",
    "            \n",
    "        try:\n",
    "            input_size = float(str(info[' iptSz'][0]).split()[0][1:])\n",
    "        except Exception as e:\n",
    "            print(f\"There is an issue determining the bulge mask for {self.gname}.\")\n",
    "            return bulge_mask\n",
    "        \n",
    "        bulge_rad  = float(info[' bulgeMajAxsLen'][0])\n",
    "        # In radians\n",
    "        bulge_angle = float(info[' bulgeMajAxsAngle'][0])\n",
    "        axis_ratio  = float(info[' bulgeAxisRatio'][0]) # Maj/minor\n",
    "        if axis_ratio < 0.5:\n",
    "            axis_ratio = 0.5\n",
    "        \n",
    "        # + 1 added for effect\n",
    "        major_rad = int(bulge_rad * len(self.model.data[0]) // input_size) + 1\n",
    "        minor_rad = int(major_rad/axis_ratio)\n",
    "\n",
    "        crop_box = self.feedme.header.region_to_fit.value\n",
    "        # To adjust for python indexing\n",
    "        xbox_min, ybox_min = crop_box[0] - 1, crop_box[2] - 1\n",
    "        \n",
    "        # Shifting everything to origin\n",
    "        center_x, center_y = np.array(self.feedme.bulge.position.value, dtype = int) - 1 -\\\n",
    "                             np.array((xbox_min, ybox_min), dtype = int)\n",
    "        \n",
    "        # center_x2, bulge_y2 = np.array(self.feedme.bulge.position, dtype = int) - \\\n",
    "        #                      np.array((xbox_min, ybox_min), dtype = int) + \\\n",
    "        #                      rad\n",
    "\n",
    "        #xx, yy = disk((center_x, center_y), major_rad)\n",
    "        try:\n",
    "            xx, yy = ellipse(center_x, center_y, major_rad, minor_rad, rotation = bulge_angle, shape = np.shape(self.model.data))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(self.gname)\n",
    "            print(center_x, center_y, major_rad, minor_rad, rotation)\n",
    "            return bulge_mask\n",
    "        \n",
    "        bulge_mask[xx, yy] = 0\n",
    "        self.bulge_mask = bulge_mask\n",
    "        \n",
    "#         temp = self.model.data\n",
    "#         plt.imshow(temp, origin = \"lower\")\n",
    "#         plt.show()\n",
    "        \n",
    "#         temp[xx, yy] = np.min(self.model.data[np.nonzero(self.model.data)])\n",
    "#         plt.imshow(temp, origin = \"lower\")\n",
    "#         plt.show()\n",
    "\n",
    "        #self.close()\n",
    "        return bulge_mask\n",
    "    \n",
    "# ==========================================================================================================\n",
    "        \n",
    "    def generate_cluster_mask(self, cluster_mask_png, crop_box):\n",
    "        # 1237668297135030610-D_clusMask.png\n",
    "\n",
    "        cluster_mask = None\n",
    "        try:\n",
    "            cluster_img = iio.imread(cluster_mask_png, mode = \"L\")\n",
    "        except FileNotFoundError as fe:\n",
    "            print(fe)\n",
    "            return cluster_mask\n",
    "\n",
    "        xbox_min, xbox_max, ybox_min, ybox_max = crop_box[0] - 1, crop_box[1], crop_box[2] - 1, crop_box[3]\n",
    "        cluster_img = cluster_img[xbox_min:xbox_max, ybox_min:ybox_max]\n",
    "        \n",
    "        cluster_mask = deepcopy(cluster_img)\n",
    "        # Mask non-clusters\n",
    "        cluster_mask[cluster_img == 0] = 1\n",
    "        # Leave clusters alone\n",
    "        cluster_mask[cluster_img != 0] = 0\n",
    "        \n",
    "        self.cluster_mask = cluster_mask\n",
    "        \n",
    "        return cluster_mask\n",
    "    \n",
    "# ==========================================================================================================\n",
    "        \n",
    "    def generate_masked_residual(\n",
    "        self, \n",
    "        mask, \n",
    "        use_bulge_mask = False,\n",
    "        use_cluster_mask = False,\n",
    "        update_fits_header = True\n",
    "    ):\n",
    "\n",
    "        small_number = 1e-8\n",
    "        \n",
    "        crop_box = self.feedme.header.region_to_fit.value\n",
    "        # To adjust for python indexing\n",
    "        # Also, reminder, non-inclusive of end\n",
    "        xbox_min, xbox_max, ybox_min, ybox_max = crop_box[0] - 1, crop_box[1], crop_box[2] - 1, crop_box[3]\n",
    "        # To invert the matrix since galfit keeps 0 valued areas\n",
    "        crop_mask = 1\n",
    "        if mask is not None and np.any(mask.data):\n",
    "            cropped_mask = mask.data[xbox_min:xbox_max, ybox_min:ybox_max]\n",
    "            mask_shape = np.shape(mask.data)\n",
    "            # Fixing two common issues, hence two if statements\n",
    "            if np.shape(cropped_mask) != np.shape(self.model.data):\n",
    "                # The issue seems to pop up at the max border when either the min or the max runs up\n",
    "                # against the original image size\n",
    "                print(\"Shape mismatch between crop mask and model. Likely an indexing issue due to crop mask running into image bounds. Attempting to fix.\")\n",
    "                diff = np.array(np.shape(cropped_mask)) - np.array(np.shape(self.model.data))\n",
    "                # One or the other... No graceful way to do this\n",
    "                if xbox_min == 0:\n",
    "                    xbox_max -= diff[0]\n",
    "                else:\n",
    "                    xbox_min -= diff[0]\n",
    "                    \n",
    "                if ybox_min == 0:\n",
    "                    ybox_max -= diff[0]\n",
    "                else:\n",
    "                    ybox_min -= diff[0]\n",
    "                \n",
    "                cropped_mask = mask.data[xbox_min:xbox_max, ybox_min:ybox_max]\n",
    "                \n",
    "            # Now we're just trying to brute force it and hope for the best\n",
    "            if np.shape(cropped_mask) != np.shape(self.model.data):\n",
    "                print(\"Shape mismatch (again) between crop mask and model. Likely an indexing issue due to crop mask running into image bounds. Attempting to fix.\")\n",
    "                diff = np.abs(np.array(np.shape(cropped_mask)) - np.array(np.shape(self.model.data)))\n",
    "                cropped_mask = np.pad(cropped_mask, ((diff[0],0), (diff[1],0)), 'constant')\n",
    "                \n",
    "            # Giving up and proceeding without\n",
    "            if np.shape(cropped_mask) != np.shape(self.model.data):\n",
    "                print(\"Shape mismatch. Proceeding without crop mask.\")\n",
    "                cropped_mask = 0\n",
    "                \n",
    "            crop_mask = 1 - cropped_mask\n",
    "            \n",
    "        feedme_dir, feedme_file = os.path.split(self.feedme.path_to_feedme)\n",
    "        if use_bulge_mask:\n",
    "            if exists(pj(feedme_dir, f\"{self.gname}.csv\")):\n",
    "                crop_mask = self.generate_bulge_mask(pj(feedme_dir, f\"{self.gname}.csv\")) * crop_mask\n",
    "            else:\n",
    "                # REQUIRES GENERATE_BULGE_MASK TO BE RUN SEPARATE WITH CSV FILE SPECIFIED \n",
    "                try:\n",
    "                    crop_mask = self.bulge_mask * crop_mask\n",
    "                except AttributeError:\n",
    "                    print(f\"Could not generate bulge mask for {self.gname}. Check location of csv or run generate_bulge_mask with a specified csv file.\")\n",
    "                except ValueError:\n",
    "                    print(f\"Could not generate bulge mask for {self.gname}. There may be an issue with sparcfire output (broadcast issue).\")\n",
    "        \n",
    "        if use_cluster_mask:\n",
    "            # Use reprojected mask\n",
    "            cmask_filename = pj(feedme_dir, f\"{self.gname}-K_clusMask-reprojected.png\")\n",
    "            \n",
    "            if exists(cmask_filename):\n",
    "                crop_mask = self.generate_cluster_mask(cmask_filename, crop_box) * crop_mask\n",
    "            else:\n",
    "                # REQUIRES GENERATE_CLUSTER_MASK TO BE RUN SEPARATE WITH CSV FILE SPECIFIED \n",
    "                try:\n",
    "                    crop_mask = self.cluster_mask * crop_mask\n",
    "                except AttributeError:\n",
    "                    print(f\"Could not generate cluster mask for {self.gname}. Check location of csv or run generate_bulge_mask with a specified csv file.\")\n",
    "                except ValueError:\n",
    "                    print(f\"Could not generate cluster mask for {self.gname}. There may be an issue with sparcfire output (broadcast issue).\")\n",
    "            \n",
    "        try:\n",
    "            # compare to gaussian with same mean, std via kstest\n",
    "            # if p value high, not that different\n",
    "            \n",
    "            self.masked_residual  = (self.observation.data - self.model.data)*crop_mask\n",
    "            exclude_masked_pixels = self.masked_residual[np.abs(self.masked_residual) > 0]\n",
    "            mean                  = np.mean(exclude_masked_pixels)\n",
    "            std                   = np.std(exclude_masked_pixels)\n",
    "            gaussian              = norm.rvs(size = len(exclude_masked_pixels), loc = mean, scale = std, random_state = 0)\n",
    "            self.kstest           = kstest(gaussian, exclude_masked_pixels.flatten())\n",
    "            pvalue                = self.kstest.pvalue\n",
    "            #statistic             = self.kstest.statistic\n",
    "            # gaussian = norm.rvs(size = len(self.masked_residual)**2, loc = mean, scale = std, random_state = 0)\n",
    "            # noised_masked_pixels = np.where(np.abs(self.masked_residual.flatten()) > 0, self.masked_residual.flatten(), gaussian)\n",
    "            # self.kstest = kstest(gaussian, noised_masked_pixels)\n",
    "\n",
    "            self.norm_observation           = slg.norm(crop_mask*self.observation.data)\n",
    "            self.norm_model                 = slg.norm(crop_mask*self.model.data)\n",
    "            self.norm_residual              = slg.norm(crop_mask*self.residual.data)\n",
    "            self.masked_residual_normalized = self.masked_residual/min(self.norm_observation, self.norm_model)\n",
    "            self.wayne_residual             = self.norm_residual/self.norm_observation\n",
    "            self.wayne_quality              = pvalue/self.wayne_residual # bigger is better\n",
    "            \n",
    "#             obs_model = 1 - np.divide(\n",
    "#                                 crop_mask*self.observation.data/self.norm_observation, \n",
    "#                                 crop_mask*self.model.data/self.norm_model + small_number\n",
    "#                                      )\n",
    "\n",
    "#             model_obs = 1 - np.divide( \n",
    "#                                 crop_mask*self.model.data/self.norm_model,\n",
    "#                                 crop_mask*self.observation.data/self.norm_observation + small_number\n",
    "#                                     )\n",
    "            # Replace negative values with 1 - reciprocal\n",
    "#            self.masked_residual_ratio = np.where(obs_model >= 0, obs_model, model_obs)\n",
    "            # Masked residual normalized\n",
    "            # I seem to use this acronym a lot\n",
    "            self.nmr  = slg.norm(self.masked_residual_normalized)\n",
    "#            self.nmrr = slg.norm(self.masked_residual_ratio)\n",
    "\n",
    "            if update_fits_header:\n",
    "                with fits.open(self.filepath, mode='update', output_verify='ignore') as hdul:\n",
    "                    hdul[2].header[\"NMR\"]   = (round(self.nmr, 8), \"Norm of the masked residual\")\n",
    "                    hdul[2].header[\"W_NMR\"] = (round(self.wayne_residual, 8), \"Wayne's residual\")\n",
    "                    #hdul[2].header[\"W_Q\"]   = (round(self.nmr, 8), \"Wayne's quality measure\")\n",
    "\n",
    "                    # pvalue is sometimes none but round can't handle it\n",
    "                    if isinstance(pvalue, float): # and isinstance(statistic, float):\n",
    "                        hdul[2].header[\"KS_P\"]    = (round(pvalue, 8), \"p value of kstest vs noise\")\n",
    "                        #hdul[2].header[\"KS_STAT\"] = (round(statistic, 8), \"statistic value of kstest vs noise\")\n",
    "                    else:\n",
    "                        hdul[2].header[\"KS_P\"]    = (None, \"p value of kstest vs noise\")\n",
    "                        #hdul[2].header[\"KS_STAT\"] = (None, \"statistic value of kstest vs noise\")\n",
    "\n",
    "        except ValueError:\n",
    "            print(f\"There may be a broadcast issue, observation, model, crop mask: \", end = \"\")\n",
    "            print(f\"{np.shape(self.observation.data)}, {np.shape(self.model.data)}, {np.shape(crop_mask)}\")\n",
    "            # print(np.shape(mask_fits_file.data))\n",
    "            # print(np.shape(fits_file.data))\n",
    "            # print(crop_box)\n",
    "            #self.close()\n",
    "            return None\n",
    "        \n",
    "        #self.close()\n",
    "        \n",
    "        return self.masked_residual_normalized\n",
    "\n",
    "# =========================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75833ee7-fa48-45cd-a4e5-8ce1467453e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from RegTest.RegTest import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a35a54d6-6188-4e98-8f94-eb8c42e8123a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation\n",
      "SIMPLE = True\n",
      "BITPIX = -64\n",
      "NAXIS = 2\n",
      "NAXIS1 = 148\n",
      "NAXIS2 = 148\n",
      "CRVAL1 = 132.77287749\n",
      "CRVAL2 = 11.05630315\n",
      "RADESYS = FK5\n",
      "EQUINOX = 2000.0\n",
      "CTYPE1 = RA---TAN\n",
      "CTYPE2 = DEC--TAN\n",
      "CRPIX1 = 74.5\n",
      "CRPIX2 = 74.5\n",
      "CDELT1 = -0.00011\n",
      "CDELT2 = 0.00011\n",
      "COMMENT = \n",
      " SkyView Survey metadata\n",
      "\n",
      "Provenance:  Sloan Digital Sky Survey Team\n",
      "Copyright:   See        Sloan usage document for distribution rights a\n",
      "          nd acknowledgements.\n",
      "Regime:      Optical\n",
      "NSurvey:     5\n",
      "Frequency:   490 THz\n",
      "Coverage:    9,583 square degrees. The SDDS site provides coverage map\n",
      "          s\n",
      "PixelScale:  0.4\"\n",
      "PixelUnits:  ADUs\n",
      "Resolution:  1\"\n",
      "Coordinates: Equatorial\n",
      "Projection:  Tangent\n",
      "Epoch:       ca. 2000\n",
      "Reference:    Sloan Digital Sky Survey web site\n",
      "\n",
      "Survey specific cards\n",
      "\n",
      "These data are resampled from the Sloan Digital Sky Survey Data\n",
      "available at www.sdss.org.\n",
      "Image datasets were dynamically downloaded from the Sloan Site\n",
      "and resampled into the projection requested by the user.\n",
      "SURVEY = SDSS-r  DR7\n",
      "HISTORY = \n",
      " Settings used in processing:\n",
      "\n",
      "coordinates = J2000.0\n",
      "deedger = skyview.process.Deedger\n",
      "equinox = 2000\n",
      "finalpostprocessor = skyview.ij.IJProcessor,skyview.data.BoxSmoother,sky\n",
      "imagefactory = skyview.survey.CachingImageFactory\n",
      "imagesize = 0.25\n",
      "lat = 11.05630315\n",
      "lon = 132.77287749\n",
      "mosaicker = skyview.process.Mosaicker\n",
      "name = Sloan Digitized Sky Survey r-band\n",
      "output = 1237671124296532233_3\n",
      "pixels = 148\n",
      "position = 132.77287749, 11.05630315\n",
      "projection = Tan\n",
      "reqxpos = 132.77287749\n",
      "reqypos = 11.05630315\n",
      "resolver = NED-SIMBAD\n",
      "sampler = Default\n",
      "scale = 0.00011\n",
      "settingsupdaters = BatchCompatibility,SettingsFixer,skyview.request.Toas\n",
      "shortname = SDSSdr7r,SDSSdr7 r\n",
      "siabase = http://skyview.gsfc.nasa.gov/cgi-bin/images?\n",
      "siapcoordinates = J2000\n",
      "siapprojection = Tan\n",
      "siapurl = http://casjobs.sdss.org/vo/DR7SIAP/SIAP.asmx/getSiapInfo?FORMA\n",
      "size = 0.01628,0.01628\n",
      "survey = SDSSdr7u,SDSSdr7g,SDSSdr7r,SDSSdr7i,SDSSdr7z\n",
      "surveyfinder = skyview.survey.XMLSurveyFinder\n",
      "surveymanifest = surveys/survey.manifest\n",
      "url.heasarcbase = http://heasarc.gsfc.nasa.gov/xamin/vo/cone?table=\n",
      "url.ned = http://nedwww.ipac.caltech.edu/cgi-bin/nph-NEDobjsearch?search\n",
      "url.simbad = http://simbad.u-strasbg.fr/simbad-conesearch.pl?\n",
      "url.vizierbase = http://vizier.u-strasbg.fr/viz-bin/votable/-dtd/-A?-out\n",
      "urlcoordinates = http://heasarc.gsfc.nasa.gov/cgi-bin/Tools/convcoord/co\n",
      "urllocalhelp = http://skyview.gsfc.nasa.gov/help/help.html\n",
      "\n",
      " Map generated at: Tue Dec 18 17:55:18 PST 2012\n",
      "\n",
      " Resampler used: NNSampler\n",
      "\n",
      "\n",
      "Image mosaicking using skyview.geometry.Mosaicker\n",
      "\n",
      "  Used image:.\\skycache\\fpC-005972-r4-0116.fit.gz\n",
      "\n",
      "Img size: (148, 148)\n",
      "\n",
      "#  Input menu file: .in\n",
      "\n",
      "#  \n",
      "\n",
      "================================================================================\n",
      "# IMAGE and GALFIT CONTROL PARAMETERS\n",
      "A) .fits                # Input data image (FITS file)\n",
      "B) _galfit_out.fits     # Output data image block\n",
      "C) none                 # Sigma image name (made from data if blank or 'none')\n",
      "D) 1237671124296532233_psf.fits # Input PSF image and (optional) diffusion kernel\n",
      "E) 1                    # PSF fine sampling factor relative to data\n",
      "F) _star-rm.fits        # Bad pixel mask (FITS image or ASCII coord list)\n",
      "G) none                 # File with parameter constraints (ASCII file)\n",
      "H) 20   128  20   128   # Image region to fit (xmin xmax ymin ymax)\n",
      "I) 50     50            # Size of the convolution box (x y)\n",
      "J) 24.8                 # Magnitude photometric zeropoint\n",
      "K) 0.396  0.396         # Plate scale (dx dy)   [arcsec per pixel]\n",
      "O) regular              # Display type (regular, curses, both)\n",
      "P) 0                    # Choose: 0=optimize, 1=model, 2=imgblock, 3=subcomps\n",
      "\n",
      "# INITIAL FITTING PARAMETERS\n",
      "#\n",
      "#   For component type, the allowed functions are: \n",
      "#       sersic, expdisk, edgedisk, devauc, king, nuker, psf, \n",
      "#       gaussian, moffat, ferrer, and sky. \n",
      "#  \n",
      "#   Hidden parameters will only appear when they're specified:\n",
      "#       Bn (n=integer, Bending Modes).\n",
      "#       C0 (diskyness/boxyness), \n",
      "#       Fn (n=integer, Azimuthal Fourier Modes).\n",
      "#       R0-R10 (coordinate rotation, for creating spiral structures).\n",
      "#       To, Ti, T0-T10 (truncation function).\n",
      "# \n",
      "# ------------------------------------------------------------------------------\n",
      "#   par)    par value(s)    fit toggle(s)    # parameter description \n",
      "# ------------------------------------------------------------------------------\n",
      "\n",
      "# Component number: 1\n",
      " 0) sersic              # Component type\n",
      " 1) 73.8201 74.2847 0  0 # Position x, y\n",
      " 3) 14.4655     1       # Integrated magnitude\n",
      " 4) 11.9606     1       # R_e (effective radius)   [pix]\n",
      " 5) 1.0225      1       # Sersic index n (de Vaucouleurs n=4)\n",
      " 9) 0.5615      1       # Axis ratio (b/a)\n",
      " 10) -2.9069    1       # Position angle (PA) [deg: Up=0, Left=90]\n",
      " Z) 0                   # Skip this model in output image?  (yes=1, no=0)\n",
      "\n",
      "# Component number: 2\n",
      " 0) sersic              # Component type\n",
      " 1) 73.8200 74.2800 0  0 # Position x, y\n",
      " 3) 13.7671     1       # Integrated magnitude\n",
      " 4) 23.4744     1       # R_e (effective radius)   [pix]\n",
      " 5) 0.4464      1       # Sersic index n (de Vaucouleurs n=4)\n",
      " 9) 0.4353      1       # Axis ratio (b/a)\n",
      " 10) -87.8193   1       # Position angle (PA) [deg: Up=0, Left=90]\n",
      " Z) 0                   # Skip this model in output image?  (yes=1, no=0)\n",
      "\n",
      "R0) power               # Component type\n",
      "R1) 0.0         0       # Spiral inner radius [pixels]\n",
      "R2) 8.2001      0       # Spiral outer radius [pixels]\n",
      "R3) -230.4884   1       # Cumul. rotation out to outer radius [degrees]\n",
      "R4) 0.1411      1       # Asymptotic spiral powerlaw\n",
      "R9) 55.6969     1       # Inclination to L.o.S. [degrees]\n",
      "R10) 56.5248    1       # Sky position angle\n",
      "F1) 0.0642 166.0134 1  1 # Azim. Fourier mode 1, amplitude, & phase angle\n",
      "F3) -0.1451 43.4874 1  1 # Azim. Fourier mode 3, amplitude, & phase angle\n",
      " Z) 0                   # Skip this model in output image?  (yes=1, no=0)\n",
      "\n",
      "# Component number: 3\n",
      " 0) sky                 # Component type\n",
      " 1) 1084.9591   1       # Sky background at center of fitting region [ADUs]\n",
      " 2) -0.002      1       # dsky/dx (sky gradient in x)     [ADUs/pix]\n",
      " 3) 0.0009      1       # dsky/dy (sky gradient in y)     [ADUs/pix]\n",
      " Z) 0                   # Skip this model in output image?  (yes=1, no=0)\n",
      "\n",
      "\n",
      "model\n",
      "XTENSION = IMAGE\n",
      "BITPIX = -32\n",
      "NAXIS = 2\n",
      "NAXIS1 = 109\n",
      "NAXIS2 = 109\n",
      "OBJECT = model\n",
      "COMMENT = ========== GALFIT Input Parameters ==========\n",
      "========== GALFIT Final Parameters ==========\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "=============================================\n",
      "\n",
      "INITFILE = /home/portmanm/sparcfire_matt/GalfitModule/RegTest/TestOutput/test-o\n",
      "DATAIN = /home/portmanm/sparcfire_matt/GalfitModule/RegTest/TestData/test-in/\n",
      "SIGMA = none\n",
      "PSF = 1237671124296532233_psf.fits\n",
      "CONSTRNT = none\n",
      "MASK = /home/portmanm/sparcfire_matt/GalfitModule/RegTest/TestOutput/test-t\n",
      "FITSECT = [20:128,20:128]\n",
      "CONVBOX = 50, 50\n",
      "MAGZPT = 24.8\n",
      "COMP_1 = sersic\n",
      "1_XC = [73.8201]\n",
      "1_YC = [74.2847]\n",
      "1_MAG = 14.4655 +/- 0.0496\n",
      "1_RE = 11.9606 +/- 0.4152\n",
      "1_N = 1.0225 +/- 0.0281\n",
      "1_AR = 0.5615 +/- 0.0183\n",
      "1_PA = -2.9069 +/- 1.5305\n",
      "COMP_2 = sersic\n",
      "2_XC = [73.8200]\n",
      "2_YC = [74.2800]\n",
      "2_MAG = 13.7671 +/- 0.0278\n",
      "2_RE = 23.4744 +/- 1.4306\n",
      "2_N = 0.4464 +/- 0.0107\n",
      "2_AR = 0.4353 +/- 0.0290\n",
      "2_PA = -87.8193 +/- 68.2534\n",
      "2_ROTF = power\n",
      "2_RIN = [0.0000]\n",
      "2_ROUT = [8.2001]\n",
      "2_RANG = -230.4884 +/- 68.6326\n",
      "2_ALPHA = 0.1411 +/- 0.0421\n",
      "2_INCL = 55.6969 +/- 2.1821\n",
      "2_SPA = 56.5248 +/- 1.3948\n",
      "2_F1 = 0.0642 +/- 0.0046\n",
      "2_F1PA = 166.0134 +/- 5.7221\n",
      "2_F3 = -0.1451 +/- 0.0043\n",
      "2_F3PA = 43.4874 +/- 1.2761\n",
      "COMP_3 = sky\n",
      "3_XC = [74.0000]\n",
      "3_YC = [74.0000]\n",
      "3_SKY = 1084.9591 +/- 0.0454\n",
      "3_DSDX = -1.982e-03 +/- 1.128e-03\n",
      "3_DSDY = 9.500e-04 +/- 1.135e-03\n",
      "FLAGS = A-6 H-3 H-4 H-1 A-2 A-5\n",
      "CHISQ = 11132.8013029998\n",
      "NDOF = 11802\n",
      "NFREE = 21\n",
      "NFIX = 6\n",
      "CHI2NU = 0.9432979\n",
      "LOGFILE = galfit.02\n",
      "Img size: (109, 109)\n",
      "\n",
      "These should all be the same .\n",
      "(109, 109)\n",
      "(109, 109)\n",
      "(109, 109)\n",
      "(109, 109)\n",
      "Andddd pre crop\n",
      "(148, 148)\n"
     ]
    }
   ],
   "source": [
    "# Testing from_file\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    gname = \"1237671124296532233\"\n",
    "    obs   = pj(SAMPLE_DIR, f\"{gname}.fits\")\n",
    "    model = pj(SAMPLE_DIR, f\"{gname}_galfit_out.fits\")\n",
    "    mask  = pj(SAMPLE_DIR, f\"{gname}_star-rm.fits\")\n",
    "    \n",
    "    test_obs   = FitsFile(obs)\n",
    "    test_model = OutputFits(model)\n",
    "    test_mask  = FitsFile(mask)\n",
    "    \n",
    "    print(test_obs.observation)\n",
    "    print()\n",
    "    print(test_model.feedme)\n",
    "    print()\n",
    "    print(test_model.model)\n",
    "    \n",
    "    # Purposefully do not fill in some of the header parameters\n",
    "    # since those do not exist in the output FITS header\n",
    "    # This is done to remind the user/programmer that the \n",
    "    # OutputFits object only serves to represent the header\n",
    "    # nothing more, nothing less and so also reminds them to\n",
    "    # use a different method to fill in the header.\n",
    "    #print(test_model.feedme.header)\n",
    "    \n",
    "#     _header = GalfitHeader()\n",
    "#     _header.from_file_helper(test_out.header)\n",
    "    \n",
    "#     crop_box = _header.region_to_fit\n",
    "#     # To adjust for python indexing\n",
    "#     box_min, box_max = crop_box[0] - 1, crop_box[1]\n",
    "        \n",
    "#     print(np.shape(test_in.data[box_min:box_max, box_min:box_max]))\n",
    "    print(\"\\nThese should all be the same .\")\n",
    "    print(np.shape(test_model.observation.data))\n",
    "    print(np.shape(test_model.data))\n",
    "    print(np.shape(test_model.residual.data))\n",
    "    crop_box = test_model.feedme.header.region_to_fit.value\n",
    "    # + 1 to account for python indexing\n",
    "    crop_rad = crop_box[1] - crop_box[0] + 1\n",
    "    print(f\"({crop_rad}, {crop_rad})\")\n",
    "    print(\"Andddd pre crop\")\n",
    "    print(np.shape(test_obs.observation.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92c03ef5-731d-4284-9d4b-52c4f50e818e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No bulge mask\n",
      "Norm of the observation: 118341.5481\n",
      "Norm of the model: 118339.6776\n",
      "Norm of the residual: 495.2399\n",
      "Norm of the masked residual: 0.0042\n",
      "Wayne's residual: 0.0042\n",
      "kstest p value: 0.0005\n",
      "\n",
      "Now with bulge mask\n",
      "Norm of the observation: 118341.5481\n",
      "Norm of the model: 118339.6776\n",
      "Norm of the residual: 495.2399\n",
      "Norm of the masked residual: 0.0042\n",
      "Wayne's residual: 0.0042\n",
      "kstest p value: 0.0005\n"
     ]
    }
   ],
   "source": [
    "# Unit test to check value of masked residual\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Turn off updating FITS header to avoid modifying test data\n",
    "    print(\"No bulge mask\")\n",
    "    _ = test_model.generate_masked_residual(test_mask, use_bulge_mask = False, update_fits_header = False)\n",
    "    print(f\"Norm of the observation: {test_model.norm_observation:.4f}\")\n",
    "    print(f\"Norm of the model: {test_model.norm_model:.4f}\")\n",
    "    print(f\"Norm of the residual: {test_model.norm_residual:.4f}\")\n",
    "    print(f\"Norm of the masked residual: {test_model.nmr:.4f}\")\n",
    "    print(f\"Wayne's residual: {test_model.wayne_residual:.4f}\")\n",
    "    #print(f\"Norm of the masked residual ratio: {test_model.nmrr:.8f}\")\n",
    "    print(f\"kstest p value: {test_model.kstest.pvalue:.4f}\")\n",
    "    #print(f\"kstest statistic: {test_model.kstest.statistic:.4f}\")\n",
    "    \n",
    "    print(\"\\nNow with bulge mask\")\n",
    "    _ = test_model.generate_bulge_mask(pj(TEST_DATA_DIR, \"test-out\", gname, f\"{gname}.csv\"))\n",
    "    _ = test_model.generate_masked_residual(test_mask, update_fits_header = False)\n",
    "    print(f\"Norm of the observation: {test_model.norm_observation:.4f}\")\n",
    "    print(f\"Norm of the model: {test_model.norm_model:.4f}\")\n",
    "    print(f\"Norm of the residual: {test_model.norm_residual:.4f}\")\n",
    "    print(f\"Norm of the masked residual: {test_model.nmr:.4f}\")\n",
    "    print(f\"Wayne's residual: {test_model.wayne_residual:.4f}\")\n",
    "    #print(f\"Norm of the masked residual ratio: {test_model.nmrr:.8f}\")\n",
    "    print(f\"kstest p value: {test_model.kstest.pvalue:.4f}\")\n",
    "    #print(f\"kstest statistic: {test_model.kstest.statistic:.4f}\")\n",
    "    #print(np.min(test_model.observation.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "097ac095-8233-4498-a09f-8824a82fd9c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking FITS header update with NMR\n",
      "Does the updated FITS file contain NMR and KStest keys?\n",
      "Before... (expect False) False\n",
      "After... True\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model           = pj(SAMPLE_DIR, f\"sample_model_galfit_out.fits\")\n",
    "    model_to_update = pj(TEST_OUTPUT_DIR, f\"temp_galfit_out.fits\")\n",
    "    \n",
    "    if exists(model_to_update):\n",
    "        #sp(f\"rm -f {model_to_update}\")\n",
    "        rm_files(model_to_update)\n",
    "        \n",
    "    _ = sp(f\"cp {model} {model_to_update}\")\n",
    "\n",
    "    test_model = OutputFits(model_to_update)\n",
    "    print(\"Checking FITS header update with NMR\")\n",
    "    \n",
    "    print(\"Does the updated FITS file contain NMR and KStest keys?\")\n",
    "    keys_to_check = (\"NMR\", \"KS_P\", \"W_NMR\")\n",
    "    \n",
    "    # TODO: replace fits file with one without those header options\n",
    "    # Expect False\n",
    "    print(\"Before... (expect False)\", all(k in test_model.header for k in keys_to_check))\n",
    "    assert not all(k in test_model.header for k in keys_to_check), \"Expected False.\"\n",
    "    \n",
    "    \n",
    "    _ = test_model.generate_masked_residual(test_mask)\n",
    "    test_model = OutputFits(model_to_update)\n",
    "\n",
    "    print(\"After...\", all(k in test_model.header for k in keys_to_check))\n",
    "    assert all(k in test_model.header for k in keys_to_check), \"Expected True.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5230832d-ffcf-4905-8a37-f40720f967b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if all FITS files are closed...\n",
      "Expect True: True\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Checking if all FITS files are closed...\")\n",
    "    print(\"Expect True:\", not any(\"fits\" in pof.path for pof in psutil.Process().open_files()))\n",
    "    assert not any(\"fits\" in pof.path for pof in psutil.Process().open_files()), \"Expected True.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7af0c62-fbe9-4f59-9d44-bc769ce837fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting FitsHandlers.ipynb\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    export_to_py(\"FitsHandlers\", pj(_MODULE_DIR, \"Classes\", \"FitsHandlers\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
