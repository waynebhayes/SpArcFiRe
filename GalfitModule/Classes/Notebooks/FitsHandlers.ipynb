{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33abdbf-5f26-4ca8-b4e9-42f3a8081216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from os.path import join as pj\n",
    "from os.path import exists\n",
    "import subprocess\n",
    "from copy import deepcopy\n",
    "from IPython import get_ipython\n",
    "from astropy.io import fits\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import scipy.linalg as slg\n",
    "from scipy.stats import norm, kstest\n",
    "from skimage.draw import disk, ellipse\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422e80ba-e349-474e-a843-75cb28e8079a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For debugging purposes\n",
    "from IPython import get_ipython\n",
    "def in_notebook():\n",
    "    ip = get_ipython()\n",
    "    \n",
    "    if ip:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc86a10-9752-46fe-8f9a-978003abaf84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_HOME_DIR = os.path.expanduser(\"~\")\n",
    "if in_notebook():\n",
    "    _SPARCFIRE_DIR = pj(_HOME_DIR, \"sparcfire_matt\") \n",
    "    _MODULE_DIR    = pj(_SPARCFIRE_DIR, \"GalfitModule\")\n",
    "else:\n",
    "    try:\n",
    "        _SPARCFIRE_DIR = os.environ[\"SPARCFIRE_HOME\"]\n",
    "        _MODULE_DIR = pj(_SPARCFIRE_DIR, \"GalfitModule\")\n",
    "    except KeyError:\n",
    "        if __name__ == \"__main__\":\n",
    "            print(\"SPARCFIRE_HOME is not set. Please run 'setup.bash' inside SpArcFiRe directory if not done so already.\")\n",
    "            print(\"Checking the current directory for GalfitModule, otherwise quitting.\")\n",
    "            \n",
    "        _MODULE_DIR = pj(os.getcwd(), \"GalfitModule\")\n",
    "        \n",
    "        if not exists(_MODULE_DIR):\n",
    "            raise Exception(\"Could not find GalfitModule!\")\n",
    "\n",
    "sys.path.append(_MODULE_DIR)\n",
    "\n",
    "from Functions.helper_functions import *\n",
    "from Classes.Components import *\n",
    "from Classes.Containers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c556ed-4bbf-4cc4-a519-a8eb6b401b08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HDU:\n",
    "    def __init__(self, \n",
    "                 name   = \"observation\",\n",
    "                 header = {}, \n",
    "                 data   = None):\n",
    "        self.name   = name\n",
    "        self.header = dict(header)\n",
    "        self.data   = data\n",
    "        \n",
    "    def to_dict(self):\n",
    "        return {\"name\"   : name,\n",
    "                \"header\" : header,\n",
    "                \"data\"   : data\n",
    "               }\n",
    "    \n",
    "    def __str__(self):\n",
    "        header_str = \"\"\n",
    "        for k,v in self.header.items():\n",
    "            header_str += f\"{k} = {v}\\n\"\n",
    "            \n",
    "        output_str = f\"{self.name}\\n{header_str}Img size: {np.shape(self.data)}\"\n",
    "        return output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a88fd3-05d5-43ce-8d6a-f977ce1bfca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FitsFile:\n",
    "    def __init__(self,\n",
    "                 filepath,\n",
    "                 name = \"observation\",\n",
    "                 wait = False,\n",
    "                 **kwargs\n",
    "                ):\n",
    "        \n",
    "        self.name     = name\n",
    "        self.filepath = filepath\n",
    "        \n",
    "        # Use split over rstrip in case a waveband designation is given\n",
    "        # (rstrip will remove any character that matches in the substring)\n",
    "        # i.e. 12345678910_g would lose the _g for \"_galfit_out.fits\"\n",
    "        # TODO: Replace rstrip with split in the rest of these scripts...\n",
    "        self.gname    = kwargs.get(\"gname\", os.path.basename(filepath).split(\"_galfit_out.fits\")[0])\n",
    "        # self.num_hdu  = 0\n",
    "        # self.num_imgs = 1\n",
    "        \n",
    "        assert os.path.splitext(filepath)[-1] == \".fits\", \"File being passed into FitsHandler must be .fits!\"\n",
    "        \n",
    "        try:\n",
    "            file_in = fits.open(filepath)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Can't open to read the file, {filepath}. Check name/permissions/directory.\")\n",
    "            raise(Exception()) \n",
    "\n",
    "        except OSError as ose:\n",
    "            print(f\"Something went wrong! {ose}\")\n",
    "            raise(Exception())\n",
    "        \n",
    "        # FITS starts the index at 0 but GALFIT outputs the observation image at 1\n",
    "        # Also converting the header to a dict to save some trouble\n",
    "        try:\n",
    "            self.header = dict(file_in[1].header)\n",
    "            self.data   = file_in[1].data\n",
    "            self.num_imgs = len(file_in) - 1\n",
    "        except IndexError:\n",
    "            self.header = dict(file_in[0].header)\n",
    "            self.data   = file_in[0].data\n",
    "            self.num_imgs = 1       \n",
    "        \n",
    "        hdu = HDU(name = name, header = self.header, data = self.data)\n",
    "        self.observation = hdu\n",
    "        \n",
    "        self.all_hdu  = {name : hdu}\n",
    "        self.file = file_in\n",
    "        \n",
    "        # Wait is for continuing to use the file in some other capacity\n",
    "        # i.e. for outputfits below to grab more info\n",
    "        if not wait:\n",
    "            file_in.close(verbose = True)\n",
    "        \n",
    "        #print(\"Did it close?\", file_in.closed)\n",
    "        # assert hdu_num == 4, \"File being passed into FitsHandler has too few output HDUs.\"\n",
    "# ==========================================================================================================\n",
    "\n",
    "    #def close(self):\n",
    "    #    self.file.close(verbose = True)\n",
    "    #    return\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Destructor for closing FITS files.\"\"\"\n",
    "        \n",
    "        for ext in self.file:\n",
    "            try:\n",
    "                del ext.data\n",
    "                del ext.header\n",
    "            except AttributeError as ae:\n",
    "                pass\n",
    "            gc.collect()\n",
    "\n",
    "        try:\n",
    "            self.file.close(verbose = True)\n",
    "        except Exception as ee:\n",
    "            print(f'Failed to close FITS instance for {self.gname}: {ee}')\n",
    "            print(\"May already be closed...\")\n",
    "\n",
    "# ==========================================================================================================\n",
    "\n",
    "    def to_png(self, cleanup = True, **kwargs): #tmp_fits_path = \"\", tmp_png_path = \"\", out_filename = \"\"):\n",
    "        \n",
    "        gname         = kwargs.get(\"gname\", self.gname)\n",
    "        \n",
    "        # TODO: BAD ASSUMPTION MOVING FORWARD\n",
    "        #tmp_fits_path = kwargs.get(\"tmp_fits_path\", self.filepath)\n",
    "        fits_path = kwargs.get(\"fits_path\", self.filepath)\n",
    "        # .../galfits -> galfit_png\n",
    "        #tmp_png_dir   = os.path.split(tmp_fits_path)[0].rstrip(\"s\") + \"_png\"\n",
    "        tmp_png_dir   = kwargs.get(\"tmp_png_dir\", \"./\")\n",
    "        tmp_png_path  = pj(tmp_png_dir, gname)\n",
    "        tmp_png_path  = kwargs.get(\"tmp_png_path\", tmp_png_path)\n",
    "        \n",
    "        out_png_dir   = kwargs.get(\"out_png_dir\", \"./\")\n",
    "        \n",
    "        capture_output = bool(kwargs.get(\"silent\", False))\n",
    "        \n",
    "        fitspng_param = \"0.25,1\" #1,150\"\n",
    "        \n",
    "        # run_fitspng from helper_functions, string path to fitspng program\n",
    "        fitspng_cmd1 = f\"{run_fitspng} -fr \\\"{fitspng_param}\\\" -o {tmp_png_path}.png {fits_path}[1]\"\n",
    "        \n",
    "        fitspng_cmd2 = f\"{run_fitspng} -fr \\\"{fitspng_param}\\\" -o {tmp_png_path}_out.png {fits_path}[2]\"\n",
    "        \n",
    "        fitspng_cmd3 = f\"{run_fitspng} -fr \\\"{fitspng_param}\\\" -o {tmp_png_path}_residual.png {fits_path}[3]\"\n",
    "        \n",
    "        cmds = [fitspng_cmd1, fitspng_cmd2, fitspng_cmd3]\n",
    "        \n",
    "        # sp is from helper_functions, subprocess.run call\n",
    "        for cmd in cmds[:self.num_imgs]:\n",
    "            # We must capture this call to check if the conversion worked\n",
    "            fitspng_out = sp(cmd, capture_output = True)\n",
    "            \n",
    "            if \"error\" in fitspng_out.stderr:\n",
    "                print(\"Skipping fitspng conversion... there is likely a library (libcfitsio) issue.\")\n",
    "                self.combined_png = \"\"\n",
    "                return\n",
    "        \n",
    "        im1 = f\"{tmp_png_path}.png\"\n",
    "        im2 = f\"{tmp_png_path}_out.png\"\n",
    "        im3 = f\"{tmp_png_path}_residual.png\"\n",
    "        \n",
    "        combined = \"\"\n",
    "        if self.num_imgs > 1:\n",
    "            combined = \"_combined\"\n",
    "        \n",
    "        # Adding 'magick' to use the portable version in the GalfitModule\n",
    "        montage_cmd = \"magick montage \" + \\\n",
    "                      \" \".join(im_cmd for idx, im_cmd in enumerate([im1, im2, im3]) \n",
    "                               if idx <= self.num_imgs)\n",
    "        \n",
    "        # Combining the images using ImageMagick\n",
    "        # If this is a single image, it'll also resize for me so that's why I leave it in\n",
    "        montage_cmd += f\" -tile {self.num_imgs}x1 -geometry \\\"175x175+2+0<\\\" \\\n",
    "                        {pj(out_png_dir, gname)}{combined}.png\"\n",
    "            \n",
    "        _ = sp(montage_cmd, capture_output = capture_output)\n",
    "        \n",
    "        if cleanup:\n",
    "            _ = sp(f\"rm {im1} {im2} {im3}\")\n",
    "        else:\n",
    "            self.observation_png = im1\n",
    "            self.model_png       = im2\n",
    "            self.residual_png    = im3            \n",
    "            \n",
    "        self.combined_png    = f\"{pj(out_png_dir, gname)}{combined}.png\"\n",
    "\n",
    "# ==========================================================================================================\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        \n",
    "        names = self.all_hdu.keys()\n",
    "        # Python doesn't care if they're different lengths but\n",
    "        # (for instance in the residual) we don't want to compare one to one\n",
    "        result = {k : a[k].data - b[k].data for k, a, b in zip(names, self.all_hdu, other.all_hdu)}\n",
    "        \n",
    "        return result\n",
    "\n",
    "# ==========================================================================================================\n",
    "\n",
    "    # # Use str to display feedme(?)\n",
    "    # def __str__(self):\n",
    "    #     pass\n",
    "        \n",
    "        #return output_str\n",
    "        \n",
    "# ==========================================================================================================\n",
    "\n",
    "    # Use str to display feedme(?)\n",
    "    def header_dict(self, name = \"\"):\n",
    "        \n",
    "        if name:\n",
    "            output_dict = dict(self.all_hdu[name].header)\n",
    "        else:\n",
    "            output_dict = {name : dict(hdu.header) for name, hdu in self.all_hdu.items()}\n",
    "            \n",
    "        return output_dict\n",
    "        \n",
    "# ==========================================================================================================\n",
    "\n",
    "    def update_params(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e7be94-ebe9-43ae-9a9b-420e9486299d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OutputFits(FitsFile):\n",
    "\n",
    "    def __init__(self, filepath, names = []):\n",
    "        \n",
    "        FitsFile.__init__(self, filepath = filepath, wait = True)\n",
    "        \n",
    "        # by initializing FitsFile we already have observation\n",
    "        if not names:\n",
    "            names = [\"model\", \"residual\"]\n",
    "            \n",
    "        # Don't need these but for posterity\n",
    "        # self.hdu_num  = 4\n",
    "        # self.num_imgs = self.hdu_num - 1\n",
    "        \n",
    "        # Exclude observation and primary HDU (0)\n",
    "        for num, name in zip(range(2, 4), names):\n",
    "            hdu = HDU(name, self.file[num].header, self.file[num].data)\n",
    "            self.all_hdu[name] = hdu\n",
    "            \n",
    "        # For convenience, we usually use the model here\n",
    "            \n",
    "        self.update_params(**self.all_hdu) \n",
    "        \n",
    "        # Dict is very redundant here but just for funsies\n",
    "        self.header = dict(self.model.header)\n",
    "        _header = GalfitHeader()\n",
    "        # Can call the helper directly since we're just using the header dict\n",
    "        _header.from_file_helper(self.header)\n",
    "        self.feedme = FeedmeContainer(path_to_feedme = filepath, header = _header)\n",
    "        self.feedme.from_file(self.header)\n",
    "        \n",
    "        self.data = self.model.data\n",
    "        \n",
    "        self.bulge_mask = np.ones(np.shape(self.model.data))\n",
    "        \n",
    "        self.close()\n",
    "        \n",
    "        # self.observation = self.all_hdu.get(\"observation\", None)\n",
    "        # self.model       = self.all_hdu.get(\"model\", None)\n",
    "        # self.residual    = self.all_hdu.get(\"residual\", None)\n",
    "        \n",
    "    def generate_bulge_mask(self, sparcfire_csv):\n",
    "        \n",
    "        # Thanks Azra!\n",
    "        bulge_mask = np.ones(np.shape(self.model.data))\n",
    "        try:\n",
    "            info = pd.read_csv(sparcfire_csv, dtype = str).dropna()\n",
    "        except FileNotFoundError as fe:\n",
    "            print(fe)\n",
    "            return bulge_mask\n",
    "        \n",
    "        if \"rejected\" in info[' fit_state']:\n",
    "            return bulge_mask\n",
    "            \n",
    "        try:\n",
    "            input_size = float(str(info[' iptSz'][0]).split()[0][1:])\n",
    "        except Exception as e:\n",
    "            print(f\"There is an issue determining the bulge mask for {self.gname}.\")\n",
    "            return bulge_mask\n",
    "        \n",
    "        bulge_rad  = float(info[' bulgeMajAxsLen'][0])\n",
    "        # In radians\n",
    "        bulge_angle = float(info[' bulgeMajAxsAngle'][0])\n",
    "        axis_ratio  = float(info[' bulgeAxisRatio'][0]) # Maj/minor\n",
    "        if axis_ratio < 0.5:\n",
    "            axis_ratio = 0.5\n",
    "        \n",
    "        # + 1 added for effect\n",
    "        major_rad = int(bulge_rad * len(self.model.data[0]) // input_size) + 1\n",
    "        minor_rad = int(major_rad/axis_ratio)\n",
    "\n",
    "        crop_box = self.feedme.header.region_to_fit\n",
    "        # To adjust for python indexing\n",
    "        xbox_min, ybox_min = crop_box[0] - 1, crop_box[2] - 1\n",
    "        \n",
    "        # Shifting everything to origin\n",
    "        center_x, center_y = np.array(self.feedme.bulge.position, dtype = int) - 1 -\\\n",
    "                             np.array((xbox_min, ybox_min), dtype = int)\n",
    "        \n",
    "        # center_x2, bulge_y2 = np.array(self.feedme.bulge.position, dtype = int) - \\\n",
    "        #                      np.array((xbox_min, ybox_min), dtype = int) + \\\n",
    "        #                      rad\n",
    "\n",
    "        #xx, yy = disk((center_x, center_y), major_rad)\n",
    "        try:\n",
    "            xx, yy = ellipse(center_x, center_y, major_rad, minor_rad, rotation = bulge_angle, shape = np.shape(self.model.data))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(self.gname)\n",
    "            print(center_x, center_y, major_rad, minor_rad, rotation)\n",
    "            return bulge_mask\n",
    "        \n",
    "        bulge_mask[xx, yy] = 0\n",
    "        self.bulge_mask = bulge_mask\n",
    "        \n",
    "#         temp = self.model.data\n",
    "#         plt.imshow(temp, origin = \"lower\")\n",
    "#         plt.show()\n",
    "        \n",
    "#         temp[xx, yy] = np.min(self.model.data[np.nonzero(self.model.data)])\n",
    "#         plt.imshow(temp, origin = \"lower\")\n",
    "#         plt.show()\n",
    "            \n",
    "        return bulge_mask\n",
    "        \n",
    "        \n",
    "    def generate_masked_residual(self, mask, use_bulge_mask = True, update_fits_header = True):\n",
    "\n",
    "        small_number = 1e-8\n",
    "        \n",
    "        crop_box = self.feedme.header.region_to_fit\n",
    "        # To adjust for python indexing\n",
    "        # Also, reminder, non-inclusive of end\n",
    "        xbox_min, xbox_max, ybox_min, ybox_max = crop_box[0] - 1, crop_box[1], crop_box[2] - 1, crop_box[3]\n",
    "\n",
    "        # To invert the matrix since galfit keeps 0 valued areas\n",
    "        crop_mask = 1\n",
    "        if mask is not None and np.any(mask.data):\n",
    "            crop_mask = 1 - mask.data[xbox_min:xbox_max, ybox_min:ybox_max]\n",
    "            \n",
    "        if use_bulge_mask:\n",
    "            feedme_dir, feedme_file = os.path.split(self.feedme.path_to_feedme)\n",
    "            \n",
    "            if exists(pj(feedme_dir, f\"{self.gname}.csv\")):\n",
    "                crop_mask *= self.generate_bulge_mask(pj(feedme_dir, f\"{self.gname}.csv\"))\n",
    "            else:\n",
    "                # REQUIRES GENERATE_BULGE_MASK TO BE RUN SEPARATE WITH CSV FILE SPECIFIED \n",
    "                try:\n",
    "                    crop_mask *= self.bulge_mask\n",
    "                except AttributeError:\n",
    "                    print(f\"Could not generate bulge mask for {self.gname}. Check location of csv or run generate_bulge_mask with a specified csv file.\")\n",
    "                except ValueError:\n",
    "                    print(f\"Could not generate bulge mask for {self.gname}. There may be an issue with sparcfire output (broadcast issue).\")\n",
    "        \n",
    "        try:\n",
    "            # compare to gaussian with same mean, std via kstest\n",
    "            # if p value high, not that different\n",
    "            \n",
    "            self.masked_residual = (self.observation.data - self.model.data)*crop_mask\n",
    "            exclude_masked_pixels = self.masked_residual[np.abs(self.masked_residual) > 0]\n",
    "            mean = np.mean(exclude_masked_pixels)\n",
    "            std  = np.std(exclude_masked_pixels)\n",
    "            gaussian  = norm.rvs(size = len(exclude_masked_pixels), loc = mean, scale = std, random_state = 0)\n",
    "            self.kstest = kstest(gaussian, exclude_masked_pixels.flatten())\n",
    "            pvalue = self.kstest.pvalue\n",
    "            statistic = self.kstest.statistic\n",
    "            # gaussian = norm.rvs(size = len(self.masked_residual)**2, loc = mean, scale = std, random_state = 0)\n",
    "            # noised_masked_pixels = np.where(np.abs(self.masked_residual.flatten()) > 0, self.masked_residual.flatten(), gaussian)\n",
    "            # self.kstest = kstest(gaussian, noised_masked_pixels)\n",
    "\n",
    "            self.norm_observation = slg.norm(crop_mask*self.observation.data)\n",
    "            self.norm_model = slg.norm(crop_mask*self.model.data)\n",
    "            self.norm_residual = slg.norm(crop_mask*self.residual.data)\n",
    "            self.masked_residual_normalized = self.masked_residual/min(self.norm_observation, self.norm_model)\n",
    "            \n",
    "#             obs_model = 1 - np.divide(\n",
    "#                                 crop_mask*self.observation.data/self.norm_observation, \n",
    "#                                 crop_mask*self.model.data/self.norm_model + small_number\n",
    "#                                      )\n",
    "\n",
    "#             model_obs = 1 - np.divide( \n",
    "#                                 crop_mask*self.model.data/self.norm_model,\n",
    "#                                 crop_mask*self.observation.data/self.norm_observation + small_number\n",
    "#                                     )\n",
    "            # Replace negative values with 1 - reciprocal\n",
    "#            self.masked_residual_ratio = np.where(obs_model >= 0, obs_model, model_obs)\n",
    "            # Masked residual normalized\n",
    "            # I seem to use this acronym a lot\n",
    "            self.nmr  = slg.norm(self.masked_residual_normalized)\n",
    "#            self.nmrr = slg.norm(self.masked_residual_ratio)\n",
    "\n",
    "            if update_fits_header:\n",
    "                with fits.open(self.filepath, mode='update', output_verify='ignore') as hdul:\n",
    "                    hdul[2].header[\"NMR\"] = (round(self.nmr, 4), \"Norm of the masked residual\")\n",
    "\n",
    "                    # pvalue is sometimes none but round can't handle it\n",
    "                    if pvalue and statistic:\n",
    "                        hdul[2].header[\"ks_p\"]    = (round(pvalue, 4), \"p value of kstest vs noise\")\n",
    "                        hdul[2].header[\"ks_stat\"] = (round(statistic, 4), \"statistic value of kstest vs noise\")\n",
    "                    else:\n",
    "                        hdul[2].header[\"ks_p\"]    = (None, \"p value of kstest vs noise\")\n",
    "                        hdul[2].header[\"ks_stat\"] = (None, \"statistic value of kstest vs noise\")\n",
    "\n",
    "        except ValueError:\n",
    "            print(f\"There may be a broadcast issue, observation, model, crop mask: \", end = \"\")\n",
    "            print(f\"{np.shape(self.observation.data)}, {np.shape(self.model.data)}, {np.shape(crop_mask)}\")\n",
    "            # print(np.shape(mask_fits_file.data))\n",
    "            # print(np.shape(fits_file.data))\n",
    "            # print(crop_box)\n",
    "            return None\n",
    "        \n",
    "        return self.masked_residual_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75833ee7-fa48-45cd-a4e5-8ce1467453e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from RegTest.RegTest import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35a54d6-6188-4e98-8f94-eb8c42e8123a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing from_file\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    gname = \"1237671124296532233\"\n",
    "    obs   = pj(TEST_DATA_DIR, \"test-in\", f\"{gname}.fits\")\n",
    "    model = pj(TEST_DATA_DIR, \"test-out\", gname, f\"{gname}_galfit_out.fits\")\n",
    "    mask  = pj(TEST_DATA_DIR, \"test-out\", gname, f\"{gname}_star-rm.fits\")\n",
    "    \n",
    "    test_obs   = FitsFile(obs)\n",
    "    test_model = OutputFits(model)\n",
    "    test_mask  = FitsFile(mask)\n",
    "    \n",
    "    print(test_obs.observation)\n",
    "    print()\n",
    "    print(test_model.feedme)\n",
    "    print()\n",
    "    print(test_model.model)\n",
    "    \n",
    "    # Purposefully do not fill in some of the header parameters\n",
    "    # since those do not exist in the output FITS header\n",
    "    # This is done to remind the user/programmer that the \n",
    "    # OutputFits object only serves to represent the header\n",
    "    # nothing more, nothing less and so also reminds them to\n",
    "    # use a different method to fill in the header.\n",
    "    #print(test_model.feedme.header)\n",
    "    \n",
    "#     _header = GalfitHeader()\n",
    "#     _header.from_file_helper(test_out.header)\n",
    "    \n",
    "#     crop_box = _header.region_to_fit\n",
    "#     # To adjust for python indexing\n",
    "#     box_min, box_max = crop_box[0] - 1, crop_box[1]\n",
    "        \n",
    "#     print(np.shape(test_in.data[box_min:box_max, box_min:box_max]))\n",
    "    print(\"\\nThese should all be the same .\")\n",
    "    print(np.shape(test_model.observation.data))\n",
    "    print(np.shape(test_model.data))\n",
    "    print(np.shape(test_model.residual.data))\n",
    "    crop_box = test_model.feedme.header.region_to_fit\n",
    "    # + 1 to account for python indexing\n",
    "    crop_rad = crop_box[1] - crop_box[0] + 1\n",
    "    print(f\"({crop_rad}, {crop_rad})\")\n",
    "    print(\"Andddd pre crop\")\n",
    "    print(np.shape(test_obs.observation.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c03ef5-731d-4284-9d4b-52c4f50e818e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Unit test to check value of masked residual\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Turn off updating FITS header to avoid modifying test data\n",
    "    print(\"No bulge mask\")\n",
    "    _ = test_model.generate_masked_residual(test_mask, use_bulge_mask = False, update_fits_header = False)\n",
    "    print(f\"Norm of the observation: {test_model.norm_observation:.4f}\")\n",
    "    print(f\"Norm of the model: {test_model.norm_model:.4f}\")\n",
    "    print(f\"Norm of the residual: {test_model.norm_residual:.4f}\")\n",
    "    print(f\"Norm of the masked residual: {test_model.nmr:.4f}\")\n",
    "    #print(f\"Norm of the masked residual ratio: {test_model.nmrr:.8f}\")\n",
    "    print(f\"kstest p value: {test_model.kstest.pvalue:.4f}\")\n",
    "    print(f\"kstest statistic: {test_model.kstest.statistic:.4f}\")\n",
    "    \n",
    "    print(\"\\nNow with bulge mask\")\n",
    "    _ = test_model.generate_masked_residual(test_mask, update_fits_header = False)\n",
    "    print(f\"Norm of the observation: {test_model.norm_observation:.4f}\")\n",
    "    print(f\"Norm of the model: {test_model.norm_model:.4f}\")\n",
    "    print(f\"Norm of the residual: {test_model.norm_residual:.4f}\")\n",
    "    print(f\"Norm of the masked residual: {test_model.nmr:.4f}\")\n",
    "    #print(f\"Norm of the masked residual ratio: {test_model.nmrr:.8f}\")\n",
    "    print(f\"kstest p value: {test_model.kstest.pvalue:.4f}\")\n",
    "    print(f\"kstest statistic: {test_model.kstest.statistic:.4f}\")\n",
    "    #print(np.min(test_model.observation.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097ac095-8233-4498-a09f-8824a82fd9c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = pj(TEST_OUTPUT_DIR, \"test-out\", gname, f\"{gname}_galfit_out.fits\")\n",
    "    \n",
    "    if exists(model):\n",
    "        test_model = OutputFits(model)\n",
    "        print(\"Checking FITS header update with NMR\")\n",
    "        print(\"These may be different from the values above.\")\n",
    "\n",
    "        _ = test_model.generate_masked_residual(test_mask)\n",
    "        test_model = OutputFits(model)\n",
    "\n",
    "        print(f\"Norm of the masked residual: {test_model.header['NMR']:.4f}\")\n",
    "        print(f\"kstest p value: {test_model.header['KS_P']:.4f}\")\n",
    "        print(f\"kstest statistic: { test_model.header['KS_STAT']:.4f}\")\n",
    "    else:\n",
    "        print(f\"{model} doesn't exist, cannot test updating FITS header with NMR, and KStest values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7af0c62-fbe9-4f59-9d44-bc769ce837fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    export_to_py(\"FitsHandlers\", pj(_MODULE_DIR, \"Classes\", \"FitsHandlers\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
