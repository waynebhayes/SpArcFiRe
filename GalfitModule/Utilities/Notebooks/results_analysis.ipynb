{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c4247750-5fc9-4be0-8102-06041cdb7c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --user astropy\n",
    "#!pip3 install --user kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "58b85295-242d-405b-ba3a-260bf8f72535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy as ap\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "import scipy.linalg as slg\n",
    "from scipy.stats import norm, pearsonr\n",
    "#import scipy.stats\n",
    "from math import ceil\n",
    "import csv\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import iplot\n",
    "import kaleido\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.colors as colors\n",
    "# from matplotlib.colors import LinearSegmentedColormap\n",
    "import glob\n",
    "import os\n",
    "# These are in Functions\n",
    "from os.path import join as pj\n",
    "from os.path import exists # as pj\n",
    "# from os.path import abspath as absp\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import PIL\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "from collections import namedtuple as nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "2a7e0271-d54c-42e1-a9e5-9527b166c8d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"SPARCFIRE_HOME\"] = \"/home/portmanm/sparcfire_matt/\"\n",
    "\n",
    "_HOME_DIR = os.path.expanduser(\"~\")\n",
    "try:\n",
    "    _SPARCFIRE_DIR = os.environ[\"SPARCFIRE_HOME\"]\n",
    "    _MODULE_DIR = pj(_SPARCFIRE_DIR, \"GalfitModule\")\n",
    "except KeyError:\n",
    "    if __name__ == \"__main__\":\n",
    "        print(\"SPARCFIRE_HOME is not set. Please run 'setup.bash' inside SpArcFiRe directory if not done so already.\")\n",
    "        print(\"Checking the current directory for GalfitModule, otherwise quitting.\")\n",
    "            \n",
    "        _MODULE_DIR = pj(os.getcwd(), \"GalfitModule\")\n",
    "        \n",
    "        if not exists(_MODULE_DIR):\n",
    "            raise Exception(\"Could not find GalfitModule!\")\n",
    "    \n",
    "sys.path.append(_MODULE_DIR)\n",
    "from Classes.Components import *\n",
    "from Classes.Containers import *\n",
    "from Classes.FitsHandlers import *\n",
    "from Functions.helper_functions import *\n",
    "\n",
    "all_results_nt = nt(\"all_results\", [\"full_df\", \"success_df\", \"not_success_df\", \"by_eye_success_df\", \"by_eye_not_success_df\"])\n",
    "combined_results_nt = nt(\"combined_results\", [\"bool_df\", \"full_df\", \"success_df\", \"by_eye_success_df\"])\n",
    "mini_sep    = \"\\n\" + 40*\"=\" + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "de93171e-4ad6-4e16-acd3-8c302cb5d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Defunct\n",
    "# def check_galfit_chi(gal_name, base_path):\n",
    "#     # An example line\n",
    "#     # # Chi^2/nu = 4.661,  Chi^2 = 12025.575,  Ndof = 2580\n",
    "    \n",
    "#     #galfit_txt_out = \"galfit.01\" # in the future galfit.01 may change\n",
    "#     filename = os.path.join(base_path, gal_name, galfit_txt_out)\n",
    "#     with open(filename, \"r\") as f:\n",
    "#         for line in f:\n",
    "#             if \"Chi\" in line:\n",
    "#                 chi_line = line.strip(\"# \")\n",
    "    \n",
    "#     # This also works but it's quite devious...\n",
    "#     # chi_line.replace(\"^\", \"\").replace(\"/\", \"_\").replace(\",  \", \"\\n\").lower()\n",
    "#     # exec(chi_line)\n",
    "    \n",
    "#     out_vals = chi_line.split(\",\")\n",
    "#     chi2_nu = float(out_vals[0].strip().split(\"=\")[-1])\n",
    "#     chi2 = float(out_vals[1].strip().split(\"=\")[-1])\n",
    "#     ndof = int(out_vals[2].strip().split(\"=\")[-1])\n",
    "    \n",
    "#     return chi2_nu, chi2, ndof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "47be9c91-a9a6-4971-b9d2-3be76d4b9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_galaxies(in_dir = \"sparcfire-in\", out_dir = \"sparcfire-out\"):   \n",
    "    all_gnames_in  = find_files(in_dir, \"123*\", \"f\")\n",
    "    all_gnames_out = find_files(out_dir, \"123*\", \"d\")\n",
    "    total_galaxies = min(len(all_gnames_in), len(all_gnames_out))\n",
    "    if not total_galaxies:\n",
    "        total_galaxies  = max(len(all_gnames_in), len(all_gnames_out))\n",
    "        \n",
    "    return total_galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ee884139-38d5-41a0-8415-78651519848c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_residual_df(\n",
    "    out_dir, \n",
    "    basename,\n",
    "    **kwargs\n",
    "):\n",
    "    \n",
    "    method              = kwargs.get(\"method\", \"nmr_x_1-p\")\n",
    "    verbose             = kwargs.get(\"verbose\", True)\n",
    "    residual_cutoff_val = kwargs.get(\"residual_cutoff_val\", 0.007)\n",
    "    \n",
    "    pickle_filename = pj(out_dir, basename, sorted(find_files(pj(out_dir, basename), f'{basename}_output_results*.pkl', \"f\"))[-1])\n",
    "    \n",
    "    residual_df  = pd.read_pickle(pickle_filename)\n",
    "    # temp_df = deepcopy(residual_df)\n",
    "    # Setting residual columns\n",
    "    #residual_df[\"KS_P\"] = 1 - residual_df[\"KS_P\"]\n",
    "    if method == \"nmr_x_1-p\":\n",
    "        result_of_method = (1 - residual_df[\"KS_P\"])*residual_df[\"NMR\"]\n",
    "    elif method == \"nmr_neg_log\":\n",
    "        result_of_method = residual_df[\"NMR\"]/-np.log(residual_df[\"KS_P\"] + 1e-10)\n",
    "    elif method == \"W_quality\":\n",
    "        result_of_method = residual_df[\"KS_P\"]/residual_df[\"W_NMR\"]\n",
    "    else:\n",
    "        raise Exception(f\"Method given: {method} is not a valid method (yet).\")\n",
    "    \n",
    "    residual_df[method] = result_of_method\n",
    "    \n",
    "    # Valid meaning NMR was successfully calculated\n",
    "    #cols_to_drop = [col for col in residual_df.columns if col.endswith(\"_sky_2\")]\n",
    "    #valid_spiral_df = residual_df.drop(columns = cols_to_drop).dropna()\n",
    "\n",
    "    # rename sky_2 to sky_3 for non-spirals to be inline with everything else\n",
    "    # this would be for potential comparison down the line\n",
    "    cols_to_merge = [col for col in residual_df.columns if col.endswith(\"_sky_3\") or col.endswith(\"_sky_4\")]\n",
    "    #_ = [residual_df[col].fillna(residual_df[f\"{col[:-1]}2\"], inplace = True) for col in cols_to_merge]\n",
    "    cols_to_drop  = [col for col in residual_df.columns if col.endswith(\"_sky_2\") or col.endswith(\"_sky_3\")]#  + [\"KS_STAT\"]\n",
    "    residual_df.drop(columns = cols_to_drop, inplace = True)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"{len(residual_df)} galaxy models generated.\")\n",
    "        residual_cutoff = residual_df[method] <= residual_cutoff_val\n",
    "        print(f\"{sum(residual_cutoff)} models pass score cutoff.\")\n",
    "        \n",
    "    \n",
    "    return residual_df.sort_values(by = method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0f5cd1a4-3cf8-4c58-9178-ce87b4cd9278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_galaxy_csv(out_dir, basename, pre_post):\n",
    "    \n",
    "    field = \" pa_alenWtd_avg_domChiralityOnly\"\n",
    "    # {basename}_ uneccessary because different *galfit* runs \n",
    "    # should have same sparcfire output\n",
    "    fname = pj(out_dir, basename, f\"{basename}_{pre_post}_galfit_galaxy.csv\")\n",
    "    sparc_output_csv = pd.read_csv(fname, #pj(out_dir, f\"pre_galfit_galaxy.csv\"),\n",
    "                                       index_col = \"name\",\n",
    "                                       on_bad_lines = \"warn\",\n",
    "                                       usecols   = [\"name\", field], # , \" iptSz\"],\n",
    "                                       #na_values = \"NaN\",\n",
    "                                       #dtype     = {field : float} #, \" iptSz\" : str}#, \"name\" : str}\n",
    "                                      )#.loc[:, field]\n",
    "    #sparc_output_csv.index.name = None\n",
    "    sparc_output_csv[field] = sparc_output_csv[field].astype(float)\n",
    "    sparc_output_csv.index  = sparc_output_csv.index.map(str)\n",
    "    #sparc_output_csv[\" iptSz\"] = sparc_output_csv[\" iptSz\"].str.extract(r\"([0-9]+)\").astype(float)\n",
    "\n",
    "    #sparc_output_csv[\"pre_sign\"] = np.sign(sparc_output_csv[field])\n",
    "    sparc_output_csv.rename(columns = {field : f\"galaxy_{pre_post}_pa\"}, inplace = True)\n",
    "    \n",
    "    return sparc_output_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7a5e2491-9d83-4573-8826-ba9d91f5b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_galaxy_arcs_csv(out_dir, basename, pre_post, **kwargs):\n",
    "    \n",
    "    field_pa   = kwargs.get(\"field_pa\"  , \"pitch_angle\")\n",
    "    field_alen = kwargs.get(\"field_alen\", \"arc_length\")\n",
    "    name_col   = kwargs.get(\"name_col\"  , \"gxyName\")\n",
    "\n",
    "    fname = pj(out_dir, basename, f\"{basename}_{pre_post}_galfit_galaxy_arcs.csv\")\n",
    "    sparc_output_arcs_csv = pd.read_csv(fname, \n",
    "                                       index_col = name_col,\n",
    "                                       usecols   = [name_col, field_pa, field_alen],\n",
    "                                       dtype     = {field_pa : float, field_alen : float} #, name_col : str}\n",
    "                                      )#.loc[:, field]\n",
    "    #sparc_output_csv.index.name = None\n",
    "    sparc_output_arcs_csv.index = sparc_output_arcs_csv.index.map(str)\n",
    "\n",
    "    # Filtering for pure circles and near circles\n",
    "    sparc_output_arcs_csv = sparc_output_arcs_csv[abs(sparc_output_arcs_csv[field_pa ]) > 1]\n",
    "\n",
    "    #sparc_output_arcs_csv = pd.concat([sparc_output_arcs_csv, pre_sparc_output_csv], axis = 1)\n",
    "    #sparc_output_arcs_csv[\"sign\"] = np.sign(sparc_output_arcs_csv[field])\n",
    "\n",
    "    # Keeps only arms which align with dom chirality only\n",
    "    # sparc_output_arcs_csv[\"check\"] = [\n",
    "    #     row[\"sign\"] + pre_sparc_output_csv.loc[i, \"pre_sign\"] \n",
    "    #     if i in pre_sparc_output_csv.index \n",
    "    #     else None \n",
    "    #     for i, row in sparc_output_arcs_csv.iterrows()\n",
    "    # ]\n",
    "\n",
    "    #sparc_output_arcs_csv = sparc_output_arcs_csv[abs(sparc_output_arcs_csv.loc[:, \"check\"]) == 2].drop(columns = [\"sign\", \"check\"])\n",
    "    sparc_output_arcs_top3 = sparc_output_arcs_csv.groupby(name_col).head(3).reset_index()\n",
    "    sparc_output_arcs_top3[f\"{pre_post}_sign\"] = np.sign(sparc_output_arcs_top3.pitch_angle)\n",
    "\n",
    "    dom_sign = np.sign(sparc_output_arcs_top3.groupby(name_col).sum()[f\"{pre_post}_sign\"])\n",
    "    sparc_output_arcs_top3 = sparc_output_arcs_top3.join(dom_sign, rsuffix = \"_dom\", on = name_col)\n",
    "\n",
    "    cond = sparc_output_arcs_top3[f\"{pre_post}_sign_dom\"] == sparc_output_arcs_top3[f\"{pre_post}_sign\"]\n",
    "    sparc_output_arcs_top2 = sparc_output_arcs_top3[cond].groupby(name_col).head(2).reset_index().drop(columns = [f\"{pre_post}_sign_dom\", \"index\"])\n",
    "\n",
    "    #pre_sparc_output_top2.rename(columns = {field : \"pre_pa\"}, inplace = True)\n",
    "    #pre_sparc_output_csv.dropna(inplace=True)\n",
    "    return sparc_output_arcs_top2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "cc9d4a2f-ad1d-465a-9de9-dab0ffec7ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_arcs_output(sparc_output_arcs_top2, pre_post, **kwargs):\n",
    "    \n",
    "    field_pa   = kwargs.get(\"field_pa\"  , \"pitch_angle\")\n",
    "    field_alen = kwargs.get(\"field_alen\", \"arc_length\")\n",
    "    name_col   = kwargs.get(\"name_col\"  , \"gxyName\")\n",
    "    \n",
    "    single_arm = sparc_output_arcs_top2[~sparc_output_arcs_top2.duplicated(name_col, keep = False)]\n",
    "    single_arm.loc[:, field_pa] = 0\n",
    "    #single_arm.loc[:, \"arc_length\"]  = 0\n",
    "\n",
    "    filled_in = pd.concat([sparc_output_arcs_top2, single_arm], ignore_index = True)\n",
    "    str_fill = [f\"{pre_post}_pa1\", f\"{pre_post}_pa2\"] * (len(filled_in) // 2)\n",
    "    filled_in[\"temp1\"] = str_fill\n",
    "\n",
    "    str_fill = [f\"{pre_post}_alen1\", f\"{pre_post}_alen2\"] * (len(filled_in) // 2)\n",
    "    filled_in[\"temp2\"] = str_fill\n",
    "\n",
    "    #filled_in = filled_in.reset_index().drop(columns = [\"index\"])\n",
    "    sp_out = filled_in.pivot_table(index = name_col, columns = [\"temp1\", \"temp2\"], values = [field_pa, field_alen])\n",
    "\n",
    "    sp_out = sp_out.droplevel(0, axis = 1).droplevel(0, axis = 1)\n",
    "    sp_out.columns = [f'{pre_post}_alen1', f'{pre_post}_alen2', f'{pre_post}_pa1', f'{pre_post}_pa2']\n",
    "    \n",
    "    return sp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "07dbb8f0-f2fd-4c0e-a3cd-76597837bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def before_after_galfit_comparison(all_sparc_out, pre_sparc_output_csv, post_sparc_output_csv):\n",
    "    \n",
    "    before_after_galfit_df = deepcopy(all_sparc_out)#.dropna() #full_df.dropna(subset = [\"post_pa\"])\n",
    "    #before_after_galfit_df = before_after_galfit_df[np.sign(before_after_galfit_df.loc[:, \"pre_pa\"]) != np.sign(before_after_galfit_df.loc[:, \"post_pa\"])]\n",
    "\n",
    "    before_after_galfit_df[\"chiral_agreement\"] = np.sign(before_after_galfit_df[\"pre_pa1\"]) == np.sign(before_after_galfit_df[\"post_pa1\"])\n",
    "\n",
    "    before_after_galfit_df[\"pre_pa1\"]  = abs(before_after_galfit_df[\"pre_pa1\"])\n",
    "    before_after_galfit_df[\"pre_pa2\"]  = abs(before_after_galfit_df[\"pre_pa2\"])\n",
    "    before_after_galfit_df[\"post_pa1\"] = abs(before_after_galfit_df[\"post_pa1\"])\n",
    "    before_after_galfit_df[\"post_pa2\"] = abs(before_after_galfit_df[\"post_pa2\"])\n",
    "\n",
    "\n",
    "    before_after_galfit_df[\"1-1\"] = abs(before_after_galfit_df[\"pre_pa1\"] - before_after_galfit_df[\"post_pa1\"])\n",
    "    before_after_galfit_df[\"2-2\"] = abs(before_after_galfit_df[\"pre_pa2\"] - before_after_galfit_df[\"post_pa2\"])\n",
    "    before_after_galfit_df[\"1-2\"] = abs(before_after_galfit_df[\"pre_pa1\"] - before_after_galfit_df[\"post_pa2\"])\n",
    "    before_after_galfit_df[\"2-1\"] = abs(before_after_galfit_df[\"pre_pa2\"] - before_after_galfit_df[\"post_pa1\"])\n",
    "\n",
    "    before_after_galfit_df[\"mean-1122\"]  = before_after_galfit_df[[\"1-1\",\"2-2\"]].mean(axis = \"columns\")\n",
    "    before_after_galfit_df[\"mean-1221\"]  = before_after_galfit_df[[\"1-2\",\"2-1\"]].mean(axis = \"columns\")\n",
    "\n",
    "    before_after_galfit_df[\"min_diff\"]   = before_after_galfit_df[[\"mean-1122\", \"mean-1221\"]].min(axis = 1)\n",
    "\n",
    "    before_after_galfit_df[\"best_diffs\"] = [\n",
    "        (row[\"1-1\"], row[\"2-2\"]) if np.mean((row[\"1-1\"], row[\"2-2\"])) == row[\"min_diff\"] \n",
    "        else (row[\"1-2\"], row[\"2-1\"]) \n",
    "        for _, row in before_after_galfit_df.iterrows()\n",
    "    ]\n",
    "\n",
    "    before_after_galfit_df[\"pa_diff1\"], before_after_galfit_df[\"pa_diff2\"] = zip(*before_after_galfit_df[\"best_diffs\"])\n",
    "    #before_after_galfit_df[\"best_diff2\"] = [row[\"2-2\"] if np.mean((row[\"1-1\"], row[\"2-2\"])) == row[\"min_diff\"] else row[\"2-1\"] for _, row in before_after_galfit_df.iterrows()]\n",
    "    before_after_galfit_df[\"pa_diff_galaxy\"] = abs(abs(post_sparc_output_csv[\"galaxy_post_pa\"]) - abs(pre_sparc_output_csv[\"galaxy_pre_pa\"]))# < 15\n",
    "\n",
    "    # min(2_arm_length)/max(2_arm_length) > 0.7, verify that this is valid by eye\n",
    "    #before_after_galfit_df[\"alen_ratio\"] = post_sparc_output_csv[\" iptSz\"]*before_after_galfit_df[[\"pre_alen1\", \"pre_alen2\"]].min(axis = 1)/(pre_sparc_output_csv[\" iptSz\"]*before_after_galfit_df[[\"post_alen1\", \"post_alen2\"]].max(axis = 1))\n",
    "    before_after_galfit_df[\"alen_ratio\"] = before_after_galfit_df[[\"post_alen1\", \"post_alen2\"]].min(axis = 1)/before_after_galfit_df[[\"post_alen1\", \"post_alen2\"]].max(axis = 1)\n",
    "    #before_after_galfit_df.drop(columns = [\"pre_sign\", \"post_sign\"], inplace = True)\n",
    "\n",
    "    # before_after_galfit_df.loc[:, \"within_15_degrees_pre\"]  = before_after_galfit_df.loc[:, \"diff_pre\"] < 15\n",
    "    # before_after_galfit_df.loc[:, \"within_15_degrees_post\"] = before_after_galfit_df.loc[:, \"diff_post\"] < 15\n",
    "    #before_after_galfit_df.sort_values(by = [\"post_pa\"])\n",
    "    before_after_galfit_df = before_after_galfit_df.drop(columns = before_after_galfit_df.columns[9:-4])\n",
    "    \n",
    "    return before_after_galfit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "16e8bd45-f542-48a8-8923-1e07f5cbb9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_everything(residual_df, before_after_galfit_df, method):\n",
    "    full_df = residual_df.join(before_after_galfit_df)\n",
    "    full_df = full_df[full_df.index.notnull()].sort_values(by = method)\n",
    "\n",
    "    #full_df.dropna(subset = [\"pa_diff1\", \"pa_diff2\", \"pa_diff_galaxy\"], how = \"all\", inplace = True)\n",
    "    #full_df.fillna(subset = [\"pa_diff1\", \"pa_diff2\", \"pa_diff_galaxy\"], how = \"all\", inplace = True)\n",
    "    full_df[\"min_pa_diff\"] = full_df[[\"pa_diff1\", \"pa_diff2\", \"pa_diff_galaxy\"]].min(axis = 1)\n",
    "    \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "850f1b7e-eb54-45d1-b759-dbfffc197ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_success(\n",
    "    full_df, \n",
    "    **kwargs\n",
    "):\n",
    "    \n",
    "    in_dir                = kwargs.get(\"in_dir\", \"sparcfire-in\") \n",
    "    out_dir               = kwargs.get(\"out_dir\",\"sparcfire-out\")\n",
    "    sparcfire_processed   = kwargs.get(\"sparcfire_processed\", None)\n",
    "    flip_chiral_agreement = kwargs.get(\"flip_chiral_agreement\", False)\n",
    "    residual_cutoff_val   = kwargs.get(\"residual_cutoff_val\", 0.007)\n",
    "    pa_cutoff_val         = kwargs.get(\"pa_cutoff_val\", 10)\n",
    "    alen_cutoff_val       = kwargs.get(\"alen_cutoff_val\", 0.5)\n",
    "    verbose               = kwargs.get(\"verbose\", True)\n",
    "    \n",
    "    residual_cutoff = full_df[\"nmr_x_1-p\"] <= residual_cutoff_val\n",
    "    #pa_cutoff = (full_df[\"pa_diff1\"] < 10) | (full_df[\"pa_diff2\"] < 10)\n",
    "    pa_cutoff   = full_df[\"min_pa_diff\"] < pa_cutoff_val\n",
    "    alen_cutoff = full_df[\"alen_ratio\"] > alen_cutoff_val #[True]\n",
    "    sign_cutoff = full_df[\"chiral_agreement\"].astype(bool)\n",
    "    if flip_chiral_agreement:\n",
    "        sign_cutoff = ~sign_cutoff\n",
    "\n",
    "    success_df     = full_df[residual_cutoff & pa_cutoff & alen_cutoff & sign_cutoff]\n",
    "    not_success_df = full_df[~(residual_cutoff & pa_cutoff & alen_cutoff & sign_cutoff)]\n",
    "    \n",
    "    if verbose:\n",
    "        # print(f\"{len(full_df)} processed by sparcfire\")\n",
    "        # print(f\"{sum(residual_cutoff)} pass score cutoff\")\n",
    "        print(f\"{sum(pa_cutoff)} pass pitch angle cutoff\")\n",
    "        print(f\"{sum(alen_cutoff)} pass arm length ratio cutoff\")\n",
    "        print(f\"{sum(sign_cutoff)} pass chiral agreement\")\n",
    "        print(f\"{len(success_df)} or {100*len(success_df)/len(full_df):.2f}% ({len(success_df)}/{len(full_df)}) succeed by SpArcFiRe+Score\")\n",
    "        if sparcfire_processed is not None:\n",
    "            sparcfire_processed = full_df.dropna(subset = [\"pa_diff1\", \"pa_diff2\", \"pa_diff_galaxy\"], how = \"all\")\n",
    "        \n",
    "        print(f\"{total_galaxies - len(sparcfire_processed)}/{total_galaxies} models failed reprocessing by SpArcFiRe\")\n",
    "        \n",
    "        #print(f\"Total success less 24% false positive -- {len(success_df)*.76:.0f}\")\n",
    "        #print(f\"Total success less 24% false positive + 24% false negative -- {len(not_success_df)*0.24+len(success_df)*.76:.0f}\")\n",
    "        #print(f\"Estimated total success % -- {100*(len(not_success_df)*0.24+len(success_df)*.76)/len(full_df):.0f}%\")\n",
    "    \n",
    "    # cutoffs = {\n",
    "    #     \"residual_cutoff\" : residual_cutoff, \n",
    "    #     \"pa_cutoff\"       : pa_cutoff, \n",
    "    #     \"alen_cutoff\"     : alen_cutoff, \n",
    "    #     \"sign_cutoff\"     : sign_cutoff\n",
    "    # }\n",
    "    return success_df, not_success_df # , cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "28a24bed-8970-4c51-b8a9-83d51e80bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_by_eye_data(\n",
    "    out_dir, \n",
    "    basename, \n",
    "    residual_df, \n",
    "    full_df,\n",
    "    **kwargs\n",
    "):\n",
    "    \n",
    "    sparcfire_processed = kwargs.get(\"sparcfire_processed\", None)\n",
    "    subset              = kwargs.get(\"subset\", None)\n",
    "    verbose             = kwargs.get(\"verbose\", True)\n",
    "    \n",
    "    with open(f\"{pj(out_dir, basename, basename)}_by-eye_success.txt\", \"r\") as f:\n",
    "        raw_by_eye_success_galaxies = [i.split(\"_\")[0].strip() for i in f.readlines()]\n",
    "\n",
    "    with open(f\"{pj(out_dir, basename, basename)}_by-eye_not_success.txt\", \"r\") as f:\n",
    "        raw_by_eye_not_success_galaxies = [i.split(\"_\")[0].strip() for i in f.readlines()]\n",
    "        \n",
    "    by_eye_success_galaxies = [i for i in raw_by_eye_success_galaxies if i in full_df.index]\n",
    "    by_eye_not_success_galaxies = [i for i in raw_by_eye_not_success_galaxies if i in full_df.index]\n",
    "    if sparcfire_processed is not None:\n",
    "        sparcfire_processed = full_df.dropna(subset = [\"pa_diff1\", \"pa_diff2\", \"pa_diff_galaxy\"], how = \"all\")\n",
    "    \n",
    "    if verbose:\n",
    "        total = len(residual_df)\n",
    "        if subset:\n",
    "            total = subset\n",
    "            print(f\"Working on a subset of {total} galaxies\")\n",
    "            \n",
    "        align = len(f\"{len(by_eye_success_galaxies)}/{len(raw_by_eye_success_galaxies)}\")\n",
    "        print(f\"Number of *total* by eye successful galaxies\")\n",
    "        print(f\"{len(raw_by_eye_success_galaxies):<{align}} => {len(raw_by_eye_success_galaxies)/total*100:.2f}%\")\n",
    "        print(f\"Number of by eye successful galaxies that SpArcFiRe *could* process\")\n",
    "        by_eye_processed = [i for i in sparcfire_processed.index if i in raw_by_eye_success_galaxies]\n",
    "        print(f\"{len(by_eye_processed)}/{len(raw_by_eye_success_galaxies)} => {len(by_eye_processed)/len(raw_by_eye_success_galaxies)*100:.2f}%\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        align = len(f\"{len(by_eye_not_success_galaxies)}/{len(raw_by_eye_not_success_galaxies)}\")\n",
    "        print(f\"Number of *total* by eye not successful galaxies\")\n",
    "        print(f\"{len(raw_by_eye_not_success_galaxies):<{align}} => {len(raw_by_eye_not_success_galaxies)/total*100:.2f}%\")\n",
    "        \n",
    "        print(f\"Number of by eye not successful galaxies that SpArcFiRe *could* process\")\n",
    "        by_eye_processed = [i for i in sparcfire_processed.index if i in raw_by_eye_not_success_galaxies]\n",
    "        print(f\"{len(by_eye_processed)}/{len(raw_by_eye_not_success_galaxies)} => {len(by_eye_processed)/len(raw_by_eye_not_success_galaxies)*100:.2f}%\")\n",
    "    \n",
    "    return by_eye_success_galaxies, by_eye_not_success_galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f49f540e-82da-4e7b-8c61-6779c16075a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_false_positive_negative(\n",
    "    by_eye_success_galaxies, \n",
    "    by_eye_not_success_galaxies, \n",
    "    success_df, \n",
    "    not_success_df, \n",
    "    full_df,\n",
    "    method  = \"nmr_x_1-p\",\n",
    "    verbose = True\n",
    "):\n",
    "    \n",
    "    false_positive = set(by_eye_not_success_galaxies).intersection(set(success_df.index))\n",
    "    false_negative = set(by_eye_success_galaxies).intersection(set(not_success_df.index))\n",
    "\n",
    "    by_eye_success_df     = full_df.loc[by_eye_success_galaxies].sort_values(by = method)\n",
    "    by_eye_not_success_df = full_df.loc[by_eye_not_success_galaxies].sort_values(by = method)\n",
    "\n",
    "    FP_rate = f\"{len(false_positive)}/({len(false_positive)} + {len(by_eye_not_success_df)})\"\n",
    "    FN_rate = f\"{len(false_negative)}/({len(false_negative)} + {len(by_eye_success_df)})\"\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"False positive rate (by eye) -- {FP_rate} = {100*eval(FP_rate):.2f}%\")\n",
    "        print(f\"False negative rate (by eye) -- {FN_rate} = {100*eval(FN_rate):.2f}%\")\n",
    "\n",
    "    #print(f\"Total # of galaxies sorted by eye -- {len(raw_by_eye_success_galaxies) + len(raw_by_eye_not_success_galaxies)}\")\n",
    "    return by_eye_success_df, by_eye_not_success_df, FP_rate, FN_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a481b27c-a6ff-4fc8-86ed-0ae1e24c014c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vprint(verbosity, *args, **kwargs):\n",
    "    if verbosity:\n",
    "        print(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "ec6fcd6b-d3b1-4e8a-a675-1d196bbe4d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_analysis(\n",
    "    **kwargs\n",
    "):\n",
    "    \n",
    "    in_dir                = kwargs.get(\"in_dir\", \"sparcfire-in\")\n",
    "    out_dir               = kwargs.get(\"out_dir\", \"sparcfire-out\")\n",
    "    basename              = kwargs.get(\"basename\", \"\") \n",
    "    method                = kwargs.get(\"method\", \"nmr_x_1-p\")\n",
    "    flip_chiral_agreement = kwargs.get(\"flip_chiral_agreement\", False)\n",
    "    pa_cutoff_val         = kwargs.get(\"pa_cutoff_val\", 10)\n",
    "    residual_cutoff_val   = kwargs.get(\"residual_cutoff_val\", 0.5)\n",
    "    alen_cutoff_val       = kwargs.get(\"alen_cutoff_val\", 0.007)\n",
    "    incl_by_eye           = kwargs.get(\"incl_by_eye\", True)\n",
    "    by_eye_subset         = kwargs.get(\"by_eye_subset\", None)\n",
    "    verbose               = kwargs.get(\"verbose\", False)\n",
    "    \n",
    "    vprint(verbose, \"Load residual.\")\n",
    "    residual_df = load_residual_df(\n",
    "        out_dir, \n",
    "        basename, \n",
    "        method = method, \n",
    "        residual_cutoff_val = residual_cutoff_val\n",
    "    )\n",
    "    \n",
    "    # field_pa   = \"pitch_angle\"\n",
    "    # field_alen = \"arc_length\"\n",
    "    # name_col   = \"gxyName\"\n",
    "\n",
    "    vprint(verbose, \"Load pre galaxy csv.\")\n",
    "    pre_sparc_output_csv        = load_galaxy_csv(out_dir,      basename, pre_post = \"pre\")\n",
    "        \n",
    "    vprint(verbose, \"Load pre galaxy arcs csv.\")\n",
    "    pre_sparc_output_arcs_top2  = load_galaxy_arcs_csv(out_dir, basename, pre_post = \"pre\")\n",
    "\n",
    "    vprint(verbose, \"Load post galaxy csv.\")\n",
    "    post_sparc_output_csv       = load_galaxy_csv(out_dir,      basename, pre_post = \"post\")\n",
    "    \n",
    "    vprint(verbose, \"Load post galaxy arcs csv.\")\n",
    "    post_sparc_output_arcs_top2 = load_galaxy_arcs_csv(out_dir, basename, pre_post = \"post\")\n",
    "\n",
    "# ====================================================================================================================\n",
    "\n",
    "    vprint(verbose, \"Prep pre galaxy arcs df\")\n",
    "    pre_sp_out    = prepare_arcs_output(pre_sparc_output_arcs_top2,  pre_post = \"pre\")\n",
    "    vprint(verbose, \"Prep post galaxy arcs df\")\n",
    "    post_sp_out   = prepare_arcs_output(post_sparc_output_arcs_top2, pre_post = \"post\")\n",
    "\n",
    "    vprint(verbose, \"And combine\")\n",
    "    all_sparc_out = pd.concat([pre_sp_out, post_sp_out], axis = 1)\n",
    "    \n",
    "# ====================================================================================================================\n",
    "\n",
    "    vprint(verbose, \"Compare SpArcFiRe analysis before and after\")\n",
    "    before_after_galfit_df     = before_after_galfit_comparison(\n",
    "        all_sparc_out, \n",
    "        pre_sparc_output_csv, \n",
    "        post_sparc_output_csv\n",
    "    )\n",
    "    \n",
    "    vprint(verbose, \"Bring everything together\")\n",
    "    full_df             = gather_everything(residual_df, before_after_galfit_df, method)\n",
    "    \n",
    "    sparcfire_processed = full_df.dropna(subset = ['pa_diff1', 'pa_diff2', 'pa_diff_galaxy'], how = 'all')\n",
    "    \n",
    "    vprint(verbose, \"Determine success\")\n",
    "    success_df, not_success_df = determine_success(\n",
    "        full_df, \n",
    "        in_dir                 = in_dir, \n",
    "        out_dir                = out_dir, \n",
    "        flip_chiral_agreement  = flip_chiral_agreement,\n",
    "        sparcfire_processed    = sparcfire_processed,\n",
    "        pa_cutoff_val          = pa_cutoff_val, \n",
    "        residual_cutoff_val    = residual_cutoff_val,\n",
    "        alen_cutoff_val        = alen_cutoff_val\n",
    "    )\n",
    "    \n",
    "    full_df[\"success\"] = full_df.index.isin(success_df.index)\n",
    "    print()\n",
    "    \n",
    "# ====================================================================================================================\n",
    "    \n",
    "    by_eye_success_df     = None\n",
    "    by_eye_not_success_df = None\n",
    "    \n",
    "    if incl_by_eye:\n",
    "        vprint(verbose, \"Extract by-eye evaluation\")\n",
    "        by_eye_success_galaxies, by_eye_not_success_galaxies = extract_by_eye_data(\n",
    "            out_dir, \n",
    "            basename, \n",
    "            residual_df, \n",
    "            full_df, \n",
    "            subset = by_eye_subset,\n",
    "            sparcfire_processed = sparcfire_processed\n",
    "        )\n",
    "        print()\n",
    "\n",
    "        # To resolve an occasional processing error...\n",
    "        by_eye_success_limited     = list(set(by_eye_success_galaxies).intersection(full_df.index))\n",
    "        by_eye_not_success_limited = list(set(by_eye_not_success_galaxies).intersection(full_df.index))\n",
    "\n",
    "        vprint(verbose, \"Calculate by-eye statistics\")\n",
    "        by_eye_success_df, by_eye_not_success_df, FP_rate, FN_rate = calculate_false_positive_negative(\n",
    "            by_eye_success_limited, \n",
    "            by_eye_not_success_limited, \n",
    "            success_df, \n",
    "            not_success_df, \n",
    "            full_df,\n",
    "            method = method\n",
    "        )\n",
    "\n",
    "        full_df[\"by_eye_success\"] = full_df.index.isin(by_eye_success_df.index)\n",
    "    \n",
    "    results_nt = all_results_nt(full_df, success_df, not_success_df, by_eye_success_df, by_eye_not_success_df)\n",
    "    for df in results_nt:\n",
    "        df[\"runname\"]  = basename\n",
    "        \n",
    "    return results_nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "e86d3aa8-f9c3-4490-9092-cc594f47de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_multi_run_results(\n",
    "    method, \n",
    "    *args,\n",
    "    **kwargs\n",
    "):\n",
    "    \n",
    "    df_names      = kwargs.get(\"df_names\", [])\n",
    "    incl_by_eye   = kwargs.get(\"incl_by_eye\", True)\n",
    "    by_eye_subset = kwargs.get(\"by_eye_subset\", None)\n",
    "    verbose       = kwargs.get(\"verbose\", True)\n",
    "    \n",
    "    print(f\"Joining {len(args)} attempts...\")\n",
    "    primary_full_df = deepcopy(args[0].full_df)\n",
    "    \n",
    "    num_dfs = len(args)\n",
    "    #alt_full_df     = deepcopy(args[1].full_df)\n",
    "    #alt_full_df.rename(columns = {method : f\"1_{method}\"}, inplace = True)\n",
    "\n",
    "    all_full_dfs = [primary_full_df]\n",
    "    all_methods  = [method]\n",
    "    all_columns  = []\n",
    "    \n",
    "    for i, arg in enumerate(args[1:]):\n",
    "        alt_method = f\"{i}_{method}\"\n",
    "        all_methods.append(alt_method)\n",
    "        \n",
    "        all_full_dfs.append(arg.full_df.rename(columns = {method : alt_method}))\n",
    "        all_columns.append(set(arg.full_df.columns))\n",
    "        \n",
    "    shared_columns = list(set(primary_full_df.columns).intersection(*all_columns)) + [\"gname\"]\n",
    "    #empty_list = [None]*max([len(df) for df in all_full_dfs])\n",
    "    #empty_df = pd.DataFrame({col : None for col in shared_columns}) #.set_index(\"gname\")\n",
    "    \n",
    "    # BY RESIDUAL\n",
    "    #temp_bool_df = pd.concat([primary_full_df[method], alt_full_df[f\"1_{method}\"]], axis = 1)\n",
    "    combined_bool_df = pd.concat([df[method] for df, method in zip(all_full_dfs, all_methods)], axis = 1)\n",
    "\n",
    "    #combined_bool_df.drop(index = list(set(primary_full_df.index).difference(set(alt_full_df.index))), inplace = True)\n",
    "    #temp_bool_df[\"minima\"] = temp_bool_df.idxmin(axis = 1)\n",
    "    combined_bool_df[\"minima\"] = combined_bool_df.idxmin(axis = 1)\n",
    "    \n",
    "    #og_minima  = temp_bool_df.minima == method\n",
    "    #alt_minima = temp_bool_df.minima == f\"1_{method}\"\n",
    "    \n",
    "    #og_success = temp_bool_df.index.isin(args[0].by_eye_success_df.index)\n",
    "    #alt_success = temp_bool_df.index.isin(args[1].by_eye_success_df.index)\n",
    "    #print(sum((og_minima & og_success) | (alt_minima & alt_success)))\n",
    "        \n",
    "    # By everything\n",
    "    eval_str = \" | \".join([f\"all_full_dfs[{i}].success\" for i in range(num_dfs)])\n",
    "    # success_n | success_m\n",
    "    combined_bool_df[\"by_sparcfire_score_success\"] = eval(eval_str) #primary_full_df.success | alt_full_df.success # | combined_bool_df.residual_minima_success\n",
    "    \n",
    "    minima_conditions  = [combined_bool_df.minima == method for method in all_methods]\n",
    "    success_conditions = [df.success for df in all_full_dfs]\n",
    "    all_conditions     = zip(minima_conditions, success_conditions)\n",
    "    \n",
    "    list_o_conditions = [cond_set[0] & cond_set[1] for cond_set in all_conditions]\n",
    "    eval_str = \" | \".join([f\"list_o_conditions[{i}]\" for i in range(num_dfs)])\n",
    "    # minima -> success_minima\n",
    "    combined_bool_df[\"by_sparcfire_and_best_score_success\"] = eval(eval_str)\n",
    "    \n",
    "    combined_bool_df[\"best_fit\"] = combined_bool_df[combined_bool_df.by_sparcfire_score_success].minima.replace({f\"{i}_{method}\" : name for i, name in enumerate(df_names)})\n",
    "    \n",
    "    if incl_by_eye:\n",
    "        \n",
    "        # Use by eye success df to account for by eye subsets (and to shorten the array) rather than info in full_df\n",
    "        by_eye_success_conditions = [combined_bool_df.index.isin(df.by_eye_success_df.index) for df in args]\n",
    "        # Flatten\n",
    "        all_by_eye_success_gnames     = list(set([gname for df in args for gname in df.by_eye_success_df.index]))\n",
    "        #all_by_eye_not_success_gnames = list(set([gname for df in args for gname in df.by_eye_not_success_df.index]))\n",
    "        all_by_eye_not_success_gnames = list(set([gname for df in args for gname in df.by_eye_not_success_df.index]))\n",
    "        #by_sparcfire_success_cond = [combined_bool_df.by_sparcfire_success == method for method in all_methods]\n",
    "\n",
    "        combined_bool_df[\"residual_success_by_eye\"] = combined_bool_df.index.isin(all_by_eye_success_gnames) & combined_bool_df.by_sparcfire_score_success \n",
    "        \n",
    "        all_conditions = zip(minima_conditions, by_eye_success_conditions)\n",
    "        list_o_conditions = [cond_set[0] & cond_set[1] for cond_set in all_conditions]\n",
    "        eval_str = \" | \".join([f\"list_o_conditions[{i}]\" for i in range(num_dfs)])\n",
    "\n",
    "        # How well does choosing the smallest residual score across all runs work in picking a successful fit\n",
    "        # when compared with the by eye analysis?\n",
    "        # minima -> (success_minima & by eye)\n",
    "        combined_bool_df[\"residual_minima_success_by_eye\"] = eval(eval_str)\n",
    "        # print(sum((minima_conditions[0] & by_eye_success_conditions[0]) | (minima_conditions[1] & by_eye_success_conditions[1])))\n",
    "        # print(sum(list_o_conditions[0] | list_o_conditions[1]))\n",
    "        \n",
    "        by_sparcfire_success_by_eye = combined_bool_df.index.isin(all_by_eye_success_gnames) & combined_bool_df.by_sparcfire_score_success\n",
    "            \n",
    "        # As with and including residual minima, but now include the sparcfire scoring\n",
    "        # (minima -> [success_minima & by eye]) | ([success_m | success_n] & by eye)\n",
    "        combined_bool_df[\"by_minima_or_sparcfire_success_by_eye\"]  = by_sparcfire_success_by_eye | combined_bool_df.residual_minima_success_by_eye\n",
    "        # Comment out this one because it's filtering both individually by eye rather than doing (minima | score) & by eye\n",
    "        #combined_bool_df[\"by_minima_and_sparcfire_success_by_eye\"] = by_sparcfire_success_by_eye & combined_bool_df.residual_minima_success_by_eye\n",
    "    \n",
    "        # TODO: Show % in both\n",
    "        # by eye success for all labeled by df\n",
    "        best_fit_str_dict = {m : f\"df_{i}\" for i, m in enumerate(all_methods)}\n",
    "        combined_bool_df[\"best_fit_by_eye\"] = None\n",
    "\n",
    "        for gname, row in combined_bool_df.iterrows():\n",
    "            best_method = [\n",
    "                (m, full_df.loc[gname, \"by_eye_success\"]) \n",
    "                for m, full_df in zip(all_methods, all_full_dfs)\n",
    "                if gname in full_df.index and full_df.loc[gname, \"by_eye_success\"]\n",
    "            ]\n",
    "\n",
    "            if len(best_method) > 1:\n",
    "                best_method = [(row.minima, None)]\n",
    "\n",
    "            elif not best_method:\n",
    "                best_method = [(None, None)]\n",
    "\n",
    "            if not combined_bool_df.loc[gname, \"best_fit_by_eye\"]:\n",
    "                combined_bool_df.loc[gname, \"best_fit_by_eye\"] = best_fit_str_dict.get(best_method[0][0], None)\n",
    "\n",
    "        #eval_str = \" | \".join([f\"all_full_dfs[{i}].by_eye_success\" for i, _ in enumerate(all_full_dfs)])\n",
    "        #combined_bool_df[\"by_eye_success\"] = eval(eval_str) #primary_full_df.by_eye_success | alt_full_df.by_eye_success\n",
    "        combined_bool_df[\"by_eye_success\"] = False | combined_bool_df.best_fit_by_eye.str.contains(\"df\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Total success by combining SpArcFiRe + score: {sum(combined_bool_df.by_sparcfire_score_success)}/{total_galaxies}\")\n",
    "        print(f\"i.e. success_n | success_m | ...\")\n",
    "        print()\n",
    "        print(f\"Total success by combining SpArcFiRe + best score: {sum(combined_bool_df.by_sparcfire_and_best_score_success)}/{total_galaxies}\")\n",
    "        print(f\"i.e. minima -> success_minima\")\n",
    "        print(mini_sep)\n",
    "        if incl_by_eye:\n",
    "            print(\"Checking against the by eye determination...\")\n",
    "            _total_galaxies = total_galaxies\n",
    "            if df_names:\n",
    "                if len(df_names) != num_dfs: \n",
    "                    print(\"Length of dataframe names supplied should be equal to the number of dataframes supplied.\")\n",
    "                    print(\"Leaving current convention in the dataframe (df_0, df_1, ..., df_n)\")\n",
    "                else:\n",
    "                    combined_bool_df[\"best_fit_by_eye\"]   = combined_bool_df.best_fit_by_eye.replace({f\"df_{i}\" : name for i, name in enumerate(df_names)})\n",
    "            \n",
    "            if by_eye_subset:\n",
    "                _total_galaxies = by_eye_subset\n",
    "                print(\"Using a subset of galaxies for the by eye determination...\")\n",
    "                \n",
    "            print(f\"Total success by eye: {sum(combined_bool_df.by_eye_success)}/{_total_galaxies}\")\n",
    "            total_by_eye = sum(combined_bool_df.by_eye_success)\n",
    "            print()\n",
    "            print(f\"By eye captured by either score: {sum(combined_bool_df.residual_success_by_eye)}/{total_by_eye}\")\n",
    "            print(f\"i.e. (success_m | success_n | ...) & by eye\")\n",
    "            print()\n",
    "            print(f\"By eye captured by best score: {sum(combined_bool_df.residual_minima_success_by_eye)}/{total_by_eye}\")\n",
    "            print(f\"i.e. minima -> (success_minima & by eye)\")\n",
    "            print()\n",
    "            print(f\"By eye captured by SpArcFiRe or choosing best score between the two runs: {sum(combined_bool_df.by_minima_or_sparcfire_success_by_eye)}/{total_by_eye}\")\n",
    "            print(f\"i.e. (minima -> [success_minima & by eye]) | ([success_m | success_n | ...] & by eye)\")\n",
    "            #print(f\"By eye captured by SpArcFiRe and choosing best score between the two runs: {sum(combined_bool_df.by_minima_and_sparcfire_success_by_eye)}/{total_by_eye}\")\n",
    "            print(mini_sep)\n",
    "\n",
    "            bss  = set(combined_bool_df[combined_bool_df.by_sparcfire_score_success].index)\n",
    "            #bss  = set(combined_bool_df[bss.isin(all_by_eye_success_gnames)].index)\n",
    "            TP   = all_by_eye_success_gnames\n",
    "            #TP   = set(combined_bool_df[combined_bool_df[\"by_eye_success\"]].index)\n",
    "            \n",
    "            #bsns  = ~combined_bool_df.by_sparcfire_score_success\n",
    "            bsns = combined_bool_df[~combined_bool_df.by_sparcfire_score_success].index\n",
    "            #bsns = bsns.index\n",
    "            #bsns = set(combined_bool_df[bsns.isin(all_by_eye_not_success_gnames)].index)\n",
    "            \n",
    "            # Exclude the ones found in the success galaxies because some runs may find success where the others didn't\n",
    "            TN =  set(all_by_eye_not_success_gnames).difference(set(all_by_eye_success_gnames))\n",
    "            assert len(TP) + len(TN) == _total_galaxies, f\"True positive and true negative don't add up to {_total_galaxies}!\"\n",
    "            #TN   = combined_bool_df[~combined_bool_df[\"by_eye_success\"]].index\n",
    "            #TN   = set(TN[TN.isin(all_by_eye_not_success_gnames)])\n",
    "\n",
    "            FP   = bss.intersection(TN)\n",
    "            FN   = bsns.intersection(TP)\n",
    "\n",
    "            sparc_positive = bss.intersection(TP)\n",
    "            sparc_negative = bsns.intersection(TN)\n",
    "            fraction = len(sparc_positive)/sum(combined_bool_df.by_eye_success)\n",
    "            \n",
    "            combined_bool_by_eye_not_success = ~combined_bool_df.by_eye_success\n",
    "            denom = combined_bool_by_eye_not_success[combined_bool_by_eye_not_success.index.isin(all_by_eye_not_success_gnames)]\n",
    "            neg_fraction = len(sparc_negative)/sum(denom)\n",
    "            # FPR = FP/(FP + TN)\n",
    "            # FNR = FN/(FN + TP)\n",
    "            # TODO WTF\n",
    "            print(f\"By eye success found by SpArcFiRe + score:  {len(sparc_positive)}/{sum(combined_bool_df.by_eye_success)} = {100*fraction:.2f}%\")\n",
    "            print(f\"By eye not success found by SpArcFiRe + score:  {len(sparc_negative)}/{sum(denom)} = {100*neg_fraction:.2f}%\")\n",
    "            \n",
    "            FP_rate = f\"{len(FP)} / ({len(FP)} + {len(TN)})\"\n",
    "            FN_rate = f\"{len(FN)} / ({len(FN)} + {len(TP)})\"\n",
    "\n",
    "            print()\n",
    "            print(f\"False positive rate (by eye) -- {FP_rate} = {100*eval(FP_rate):.2f}%\")\n",
    "            print(f\"False negative rate (by eye) -- {FN_rate} = {100*eval(FN_rate):.2f}%\")\n",
    "            \n",
    "            # TODO: GENERATE CONFUSION MATRIX\n",
    "            #print()\n",
    "            #print(f\"Confusion matrix\")\n",
    "            #print()\n",
    "            #print()\n",
    "    \n",
    "    \n",
    "    _ = [full_df.rename(columns = {f\"{i}_{method}\" : method}, inplace = True) for i, full_df in enumerate(all_full_dfs[1:])]\n",
    "    \n",
    "    combined_full_df = pd.concat([full_df for full_df in all_full_dfs])\n",
    "    \n",
    "    combined_success_df = pd.concat(\n",
    "                full_df.loc[combined_bool_df[combined_bool_df.best_fit == name].index, :] \n",
    "                for name, full_df in zip(df_names, all_full_dfs)\n",
    "            )\n",
    "    combined_success_df.groupby(combined_success_df.columns, axis = 1).agg(lambda x: x.dropna)\n",
    "            \n",
    "    combined_by_eye_success_df = None\n",
    "    if incl_by_eye:\n",
    "        # Get index, i.e. galaxy name from choosing the best fit then feed that into the full_dfs in all_full_dfs via loc\n",
    "        # to grab the row\n",
    "        combined_by_eye_success_df = pd.concat(\n",
    "            full_df.loc[combined_bool_df[combined_bool_df.best_fit_by_eye == name].index, :] \n",
    "            for name, full_df in zip(df_names, all_full_dfs)\n",
    "        )\n",
    "        # Merge duplicated columns\n",
    "        combined_by_eye_success_df.groupby(combined_by_eye_success_df.columns, axis = 1).agg(lambda x: x.dropna)\n",
    "    \n",
    "    return combined_results_nt(combined_bool_df, combined_full_df, combined_success_df, combined_by_eye_success_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4037ab36-3d37-4a79-bb6f-ab0cf75fe2be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# combined_bool_df = combine_multi_run_results(\n",
    "#             \"nmr_x_1-p\",\n",
    "#             galaxy_set_1000_results[\"1000_NC2\"],\n",
    "#             galaxy_set_1000_results[\"1000_NC3\"],\n",
    "#             df_names      = [\"1000_NC2\", \"1000_NC3\"],\n",
    "#             incl_by_eye   = True,\n",
    "#             #by_ebye_subset = 1000\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "693a33b8-825d-40d2-88ec-906322df9ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_ecdf(x, runname, df, dict_o_kwargs):\n",
    "    \n",
    "    # for key, default in exec_kwargs().items():\n",
    "    #     exec(f\"{key} = kwargs.get({key}, {default})\")\n",
    "    # Yeesh https://stackoverflow.com/a/67367191\n",
    "    # Use frame(3) since these functions are nested\n",
    "    sys._getframe(4).f_locals.update(dict_o_kwargs)\n",
    "\n",
    "    fig = px.ecdf(df,\n",
    "                  x = x,\n",
    "                  markers = True, \n",
    "                  lines = False, \n",
    "                  marginal = \"histogram\",\n",
    "                  ecdfnorm = None,\n",
    "                  log_x    = log_x,\n",
    "                  log_y    = log_y\n",
    "                 ) \n",
    "\n",
    "    if add_vline:\n",
    "        fig.add_vline(x = cutoff_val, \n",
    "                      row = 1,\n",
    "                      line_color = \"cyan\",\n",
    "                      annotation_text= f\"{cutoff_val}\", \n",
    "                      annotation_position=\"bottom\")\n",
    "\n",
    "    if add_hline:\n",
    "        yval = sum(df.loc[:, x] < cutoff_val)\n",
    "        fig.add_hline(y = yval, \n",
    "                      row = 1,\n",
    "                      col = 1,\n",
    "                      line_color = \"magenta\",\n",
    "                      annotation_text=f\"{yval}\",\n",
    "                      annotation_position=\"bottom left\"\n",
    "                     )\n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d8fe7455-01b0-477f-beb7-0d72b1af46db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_scatter(x, runname, df, dict_o_kwargs):\n",
    "    \n",
    "    sys._getframe(4).f_locals.update(dict_o_kwargs)\n",
    "        \n",
    "    fig = px.scatter(df, \n",
    "               x = x, \n",
    "               y = y, \n",
    "               color = color,\n",
    "               color_continuous_scale = \"Agsunset\",\n",
    "                    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "fbe217be-635a-4f9a-85d1-bf40d0bb4fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_histogram(x, runname, df, dict_o_kwargs, multi):\n",
    "    \n",
    "    sys._getframe(4).f_locals.update(dict_o_kwargs)\n",
    "    \n",
    "    fig = px.histogram(\n",
    "        df,\n",
    "        x                       = x,\n",
    "        color                   = color,\n",
    "        color_discrete_sequence = color_discrete_sequence,\n",
    "        histnorm                = histnorm,\n",
    "        facet_col               = facet_col,\n",
    "        facet_row               = facet_row,\n",
    "        nbins                   = nbins,\n",
    "        #hover_data = {'Galaxy ID': (\":c\", full_df.index)},\n",
    "        log_x                   = log_x,\n",
    "        log_y                   = log_y,\n",
    "    )\n",
    "    \n",
    "    if facet_col or facet_row:\n",
    "        fig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\n",
    "\n",
    "    if multi:\n",
    "        fig.update_layout(barmode = \"overlay\")\n",
    "        fig.update_traces(opacity = 0.75)\n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "8c26146b-9f20-456d-aa64-f0e0b56a6225",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_plot(\n",
    "    x, \n",
    "    runname, \n",
    "    plot_type, \n",
    "    df, \n",
    "    output_image_dir = \"for_paper_images\", \n",
    "    **kwargs\n",
    "):\n",
    "        \n",
    "    dict_o_kwargs = {\n",
    "        \"y\"               : None,\n",
    "        \"color\"           : None,\n",
    "        \"color_discrete_sequence\" : None,\n",
    "        \n",
    "        \"xaxis_title\"     : \"\",\n",
    "        \"yaxis_title\"     : \"\",\n",
    "        \n",
    "        \"xaxis_range\"     : None,\n",
    "        \"yaxis_range\"     : None,\n",
    "        \n",
    "        \"log_x\"           : False,\n",
    "        \"log_y\"           : False,\n",
    "        \n",
    "        \"histnorm\"        : \"\",\n",
    "        \"facet_col\"       : None,\n",
    "        \"facet_row\"       : None,\n",
    "        \n",
    "        \"nbins\"           : 0,\n",
    "        \n",
    "        \"cutoff_val\"      : 0.007,\n",
    "        \"add_vline\"       : True,\n",
    "        \"add_hline\"       : True,\n",
    "        \n",
    "        \"title\"           : \"\",\n",
    "        \"title_x\"         : 0.9,\n",
    "        \"title_y\"         : 0.5,\n",
    "\n",
    "        \"output_image_dir\" : output_image_dir,\n",
    "        \"filetype\"        : \"png\",\n",
    "        \"show\"            : True,\n",
    "        \"write\"           : True\n",
    "    }\n",
    "    \n",
    "    # Updating with kwargs\n",
    "    dict_o_kwargs = {key : kwargs.get(key, default) for key, default in dict_o_kwargs.items()}\n",
    "    \n",
    "    plt.clf()\n",
    "    if plot_type == \"ecdf\":\n",
    "        fig = create_ecdf(x, runname, df, dict_o_kwargs)\n",
    "    elif plot_type == \"scatter\":\n",
    "        fig = create_scatter(x, runname, df, dict_o_kwargs)\n",
    "    elif plot_type == \"histogram\":\n",
    "        multi = kwargs.get(\"multi\", True)\n",
    "        fig = create_histogram(x, runname, df, dict_o_kwargs, multi)\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    sys._getframe(3).f_locals.update(dict_o_kwargs)\n",
    "    \n",
    "    if title:\n",
    "        fig.update_layout(\n",
    "            title_text = title, \n",
    "            title_x    = title_x, \n",
    "            title_y    = title_y\n",
    "        )\n",
    "        \n",
    "    if xaxis_title:\n",
    "        fig.update_layout(xaxis_title = xaxis_title)\n",
    "    if yaxis_title:\n",
    "        fig.update_layout(yaxis_title = yaxis_title)\n",
    "        \n",
    "    if xaxis_range:\n",
    "        fig.update_layout(xaxis_range = xaxis_range)\n",
    "    if yaxis_range:\n",
    "        fig.update_layout(yaxis_range = yaxis_range)\n",
    "    \n",
    "    if show:\n",
    "        fig.show()\n",
    "        \n",
    "    height           = kwargs.get(\"height\", 800)\n",
    "    width_multiplier = kwargs.get(\"width_multiplier\", 1.5) #1200\n",
    "    \n",
    "    if write:\n",
    "        fig.write_image(\n",
    "            f\"{output_image_dir}/{plot_type}_{runname}_{x}.{filetype}\", \n",
    "            height = height, width = height*width_multiplier\n",
    "        )\n",
    "        \n",
    "    fig.data   = []\n",
    "    fig.layout = {}\n",
    "    \n",
    "    #return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "524b8133-afce-4840-9a24-9d145858b41f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_all_plots(\n",
    "    df_container,\n",
    "    method, \n",
    "    basename, \n",
    "    output_image_dir,\n",
    "    **kwargs\n",
    "):\n",
    "    \n",
    "    incl_by_eye = kwargs.get(\"incl_by_eye\", True)\n",
    "    show        = kwargs.get(\"show\", True)\n",
    "    write       = kwargs.get(\"write\", True)\n",
    "        \n",
    "    # Use a cutoff because there tends to be some extremely high values which skew the plot\n",
    "    plot_df = df_container.full_df[df_container.full_df.loc[:, method] < kwargs.get(\"score_ecdf_cutoff\", 0.015)]\n",
    "\n",
    "# ============================================================================================================================================================\n",
    "# FULL ECDF\n",
    "# ============================================================================================================================================================\n",
    "\n",
    "    _ = create_plot(\n",
    "        x                = method,\n",
    "        runname          = basename,\n",
    "        plot_type        = \"ecdf\",\n",
    "        df               = plot_df,\n",
    "        output_image_dir = output_image_dir,\n",
    "        xaxis_title      = method, #\"KStest+NMR\",\n",
    "        # title       = f\"1000 galaxies: ECDF for KStest+NMR on all models\",\n",
    "        # title_y     = 0.92\n",
    "        cutoff_val       = kwargs.get(\"residual_cutoff_val\", 0.007),\n",
    "        show             = show,\n",
    "        write            = write\n",
    "    )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# ECDF OF BY EYE SCORE\n",
    "# ============================================================================================================================================================\n",
    "    \n",
    "    if incl_by_eye:\n",
    "        _ = create_plot(\n",
    "            x                = method,\n",
    "            runname          = f\"{basename}_by-eye\",\n",
    "            plot_type        = \"ecdf\",\n",
    "            df               = df_container.by_eye_success_df,\n",
    "            output_image_dir = output_image_dir,\n",
    "            xaxis_title      = method, #\"KStest+NMR\",\n",
    "            add_hline        = False,\n",
    "            # title       = f\"1000 galaxies: ECDF for KStest+NMR on by-eye successful model fits\",\n",
    "            # title_y     = 0.92\n",
    "            show             = show,\n",
    "            write            = write\n",
    "        )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# SERSIC INDEX HISTOGRAMS\n",
    "# ============================================================================================================================================================\n",
    "\n",
    "    x1   = \"sersic_index_sersic_1\"\n",
    "    x2   = \"sersic_index_sersic_2\"\n",
    "    x    = \"n\"\n",
    "    fcol = \"domain\"\n",
    "\n",
    "    plot_df = df_container.success_df[[x1,x2]].rename(columns = {x1 : \"sersic_1\", x2 : \"sersic_2\"})\n",
    "    plot_df = pd.melt(plot_df).rename(columns = {\"value\" : x, \"variable\" : \"component\"})\n",
    "    plot_df[fcol] = \"success\"\n",
    "\n",
    "    plot_df1 = df_container.full_df[[x1,x2]].rename(columns = {x1 : \"sersic_1\", x2 : \"sersic_2\"})\n",
    "    plot_df1 = pd.melt(plot_df1).rename(columns = {\"value\" : x, \"variable\" : \"component\"})\n",
    "    plot_df1[fcol] = \"all models\"\n",
    "    \n",
    "    to_concat = [plot_df, plot_df1]\n",
    "    runname   = f\"{basename}_success-vs-all\"\n",
    "    \n",
    "    if incl_by_eye:\n",
    "        # By eye success\n",
    "        plot_df2 = df_container.by_eye_success_df[[x1,x2]].rename(columns = {x1 : \"sersic_1\", x2 : \"sersic_2\"})\n",
    "        plot_df2 = pd.melt(plot_df2).rename(columns   = {\"value\" : x, \"variable\" : \"component\"})\n",
    "        plot_df2[fcol] = \"by-eye success\"\n",
    "        to_concat.append(plot_df2)\n",
    "        runname   = f\"{basename}_by-eye-vs-success-vs-all\"\n",
    "\n",
    "    plot_df = pd.concat(to_concat, axis = 0)\n",
    "\n",
    "    # Bulge -- Redder\n",
    "    color_1 = px.colors.qualitative.Plotly[1]\n",
    "    # Disk -- Bluer\n",
    "    color_2 = px.colors.qualitative.Plotly[0]\n",
    "    colors = [color_1, color_2]\n",
    "    \n",
    "    _ = create_plot(\n",
    "        x                       = x,\n",
    "        runname                 = runname,\n",
    "        plot_type               = \"histogram\",\n",
    "        df                      = plot_df,\n",
    "        output_image_dir        = output_image_dir,\n",
    "        histnorm                = \"probability\",\n",
    "        color                   = \"component\",\n",
    "        color_discrete_sequence = colors,\n",
    "        nbins                   = 40,\n",
    "        facet_col               = fcol,\n",
    "        xaxis_range             = kwargs.get(\"xaxis_range_sersic_hist\", None), # [10, 20],\n",
    "        yaxis_range             = kwargs.get(\"yaxis_range_sersic_hist\", None), # [0, 0.15],\n",
    "        # title       = f\"{runname} galaxies: distribution of magnitudes for by-eye successful models\"\n",
    "        # title_y     = 0.85\n",
    "        show                    = show,\n",
    "        write                   = write\n",
    "    )\n",
    "\n",
    "    # _ = create_plot(\n",
    "    #     x           = x,\n",
    "    #     runname     = \"1000_by-eye\",\n",
    "    #     plot_type   = \"histogram\",\n",
    "    #     df          = plot_df,\n",
    "    #     color       = \"component\",\n",
    "    #     # title       = f\"{runname} galaxies: distribution of Srsic indices for by-eye successful models\"\n",
    "    #     # title_y     = 0.85\n",
    "    #     show        = show\n",
    "    # )\n",
    "\n",
    "    # # All results\n",
    "    # plot_df = full_df[[x1,x2]].rename(columns = {x1 : \"sersic_1\", x2 : \"sersic_2\"})\n",
    "    # plot_df = pd.melt(plot_df).rename(columns = {\"value\" : x, \"variable\" : \"component\"})\n",
    "\n",
    "    # _ = create_plot(\n",
    "    #     x           = x,\n",
    "    #     runname     = \"1000\",\n",
    "    #     plot_type   = \"histogram\",\n",
    "    #     df          = plot_df,\n",
    "    #     color       = \"component\",\n",
    "    #     # title       = f\"{runname} galaxies: distribution of Srsic indices for by-eye successful models\"\n",
    "    #     # title_y     = 0.85\n",
    "    #     show        = show\n",
    "    # )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# MAGNITUDE HISTOGRAMS \n",
    "# ============================================================================================================================================================\n",
    "    \n",
    "    # TODO: Combine these into one plot either using facet or go\n",
    "    # https://plotly.com/python/subplots/\n",
    "    # or https://plotly.com/python/facet-plots/\n",
    "\n",
    "    x1   = \"magnitude_sersic_1\"\n",
    "    x2   = \"magnitude_sersic_2\"\n",
    "    x    = \"m\"\n",
    "    fcol = \"domain\"\n",
    "    \n",
    "    # TODO: BULGE SHOULD BE RED, DISK SHOULD BE BLUE\n",
    "    plot_df = df_container.success_df[[x1,x2]].rename(columns = {x1 : \"sersic_1\", x2 : \"sersic_2\"})\n",
    "    plot_df = pd.melt(plot_df).rename(columns = {\"value\" : x, \"variable\" : \"component\"})\n",
    "    plot_df[fcol] = \"success\"\n",
    "\n",
    "    plot_df1 = df_container.full_df[[x1,x2]].rename(columns = {x1 : \"sersic_1\", x2 : \"sersic_2\"})\n",
    "    plot_df1 = pd.melt(plot_df1).rename(columns = {\"value\" : x, \"variable\" : \"component\"})\n",
    "    plot_df1[fcol] = \"all models\"\n",
    "    \n",
    "    to_concat = [plot_df, plot_df1]\n",
    "    runname   = f\"{basename}_success-vs-all\"\n",
    "    \n",
    "    if incl_by_eye:\n",
    "        # By eye success\n",
    "        plot_df2 = df_container.by_eye_success_df[[x1,x2]].rename(columns = {x1 : \"sersic_1\", x2 : \"sersic_2\"})\n",
    "        plot_df2 = pd.melt(plot_df2).rename(columns   = {\"value\" : x, \"variable\" : \"component\"})\n",
    "        plot_df2[fcol] = \"by-eye success\"\n",
    "        to_concat.append(plot_df2)\n",
    "        runname   = f\"{basename}_by-eye-vs-success-vs-all\"\n",
    "        \n",
    "    plot_df = pd.concat(to_concat, axis = 0)\n",
    "\n",
    "    # Bulge -- Redder\n",
    "    color_1 = px.colors.qualitative.Plotly[1]\n",
    "    # Disk -- Bluer\n",
    "    color_2 = px.colors.qualitative.Plotly[0]\n",
    "    colors = [color_1, color_2]\n",
    "    \n",
    "    _ = create_plot(\n",
    "        x                       = x,\n",
    "        runname                 = runname,\n",
    "        plot_type               = \"histogram\",\n",
    "        df                      = plot_df,\n",
    "        output_image_dir        = output_image_dir,\n",
    "        histnorm                = \"probability\",\n",
    "        color                   = \"component\",\n",
    "        color_discrete_sequence = colors,\n",
    "        facet_col               = fcol,\n",
    "        xaxis_range             = kwargs.get(\"xaxis_range_mag_hist\", None), # [10, 20],\n",
    "        yaxis_range             = kwargs.get(\"yaxis_range_mag_hist\", None), # [0, 0.15],\n",
    "        # title       = f\"{runname} galaxies: distribution of magnitudes for by-eye successful models\"\n",
    "        # title_y     = 0.85\n",
    "        show                    = show,\n",
    "        write                   = write\n",
    "    )\n",
    "\n",
    "    # By eye\n",
    "    # figure1 = create_plot(\n",
    "    #     x           = x,\n",
    "    #     runname     = \"1000_by-eye\",\n",
    "    #     plot_type   = \"histogram\",\n",
    "    #     df          = plot_df,\n",
    "    #     color       = \"component\",\n",
    "    #     xaxis_range = [10, 17],\n",
    "    #     # title       = f\"{runname} galaxies: distribution of magnitudes for by-eye successful models\"\n",
    "    #     # title_y     = 0.85\n",
    "    #     show        = show,\n",
    "    #     write       = False\n",
    "    # )\n",
    "\n",
    "    # # All results\n",
    "    # plot_df = full_df[[x1,x2]].rename(columns = {x1 : \"sersic_1\", x2 : \"sersic_2\"})\n",
    "    # plot_df = pd.melt(plot_df).rename(columns = {\"value\" : x, \"variable\" : \"component\"})\n",
    "\n",
    "    # figure2 = create_plot(\n",
    "    #     x           = x,\n",
    "    #     runname     = \"1000\",\n",
    "    #     plot_type   = \"histogram\",\n",
    "    #     df          = plot_df,\n",
    "    #     color       = \"component\",\n",
    "    #     xaxis_range = [10, 18],\n",
    "    #     # title       = f\"{runname} galaxies: distribution of magnitudes for by-eye successful models\"\n",
    "    #     # title_y     = 0.85\n",
    "    #     show        = show,\n",
    "    #     write       = False\n",
    "    # )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# ALEN HISTOGRAM\n",
    "# ============================================================================================================================================================\n",
    "    _ = create_plot(\n",
    "        x                = \"alen_ratio\",\n",
    "        runname          = basename,\n",
    "        plot_type        = \"histogram\",\n",
    "        df               = df_container.full_df,\n",
    "        output_image_dir = output_image_dir,\n",
    "        xaxis_title      = \"alen ratio\",\n",
    "        multi            = False,\n",
    "        # title       = f\"{runname} galaxies: distribution of alen ratios for all models\"\n",
    "        # title_y     = 0.85\n",
    "        show             = show,\n",
    "        write            = write\n",
    "    )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# SCATTER OF PITCH ANGLE DIFFERENCES\n",
    "# ============================================================================================================================================================\n",
    "    \n",
    "    x     = \"observation\"\n",
    "    y     = \"model\"\n",
    "    color = \"difference\"\n",
    "\n",
    "    pre_pa  = df_container.full_df[[\"pre_pa1\" , \"pre_pa2\"]].mean(axis = 1)\n",
    "    post_pa = df_container.full_df[[\"post_pa1\", \"post_pa2\"]].mean(axis = 1)\n",
    "    plot_df = pd.concat([pre_pa, post_pa], axis = 1).rename(columns = {0 : x, 1 : y})\n",
    "    plot_df[color] = abs(plot_df[x] - plot_df[y])\n",
    "\n",
    "    _ = create_plot(\n",
    "        x                = x,\n",
    "        y                = y,\n",
    "        runname          = f\"{basename}_pa_diff\",\n",
    "        plot_type        = \"scatter\",\n",
    "        df               = plot_df,\n",
    "        output_image_dir = output_image_dir,\n",
    "        color            = color,\n",
    "        width_multiplier = 1,\n",
    "        # title     = \"Pitch angle difference reported by SpArcFiRe, model vs observation\"\n",
    "        # title_y   = 0.85\n",
    "        show             = show,\n",
    "        write            = write\n",
    "    )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# SCATTER OF PITCH ANGLE DIFFERENCES\n",
    "# ============================================================================================================================================================\n",
    "\n",
    "    _ = create_plot(\n",
    "        x                = \"pa_diff_galaxy\",\n",
    "        runname          = basename,\n",
    "        plot_type        = \"ecdf\",\n",
    "        df               = df_container.full_df,\n",
    "        output_image_dir = output_image_dir,\n",
    "        xaxis_title      = \"Pitch Angle Difference (deg)\",\n",
    "        cutoff_val       = kwargs.get(\"pa_cutoff_val\", 10),\n",
    "        # title       = f\"ECDF of pitch angle difference reported by SpArcFiRe, model vs observation\"\n",
    "        # title_y     = 0.85\n",
    "        show             = show,\n",
    "        write            = write\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "3c9968be-1763-40f0-b267-cfbe467d4d31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_quantiles(\n",
    "    out_dir, \n",
    "    df, \n",
    "    method,\n",
    "    **kwargs\n",
    "):\n",
    "    print_latex = kwargs.get(\"print_latex\", True)\n",
    "    copy_png    = kwargs.get(\"copy_png\", False)\n",
    "    \n",
    "    # Just in case\n",
    "    df.sort_values(by = method, inplace = True)\n",
    "\n",
    "    # Expect that if there exists more than one runname,\n",
    "    # then we're working with combined ata\n",
    "    runnames = list(set(df.runname))\n",
    "    if len(runnames) > 1:\n",
    "        prefixes = list(set([i.split(\"_\")[0] for i in runnames]))\n",
    "        if len(prefixes) == 1:\n",
    "            runname = f\"{prefixes[0]}_combined\"\n",
    "        else:\n",
    "            runname = \"combined\"\n",
    "    else:\n",
    "        runname = runnames[0]\n",
    "        \n",
    "    success_dir = pj(out_dir, runname, f'{runname}_galfit_png')\n",
    "    print_latex_file = pj(out_dir, runname, f\"{runname}_for_latex.txt\")\n",
    "    \n",
    "    if not exists(success_dir):\n",
    "        os.makedirs(success_dir)\n",
    "    \n",
    "    quantile           = [\"0\", \"20\", \"40\", \"60\", \"80\"]\n",
    "    quantiled_galaxies = []\n",
    "    \n",
    "    print_latex_all = []\n",
    "    if print_latex:\n",
    "        \n",
    "        if exists(print_latex_file):\n",
    "            print(\"Deleting old latex output file...\")\n",
    "            os.remove(print_latex_file)\n",
    "            \n",
    "        print(f\"Writing latex to file {print_latex_file}\")\n",
    "    \n",
    "    for q in quantile:\n",
    "        #vprint(print_latex, f\"{q} &\")\n",
    "        print_latex_all.append(f\"{q} &\")\n",
    "        \n",
    "        if copy_png:\n",
    "            quantile_dir = pj(success_dir, f\"{runname}_all_quantile\", f\"quantile_{q}\")\n",
    "            if exists(quantile_dir):\n",
    "                shutil.rmtree(quantile_dir)\n",
    "            os.makedirs(quantile_dir)\n",
    "              \n",
    "        interp_df = df[method][df[method] >= df[method].quantile(0.01*float(q), interpolation='lower')]\n",
    "        for count, (index, value) in enumerate(interp_df.items()):\n",
    "            #if count < 5:\n",
    "            #    continue\n",
    "            if count == 8:\n",
    "                break\n",
    "\n",
    "            gname = index\n",
    "            #print(q, i)\n",
    "            #vprint(print_latex, f\"{initial_str}{gname + '_combined.png'}{end_str}\")\n",
    "            rname = df.loc[index, \"runname\"]\n",
    "            \n",
    "            temp_str    = f\"images/{rname}/{rname}_all_quantile/quantile_\"\n",
    "            initial_str = f\"    \\includegraphics[height=0.18\\\\textheight]{{{temp_str}{q}/\"\n",
    "            \n",
    "            end_str = \"} &\"\n",
    "            if count == 7 or count == len(interp_df) - 1:\n",
    "                end_str = \"} \\\\\\\\\"\n",
    "                \n",
    "            print_latex_all.append(f\"{initial_str}{gname + '_combined.png'}{end_str}\")\n",
    "\n",
    "            if copy_png:\n",
    "                png_dir = pj(out_dir, rname, f'{rname}_galfit_png')\n",
    "                shutil.copy(pj(png_dir, f\"{gname}_combined.png\"), quantile_dir)\n",
    "\n",
    "            quantiled_galaxies.append(gname)\n",
    "                \n",
    "            #sp(f\"cp {pj(out_dir, 'by_eye_success', gname + '_combined.png')} {pj(success_dir, 'all_quantile', 'quantile_' + q)}\")\n",
    "            \n",
    "    if print_latex:           \n",
    "        with open(print_latex_file, \"w\") as plf:\n",
    "            plf.write(\"\\n\".join(print_latex_all))\n",
    "            plf.write(\"\\n\")\n",
    "            \n",
    "    if copy_png:\n",
    "        # Tar it all up!\n",
    "        sp(f\"tar -czvf {pj(out_dir, runname, runname)}_all_quantile.tar.gz -C {success_dir} {runname}_all_quantile\")\n",
    "        \n",
    "    return quantiled_galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "d1214924-ee80-484d-854c-ec76922f1871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fprint(input_str, fill_char = \"*\", fill_len = 100):\n",
    "    input_str = f\" {input_str} \"\n",
    "    print()\n",
    "    print(f\"{input_str:{fill_char}^{fill_len}}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "d7b8ff1f-4954-4488-9979-c5d889d40ae8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(\n",
    "    run_path, \n",
    "    *basenames, \n",
    "    **kwargs\n",
    "):\n",
    "    # Set some path variables and things\n",
    "    run_path = run_path\n",
    "    \n",
    "    if in_notebook():\n",
    "        run_path = run_path.replace(\"ics-home\", \"portmanm\")\n",
    "\n",
    "    in_dir  = kwargs.get(\"in_dir\", pj(run_path, \"sparcfire-in\"))\n",
    "    out_dir = kwargs.get(\"tmp_dir\", pj(run_path, \"sparcfire-out\"))\n",
    "    tmp_dir = kwargs.get(\"out_dir\", pj(run_path, \"sparcfire-tmp\"))\n",
    "\n",
    "    output_image_dir = kwargs.get(\"output_image_dir\", pj(run_path, \"for_paper_images\"))\n",
    "    if not exists(output_image_dir):\n",
    "        os.makedirs(output_image_dir)\n",
    "        \n",
    "    method          = kwargs.get(\"method\", \"nmr_x_1-p\")\n",
    "    nmr             = \"norm_masked_residual\"\n",
    "    \n",
    "    global total_galaxies\n",
    "    total_galaxies = get_total_galaxies(in_dir = in_dir, out_dir = out_dir)\n",
    "    \n",
    "    # FUNCTIONS OPTIONS\n",
    "    incl_by_eye   = kwargs.get(\"incl_by_eye\", False)\n",
    "    by_eye_subset = kwargs.get(\"by_eye_subset\", False)\n",
    "    write         = kwargs.get(\"write\", False)\n",
    "    show          = kwargs.get(\"show\", False)\n",
    "    print_latex   = kwargs.get(\"print_latex\", True)\n",
    "    copy_png      = kwargs.get(\"copy_png\", True)\n",
    "    \n",
    "    # Getting ready\n",
    "    all_results  = {}\n",
    "    plot_options = kwargs.get(\"plot_options\", {bname : {} for bname in basenames})\n",
    "    \n",
    "    # LOOPING THROUGH NAMES GIVEN FOR ANALYSIS\n",
    "    for basename in basenames:\n",
    "        # RESIDUAL ANALYSIS\n",
    "        fprint(f\"PERFORMING RESIDUAL ANALYSIS FOR {basename}\")\n",
    "        analysis_results  = residual_analysis(\n",
    "            in_dir              = in_dir, \n",
    "            out_dir             = out_dir, \n",
    "            basename            = basename,\n",
    "            method              = method,\n",
    "            incl_by_eye         = incl_by_eye,\n",
    "            by_eye_subset       = by_eye_subset,\n",
    "            pa_cutoff_val       = kwargs.get(\"pa_cutoff_val\", 10),\n",
    "            residual_cutoff_val = kwargs.get(\"residual_cutoff_val\", 0.5),\n",
    "            alen_cutoff_val     = kwargs.get(\"alen_cutoff_val\", 0.007)\n",
    "        )\n",
    "        \n",
    "        # Collating\n",
    "        all_results[basename] = analysis_results\n",
    "        \n",
    "        if write or show:\n",
    "            # OUTPUTTING PLOTS\n",
    "            fprint(\"CREATING PLOTS\")\n",
    "            _ = create_all_plots(\n",
    "                analysis_results, \n",
    "                method, \n",
    "                basename, \n",
    "                output_image_dir, \n",
    "                incl_by_eye = incl_by_eye,\n",
    "                show        = show,\n",
    "                pa_cutoff_val       = kwargs.get(\"pa_cutoff_val\", 10),\n",
    "                residual_cutoff_val = kwargs.get(\"residual_cutoff_val\", 0.5),\n",
    "                #alen_cutoff_val     = kwargs.get(\"alen_cutoff_val\", 0.007)\n",
    "                **plot_options[basename]\n",
    "                #xaxis_range_mag_hist = [10, 20],\n",
    "                #yaxis_range_mag_hist = [0, 0.15]\n",
    "            )\n",
    "\n",
    "        if print_latex or copy_png:\n",
    "            if incl_by_eye:\n",
    "                quantile_df = analysis_results.by_eye_success_df\n",
    "            else:\n",
    "                quantile_df = analysis_results.success_df\n",
    "\n",
    "            fprint(\"QUANTILING IMAGES FROM RESULTS\")\n",
    "            galaxy_set_q = create_quantiles(\n",
    "                out_dir, \n",
    "                #basename, \n",
    "                quantile_df,\n",
    "                method,\n",
    "                **kwargs\n",
    "                # print_latex = print_latex, \n",
    "                # copy_png = copy_png\n",
    "            )\n",
    "        \n",
    "        # Unfortunately have to do this after and have the user generate the pngs from here\n",
    "        # in order to rerun create_quantiles\n",
    "        if kwargs.get(\"prep_for_quantile\", False):\n",
    "            fprint(\"JUST KIDDING, EXTRACTING QUANTILED MODELS TO BE CONVERTED TO PNG\")\n",
    "            \n",
    "            to_untar = ' '.join([f\"./{gname}_galfit_out.fits\" for gname in galaxy_set_q])\n",
    "            tar_file = f\"{pj(out_dir, basename, basename)}_galfits.tar.gz\"\n",
    "            sp(f\"tar -xzvf {tar_file} --occurrence {to_untar}\")\n",
    "\n",
    "            _ = [shutil.move(f\"{gname}_galfit_out.fits\", f\"{pj(out_dir, basename, basename)}_galfits\")\n",
    "                 for gname in galaxy_set_q\n",
    "                ]\n",
    "            \n",
    "            print(f\"Please generate the pngs corresponding with the fits in the {pj(out_dir, basename, basename)}_galfits directory.\")\n",
    "            print(\"You may then proceed to run the 'create_quantiles' function again with copy_png set to True.\")\n",
    "    \n",
    "    if len(basenames) > 1:\n",
    "        fprint(\"COMBINING RESULTS FROM ALL RUNS FED IN\")\n",
    "        combined = combine_multi_run_results(\n",
    "            method,\n",
    "            *all_results.values(),\n",
    "            df_names      = basenames,\n",
    "            incl_by_eye   = incl_by_eye,\n",
    "            by_eye_subset = by_eye_subset\n",
    "        )\n",
    "        \n",
    "        prefixes = list(set([i.split(\"_\")[0] for i in basenames]))\n",
    "        if len(prefixes) == 1:\n",
    "            new_basename = f\"{prefixes[0]}_combined\"\n",
    "        else:\n",
    "            new_basename = \"combined\"\n",
    "        \n",
    "        all_results[new_basename] = combined\n",
    "        \n",
    "        if write or show:\n",
    "            try:\n",
    "                # OUTPUTTING PLOTS\n",
    "                fprint(\"CREATING PLOTS\")\n",
    "                _ = create_all_plots(\n",
    "                    combined, \n",
    "                    method, \n",
    "                    new_basename, \n",
    "                    output_image_dir, \n",
    "                    incl_by_eye = incl_by_eye,\n",
    "                    show        = show,\n",
    "                    pa_cutoff_val       = kwargs.get(\"pa_cutoff_val\", 10),\n",
    "                    residual_cutoff_val = kwargs.get(\"residual_cutoff_val\", 0.5),\n",
    "                    **plot_options[new_basename]\n",
    "                    #xaxis_range_mag_hist = [10, 20],\n",
    "                    #yaxis_range_mag_hist = [0, 0.15]\n",
    "                )\n",
    "            except KeyError as ke:\n",
    "                print(f\"Were plot options specified with the correct combined basename, {new_basename}?\")\n",
    "                print(\"Proceeding without plot options.\")\n",
    "                _ = create_all_plots(\n",
    "                    combined, \n",
    "                    method, \n",
    "                    new_basename, \n",
    "                    output_image_dir, \n",
    "                    incl_by_eye = incl_by_eye,\n",
    "                    show        = show,\n",
    "                    pa_cutoff_val       = kwargs.get(\"pa_cutoff_val\", 10),\n",
    "                    residual_cutoff_val = kwargs.get(\"residual_cutoff_val\", 0.5),\n",
    "                    #**plot_options[new_basename]\n",
    "                    #xaxis_range_mag_hist = [10, 20],\n",
    "                    #yaxis_range_mag_hist = [0, 0.15]\n",
    "                )\n",
    "\n",
    "        if print_latex or copy_png:\n",
    "            if incl_by_eye:\n",
    "                quantile_df = combined.by_eye_success_df\n",
    "            else:\n",
    "                quantile_df = combined.success_df\n",
    "\n",
    "            fprint(\"QUANTILING IMAGES FROM RESULTS\")\n",
    "            galaxy_set_q = create_quantiles(\n",
    "                out_dir, \n",
    "                #basename, \n",
    "                quantile_df,\n",
    "                method,\n",
    "                **kwargs\n",
    "                # print_latex = print_latex, \n",
    "                # copy_png = copy_png\n",
    "            )\n",
    "        \n",
    "        # Unfortunately have to do this after and have the user generate the pngs from here\n",
    "        # in order to rerun create_quantiles\n",
    "        if kwargs.get(\"prep_for_quantile\", False):\n",
    "            fprint(\"JUST KIDDING, EXTRACTING QUANTILED MODELS TO BE CONVERTED TO PNG\")\n",
    "            \n",
    "            to_untar = ' '.join([f\"./{gname}_galfit_out.fits\" for gname in galaxy_set_q])\n",
    "            tar_file = f\"{pj(out_dir, new_basename, new_basename)}_galfits.tar.gz\"\n",
    "            sp(f\"tar -xzvf {tar_file} --occurrence {to_untar}\")\n",
    "\n",
    "            _ = [shutil.move(f\"{gname}_galfit_out.fits\", f\"{pj(out_dir, new_basename, new_basename)}_galfits\")\n",
    "                 for gname in galaxy_set_q\n",
    "                ]\n",
    "            \n",
    "            print(f\"Please generate the pngs corresponding with the fits in the {pj(out_dir, basename, basename)}_galfits directory.\")\n",
    "            print(\"You may then proceed to run the 'create_quantiles' function again with copy_png set to True.\")\n",
    "        \n",
    "    fprint(\"DONE!!!\")\n",
    "    \n",
    "    # combined_bool_df only if applicable\n",
    "    # {basename : namedtuple (fields below), \"combined_bool_df\" : combined_bool_df}\n",
    "    # full_df, success_df, not_success_df, by_eye_success_df, by_eye_not_success_df\n",
    "    return all_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "4ca63ade-456e-41a4-baa5-4e2ae42875ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***************************** PERFORMING RESIDUAL ANALYSIS FOR 14_NC2 ******************************\n",
      "\n",
      "15 galaxy models generated.\n",
      "14 models pass score cutoff.\n",
      "13 pass pitch angle cutoff\n",
      "13 pass arm length ratio cutoff\n",
      "7 pass chiral agreement\n",
      "7 or 50.00% (7/14) succeed by SpArcFiRe+Score\n",
      "0/14 models failed reprocessing by SpArcFiRe\n",
      "\n",
      "Number of *total* by eye successful galaxies\n",
      "5   => 33.33%\n",
      "Number of by eye successful galaxies that SpArcFiRe *could* process\n",
      "5/5 => 100.00%\n",
      "\n",
      "Number of *total* by eye not successful galaxies\n",
      "9   => 60.00%\n",
      "Number of by eye not successful galaxies that SpArcFiRe *could* process\n",
      "9/9 => 100.00%\n",
      "\n",
      "False positive rate (by eye) -- 2/(2 + 9) = 18.18%\n",
      "False negative rate (by eye) -- 0/(0 + 5) = 0.00%\n",
      "\n",
      "****************************************** CREATING PLOTS ******************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31684/4284331768.py:115: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_31684/4284331768.py:115: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************************** QUANTILING IMAGES FROM RESULTS **********************************\n",
      "\n",
      "Deleting old latex output file...\n",
      "Writing latex to file testing_python_control/sparcfire-out/14_NC2/14_NC2_for_latex.txt\n",
      "\n",
      "***************************** PERFORMING RESIDUAL ANALYSIS FOR 14_NC3 ******************************\n",
      "\n",
      "15 galaxy models generated.\n",
      "14 models pass score cutoff.\n",
      "13 pass pitch angle cutoff\n",
      "14 pass arm length ratio cutoff\n",
      "12 pass chiral agreement\n",
      "12 or 85.71% (12/14) succeed by SpArcFiRe+Score\n",
      "0/14 models failed reprocessing by SpArcFiRe\n",
      "\n",
      "Number of *total* by eye successful galaxies\n",
      "11    => 73.33%\n",
      "Number of by eye successful galaxies that SpArcFiRe *could* process\n",
      "11/11 => 100.00%\n",
      "\n",
      "Number of *total* by eye not successful galaxies\n",
      "3   => 20.00%\n",
      "Number of by eye not successful galaxies that SpArcFiRe *could* process\n",
      "3/3 => 100.00%\n",
      "\n",
      "False positive rate (by eye) -- 3/(3 + 3) = 50.00%\n",
      "False negative rate (by eye) -- 2/(2 + 11) = 15.38%\n",
      "\n",
      "****************************************** CREATING PLOTS ******************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31684/4284331768.py:115: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_31684/4284331768.py:115: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************************** QUANTILING IMAGES FROM RESULTS **********************************\n",
      "\n",
      "Deleting old latex output file...\n",
      "Writing latex to file testing_python_control/sparcfire-out/14_NC3/14_NC3_for_latex.txt\n",
      "\n",
      "****************************** COMBINING RESULTS FROM ALL RUNS FED IN ******************************\n",
      "\n",
      "Joining 2 attempts...\n",
      "Total success by combining SpArcFiRe + score: 12/14\n",
      "i.e. success_n | success_m | ...\n",
      "\n",
      "Total success by combining SpArcFiRe + best score: 12/14\n",
      "i.e. minima -> success_minima\n",
      "\n",
      "========================================\n",
      "\n",
      "Checking against the by eye determination...\n",
      "Total success by eye: 11/14\n",
      "\n",
      "By eye captured by either score: 9/11\n",
      "i.e. (success_m | success_n | ...) & by eye\n",
      "\n",
      "By eye captured by best score: 10/11\n",
      "i.e. minima -> (success_minima & by eye)\n",
      "\n",
      "By eye captured by SpArcFiRe or choosing best score between the two runs: 10/11\n",
      "i.e. (minima -> [success_minima & by eye]) | ([success_m | success_n | ...] & by eye)\n",
      "\n",
      "========================================\n",
      "\n",
      "By eye success found by SpArcFiRe + score:  9/11 = 81.82%\n",
      "By eye not success found by SpArcFiRe + score:  0/3 = 0.00%\n",
      "\n",
      "False positive rate (by eye) -- 3 / (3 + 3) = 50.00%\n",
      "False negative rate (by eye) -- 2 / (2 + 11) = 15.38%\n",
      "\n",
      "****************************************** CREATING PLOTS ******************************************\n",
      "\n",
      "Were plot options specified with the correct combined basename, 14_combined?\n",
      "Proceeding without plot options.\n",
      "\n",
      "********************************** QUANTILING IMAGES FROM RESULTS **********************************\n",
      "\n",
      "Writing latex to file testing_python_control/sparcfire-out/14_combined/14_combined_for_latex.txt\n",
      "\n",
      "********************************************* DONE!!! **********************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    galaxy_set_14_results = main(\n",
    "        \"testing_python_control\", \n",
    "        \"14_NC2\", \n",
    "        \"14_NC3\",\n",
    "        incl_by_eye = True,\n",
    "        write       = True,\n",
    "        copy_png    = True,\n",
    "        print_latex = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "c22055f9-0b8d-47c8-b31a-8546d00d336a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************** PERFORMING RESIDUAL ANALYSIS FOR 1000_NC2 *****************************\n",
      "\n",
      "1000 galaxy models generated.\n",
      "909 models pass score cutoff.\n",
      "533 pass pitch angle cutoff\n",
      "896 pass arm length ratio cutoff\n",
      "708 pass chiral agreement\n",
      "367 or 36.70% (367/1000) succeed by SpArcFiRe+Score\n",
      "38/1000 models failed reprocessing by SpArcFiRe\n",
      "\n",
      "Number of *total* by eye successful galaxies\n",
      "406     => 40.60%\n",
      "Number of by eye successful galaxies that SpArcFiRe *could* process\n",
      "405/406 => 99.75%\n",
      "\n",
      "Number of *total* by eye not successful galaxies\n",
      "594     => 59.40%\n",
      "Number of by eye not successful galaxies that SpArcFiRe *could* process\n",
      "557/594 => 93.77%\n",
      "\n",
      "False positive rate (by eye) -- 145/(145 + 594) = 19.62%\n",
      "False negative rate (by eye) -- 184/(184 + 406) = 31.19%\n",
      "\n",
      "****************************************** CREATING PLOTS ******************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31684/4284331768.py:115: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_31684/4284331768.py:115: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************************** QUANTILING IMAGES FROM RESULTS **********************************\n",
      "\n",
      "Deleting old latex output file...\n",
      "Writing latex to file run13_for_paper/sparcfire-out/1000_NC2/1000_NC2_for_latex.txt\n",
      "\n",
      "**************************** PERFORMING RESIDUAL ANALYSIS FOR 1000_NC3 *****************************\n",
      "\n",
      "1000 galaxy models generated.\n",
      "896 models pass score cutoff.\n",
      "550 pass pitch angle cutoff\n",
      "861 pass arm length ratio cutoff\n",
      "693 pass chiral agreement\n",
      "335 or 33.50% (335/1000) succeed by SpArcFiRe+Score\n",
      "37/1000 models failed reprocessing by SpArcFiRe\n",
      "\n",
      "Number of *total* by eye successful galaxies\n",
      "422     => 42.20%\n",
      "Number of by eye successful galaxies that SpArcFiRe *could* process\n",
      "418/422 => 99.05%\n",
      "\n",
      "Number of *total* by eye not successful galaxies\n",
      "578     => 57.80%\n",
      "Number of by eye not successful galaxies that SpArcFiRe *could* process\n",
      "545/578 => 94.29%\n",
      "\n",
      "False positive rate (by eye) -- 116/(116 + 578) = 16.71%\n",
      "False negative rate (by eye) -- 203/(203 + 422) = 32.48%\n",
      "\n",
      "****************************************** CREATING PLOTS ******************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31684/4284331768.py:115: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_31684/4284331768.py:115: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************************** QUANTILING IMAGES FROM RESULTS **********************************\n",
      "\n",
      "Deleting old latex output file...\n",
      "Writing latex to file run13_for_paper/sparcfire-out/1000_NC3/1000_NC3_for_latex.txt\n",
      "\n",
      "****************************** COMBINING RESULTS FROM ALL RUNS FED IN ******************************\n",
      "\n",
      "Joining 2 attempts...\n",
      "Total success by combining SpArcFiRe + score: 520/1000\n",
      "i.e. success_n | success_m | ...\n",
      "\n",
      "Total success by combining SpArcFiRe + best score: 372/1000\n",
      "i.e. minima -> success_minima\n",
      "\n",
      "========================================\n",
      "\n",
      "Checking against the by eye determination...\n",
      "Total success by eye: 569/1000\n",
      "\n",
      "By eye captured by either score: 371/569\n",
      "i.e. (success_m | success_n | ...) & by eye\n",
      "\n",
      "By eye captured by best score: 467/569\n",
      "i.e. minima -> (success_minima & by eye)\n",
      "\n",
      "By eye captured by SpArcFiRe or choosing best score between the two runs: 522/569\n",
      "i.e. (minima -> [success_minima & by eye]) | ([success_m | success_n | ...] & by eye)\n",
      "\n",
      "========================================\n",
      "\n",
      "By eye success found by SpArcFiRe + score:  371/569 = 65.20%\n",
      "By eye not success found by SpArcFiRe + score:  282/431 = 65.43%\n",
      "\n",
      "False positive rate (by eye) -- 149 / (149 + 431) = 25.69%\n",
      "False negative rate (by eye) -- 198 / (198 + 569) = 25.81%\n",
      "\n",
      "****************************************** CREATING PLOTS ******************************************\n",
      "\n",
      "Were plot options specified with the correct combined basename, 1000_combined?\n",
      "Proceeding without plot options.\n",
      "\n",
      "********************************** QUANTILING IMAGES FROM RESULTS **********************************\n",
      "\n",
      "Writing latex to file run13_for_paper/sparcfire-out/1000_combined/1000_combined_for_latex.txt\n",
      "\n",
      "********************************************* DONE!!! **********************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # NC2\n",
    "    # xaxis_range_mag_hist = [10, 20],\n",
    "    # yaxis_range_mag_hist = [0, 0.15]\n",
    "    \n",
    "    # NC3\n",
    "    # xaxis_range_mag_hist = [10, 22],\n",
    "    # yaxis_range_mag_hist = [0, 0.3]\n",
    "    \n",
    "    plot_options = {\n",
    "        \"1000_NC2\" : {\n",
    "            \"xaxis_range_mag_hist\"    : [10, 20], #, \"yaxis_range_mag_hist\" : [0, 0.15]\n",
    "            \"xaxis_range_sersic_hist\" : [0, 5],\n",
    "            \"yaxis_range_sersic_hist\" : [0, 0.5]\n",
    "        },\n",
    "        \"1000_NC3\" : {\n",
    "            \"xaxis_range_mag_hist\"    : [10, 22], #, \"yaxis_range_mag_hist\" : [0, 0.35]\n",
    "            \"xaxis_range_sersic_hist\" : [0, 5],\n",
    "            \"yaxis_range_sersic_hist\" : [0, 0.5]\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    galaxy_set_elps_1000_results = main(\n",
    "        \"run13_for_paper\", \n",
    "        \"1000_NC2\", \n",
    "        \"1000_NC3\",\n",
    "        pa_cutoff_val       = 5,\n",
    "        alen_cutoff_val     = 0.5,\n",
    "        residual_cutoff_val = 0.007,\n",
    "        incl_by_eye = True,\n",
    "        write       = True,\n",
    "        copy_png    = True,\n",
    "        print_latex = True,\n",
    "        plot_options = plot_options\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3629ce-8f30-4459-8887-c43c2a5c88a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "galaxy_set_elps_1000_results[\"1000_combined\"].full_df.run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "63464946-41bd-4573-ac6a-279c63a14e30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***************************** PERFORMING RESIDUAL ANALYSIS FOR 29k_NC2 *****************************\n",
      "\n",
      "28912 galaxy models generated.\n",
      "28900 models pass score cutoff.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31684/4114222190.py:7: DtypeWarning:\n",
      "\n",
      "Columns (70) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16836 pass pitch angle cutoff\n",
      "14663 pass arm length ratio cutoff\n",
      "17012 pass chiral agreement\n",
      "7089 or 24.52% (7089/28911) succeed by SpArcFiRe+Score\n",
      "1685/28912 models failed reprocessing by SpArcFiRe\n",
      "\n",
      "Working on a subset of 1000 galaxies\n",
      "Number of *total* by eye successful galaxies\n",
      "358     => 35.80%\n",
      "Number of by eye successful galaxies that SpArcFiRe *could* process\n",
      "356/358 => 99.44%\n",
      "\n",
      "Number of *total* by eye not successful galaxies\n",
      "642     => 64.20%\n",
      "Number of by eye not successful galaxies that SpArcFiRe *could* process\n",
      "578/642 => 90.03%\n",
      "\n",
      "False positive rate (by eye) -- 87/(87 + 642) = 11.93%\n",
      "False negative rate (by eye) -- 202/(202 + 358) = 36.07%\n",
      "\n",
      "***************************** PERFORMING RESIDUAL ANALYSIS FOR 29k_NC3 *****************************\n",
      "\n",
      "28912 galaxy models generated.\n",
      "28878 models pass score cutoff.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31684/4114222190.py:7: DtypeWarning:\n",
      "\n",
      "Columns (70) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18538 pass pitch angle cutoff\n",
      "14899 pass arm length ratio cutoff\n",
      "18358 pass chiral agreement\n",
      "8149 or 28.19% (8149/28904) succeed by SpArcFiRe+Score\n",
      "1241/28912 models failed reprocessing by SpArcFiRe\n",
      "\n",
      "Working on a subset of 1000 galaxies\n",
      "Number of *total* by eye successful galaxies\n",
      "461     => 46.10%\n",
      "Number of by eye successful galaxies that SpArcFiRe *could* process\n",
      "459/461 => 99.57%\n",
      "\n",
      "Number of *total* by eye not successful galaxies\n",
      "539     => 53.90%\n",
      "Number of by eye not successful galaxies that SpArcFiRe *could* process\n",
      "498/539 => 92.39%\n",
      "\n",
      "False positive rate (by eye) -- 79/(79 + 539) = 12.78%\n",
      "False negative rate (by eye) -- 263/(263 + 461) = 36.33%\n",
      "\n",
      "****************************** COMBINING RESULTS FROM ALL RUNS FED IN ******************************\n",
      "\n",
      "Joining 2 attempts...\n",
      "Total success by combining SpArcFiRe + score: 12521/28912\n",
      "i.e. success_n | success_m | ... \n",
      "\n",
      "Total success by combining SpArcFiRe + best score: 8036/28912\n",
      "i.e. minima -> success_minima\n",
      "\n",
      "========================================\n",
      "\n",
      "Checking against the by eye determination...\n",
      "Using a subset of galaxies for the by eye determination...\n",
      "Total success by eye: 568/1000\n",
      "\n",
      "By eye captured by best score: 458/568\n",
      "i.e. minima -> (success_minima & by eye)\n",
      "\n",
      "By eye captured by SpArcFiRe or choosing best score between the two runs: 501/568\n",
      "i.e. (minima -> [success_minima & by eye]) | ([success_m | success_n] & by eye)\n",
      "\n",
      "========================================\n",
      "\n",
      "By eye success found by SpArcFiRe + score:  313/568 = 55.11%\n",
      "By eye not success found by SpArcFiRe + score:  323/432 = 74.77%\n",
      "\n",
      "False positive rate (by eye) -- 109 / (109 + 432) = 20.15%\n",
      "False negative rate (by eye) -- 255 / (255 + 568) = 30.98%\n",
      "\n",
      "********************************************* DONE!!! **********************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    plot_options = {\n",
    "        \"29k_NC2\" : {\n",
    "            \"xaxis_range_mag_hist\" : [9, 25], #\"yaxis_range_mag_hist\" : [0, 0.15]\n",
    "            \"xaxis_range_sersic_hist\" : [0, 5],\n",
    "            \"yaxis_range_sersic_hist\" : [0, 0.5]\n",
    "        },\n",
    "        \"29k_NC3\" : {\n",
    "            \"xaxis_range_mag_hist\"    : [9, 25], #\"yaxis_range_mag_hist\" : [0, 0.3]\n",
    "            \"xaxis_range_sersic_hist\" : [0, 5],\n",
    "            \"yaxis_range_sersic_hist\" : [0, 0.5]\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    galaxy_set_29k_results = main(\n",
    "        \"29k_galaxies\", \n",
    "        \"29k_NC2\", \n",
    "        \"29k_NC3\",\n",
    "        plot_options  = plot_options,\n",
    "        pa_cutoff_val   = 7,\n",
    "        alen_cutoff_val = 0.7,\n",
    "        write         = False,\n",
    "        incl_by_eye   = True,\n",
    "        by_eye_subset = 1000,\n",
    "        copy_png      = False,\n",
    "        print_latex   = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "f3518d87-0878-4c7a-a14a-0c36ce7fe1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['magnitude_sersic_1', 'effective_radius_sersic_1',\n",
       "       'sersic_index_sersic_1', 'axis_ratio_sersic_1',\n",
       "       'position_angle_sersic_1', 'position_x_sersic_1', 'position_y_sersic_1',\n",
       "       'skip_sersic_1', 'magnitude_sersic_2', 'effective_radius_sersic_2',\n",
       "       'sersic_index_sersic_2', 'axis_ratio_sersic_2',\n",
       "       'position_angle_sersic_2', 'position_x_sersic_2', 'position_y_sersic_2',\n",
       "       'skip_sersic_2', 'magnitude_sersic_3', 'effective_radius_sersic_3',\n",
       "       'sersic_index_sersic_3', 'axis_ratio_sersic_3',\n",
       "       'position_angle_sersic_3', 'position_x_sersic_3', 'position_y_sersic_3',\n",
       "       'skip_sersic_3', 'inner_rad_power_3', 'outer_rad_power_3',\n",
       "       'cumul_rot_power_3', 'powerlaw_index_power_3', 'inclination_power_3',\n",
       "       'sky_position_angle_power_3', 'F1_amplitude_fourier_3',\n",
       "       'F1_phase_angle_fourier_3', 'F3_amplitude_fourier_3',\n",
       "       'F3_phase_angle_fourier_3', 'skip_fourier_3', 'sky_background_sky_4',\n",
       "       'dsky_dx_sky_4', 'dsky_dy_sky_4', 'skip_sky_4', 'NMR', 'KS_P',\n",
       "       'inner_rad_power_2', 'outer_rad_power_2', 'cumul_rot_power_2',\n",
       "       'powerlaw_index_power_2', 'inclination_power_2',\n",
       "       'sky_position_angle_power_2', 'F1_amplitude_fourier_2',\n",
       "       'F1_phase_angle_fourier_2', 'F3_amplitude_fourier_2',\n",
       "       'F3_phase_angle_fourier_2', 'skip_fourier_2', 'nmr_x_1-p', 'pre_alen1',\n",
       "       'pre_alen2', 'pre_pa1', 'pre_pa2', 'post_alen1', 'post_alen2',\n",
       "       'post_pa1', 'post_pa2', 'chiral_agreement', 'pa_diff1', 'pa_diff2',\n",
       "       'pa_diff_galaxy', 'alen_ratio', 'min_pa_diff', 'success'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "galaxy_set_29k_results[\"29k_NC3\"].full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "a69dec47-aea0-4bb4-9826-e016a051866f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_to_evaluate = galaxy_set_29k_results[\"29k_NC2\"]\n",
    "pre_pa  = df_to_evaluate.full_df[[\"pre_pa1\" , \"pre_pa2\"]].mean(axis = 1).dropna()\n",
    "post_pa = df_to_evaluate.full_df[[\"post_pa1\", \"post_pa2\"]].mean(axis = 1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "971a4c50-422e-4520-9011-cd723dacd5cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_index = list(set(pre_pa.index).intersection(set(post_pa.index)))\n",
    "post_pa = post_pa[combined_index]\n",
    "pre_pa  = pre_pa[combined_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "c29661a5-36cc-4627-8b2f-bcfe04839cd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29k NC2\n",
      "PearsonRResult(statistic=0.006045526757101547, pvalue=0.3399548475956398)\n"
     ]
    }
   ],
   "source": [
    "print(\"29k NC2\")\n",
    "print(pearsonr(pre_pa,post_pa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "381285ed-0c4e-4269-8d55-f67ac07b1598",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_to_evaluate = galaxy_set_29k_results[\"29k_NC3\"]\n",
    "pre_pa  = df_to_evaluate.full_df[[\"pre_pa1\" , \"pre_pa2\"]].mean(axis = 1).dropna()\n",
    "post_pa = df_to_evaluate.full_df[[\"post_pa1\", \"post_pa2\"]].mean(axis = 1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "29b4b42f-9b51-41c2-884d-7fa22053a7f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_index = list(set(pre_pa.index).intersection(set(post_pa.index)))\n",
    "post_pa = post_pa[combined_index]\n",
    "pre_pa  = pre_pa[combined_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "eaa7f4f8-da6d-418a-9e19-a56d4ae76d39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29k NC3\n",
      "PearsonRResult(statistic=0.0127772371657911, pvalue=0.04143568397346512)\n"
     ]
    }
   ],
   "source": [
    "print(\"29k NC3\")\n",
    "print(pearsonr(pre_pa,post_pa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328b9189-3575-402a-ad1a-d364cb724eef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    galaxy_set_1000_results = main(\"29k_galaxies_gband\", \"29k_NC3_g\", incl_by_eye = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98498552-b0d1-4461-b28a-6412e2cc2213",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_images_old(input_df, png_dir:str, variable_name:str, custom_range = None):\n",
    "    images_out = []\n",
    "    \n",
    "    if not custom_range:\n",
    "        custom_range = range(0, len(input_df), 50) \n",
    "        \n",
    "    count = 0\n",
    "    for index_num in custom_range:\n",
    "        g_variable = input_df.iloc[index_num]\n",
    "        gname = g_variable.name\n",
    "        variable_value = g_variable[variable_name]#.norm_masked_residual\n",
    "\n",
    "        height = 500\n",
    "        width = 500\n",
    "        size = (height, width)\n",
    "        #out_str = galaxy_info.name.replace(\"galfit_out.fits\", \"combined.png\").strip()\n",
    "        out_str = f\"{gname}_combined.png\"\n",
    "        #print(out_str)\n",
    "        \n",
    "        \n",
    "        images_out.append(Image(filename = pj(png_dir, out_str), width=width, height=height))\n",
    "            \n",
    "        print(f\"{gname}, sorted #: {index_num}\")\n",
    "        print(f\"{variable_name} = {variable_value:.6f}\")\n",
    "        #print(f\"Dim: {galaxy_info['image_size']}x{galaxy_info['image_size']}\")\n",
    "        print()\n",
    "        \n",
    "    return images_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb0dadf-10a4-4c06-bfac-5c5ca8168990",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_to_disp = generate_images_old(full_df, pj(out_dir, \"galfit_png\"), \"diff\") #, range(0,len(full_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c716159c-c1f4-4aa2-89e5-8a99a118d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(*images_to_disp)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70746b6a-4331-43af-9972-17511a378117",
   "metadata": {
    "tags": []
   },
   "source": [
    "for png in glob.glob(pj(out_dir, \"scatter_plots\", \"*.png\")):\n",
    "    gname = os.path.basename(png).rstrip(\".png\")\n",
    "    if gname not in success_df.index and gname in constrained_df.index:\n",
    "        print(constrained_df.loc[gname, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd73b55-2bc5-46a9-9d47-16f472f03d31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_images(input_df, png_dir:str, cutoff_val = 0.01, variable_name = \"norm_masked_residual\", custom_range = None):\n",
    "    images_below_cutoff = []\n",
    "    images_above_cutoff = []\n",
    "    \n",
    "    if not custom_range:\n",
    "        custom_range = range(0, len(input_df), 50) \n",
    "    count = 0\n",
    "    for index_num in custom_range:\n",
    "        g_variable = input_df.iloc[index_num]\n",
    "        gname = g_variable.name\n",
    "        variable_value = g_variable[variable_name]#.norm_masked_residual\n",
    "\n",
    "        # iloc returns a series, name returns the name of the row\n",
    "\n",
    "        \n",
    "        # print(f\"chi^2/nu = {galaxy_info['chi^2_nu']:.2f}\")\n",
    "        # print(f\"chi^2 = {galaxy_info['chi^2']:.2f}\")\n",
    "        #print(f\"Norm GALFIT residual = {norm_galfit_residual:.4f}\")\n",
    "\n",
    "\n",
    "        # galfit_cmap = grayscale_cmap('RdBu')\n",
    "        # residual_plot = plt.imshow(np.flipud(masked_residual[:,:])) #, norm=colors.LogNorm())\n",
    "        # residual_plot.set_cmap('Greys')\n",
    "        # residual_plot.set_cmap(galfit_cmap)\n",
    "        # cbar = plt.colorbar()\n",
    "\n",
    "        #plt.imshow(residual_plot)\n",
    "        #imgplot = plt.imshow(arr[:, :, 0])\n",
    "        height = 500\n",
    "        width = 500\n",
    "        size = (height, width)\n",
    "        #out_str = galaxy_info.name.replace(\"galfit_out.fits\", \"combined.png\").strip()\n",
    "        out_str = f\"{gname}_combined.png\"\n",
    "        #print(out_str)\n",
    "        \n",
    "        if variable_value < cutoff_val:\n",
    "            images_below_cutoff.append(Image(filename = pj(png_dir, out_str), width=width, height=height))\n",
    "            #images_below_cutoff.append(PIL.Image.open(pj(png_dir, out_str)).resize(size))\n",
    "        else:\n",
    "            count += 1\n",
    "            if count == 1:\n",
    "                print(\"=\"*80)\n",
    "            images_above_cutoff.append(Image(filename = pj(png_dir, out_str), width=width, height=height))\n",
    "            #images_above_cutoff.append(PIL.Image.open(pj(png_dir, out_str)).resize(size))\n",
    "\n",
    "            \n",
    "        print(f\"{gname}, sorted #: {index_num}\")\n",
    "        print(f\"{variable_name} = {variable_value:.6f}\")\n",
    "        #print(f\"Dim: {galaxy_info['image_size']}x{galaxy_info['image_size']}\")\n",
    "        print()\n",
    "        \n",
    "    return images_below_cutoff, images_above_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa61e80e-f4c1-4c8c-b07f-f9ed0a1b56e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "png_dir = os.path.join(run_path, out_dir, \"galfit_png\")\n",
    "#below, above = generate_images(residual_df, png_dir, cutoff_val = 0.013342, variable_name = analysis_var, custom_range = range(700, len(residual_df), 10) )\n",
    "below, above = generate_images(residual_df, png_dir, cutoff_val = cutoff_val, variable_name = analysis_var, custom_range = range(800, len(residual_df), 10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d88e511-d149-424d-8a7e-6e8f4fe51dc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(*below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630341ca-75b3-4dc6-91b6-b9929e4f01a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(*above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9901973e-ac6f-4700-aa25-c14eab1075a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# good_fit = \"1237671262278582530\"\n",
    "# bad_fit = \"1237668366388756890\"\n",
    "\n",
    "# good_fit_obj = OutputFits(pj(out_dir, good_fit, f\"{good_fit}_galfit_out.fits\"))\n",
    "# bad_fit_obj = OutputFits(pj(out_dir, bad_fit, f\"{bad_fit}_galfit_out.fits\"))\n",
    "# good_residual = good_fit_obj.residual.data\n",
    "\n",
    "# scipy.stats.probplot(good_residual.flatten(), plot = plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ee8420-f01d-407b-a78f-7420e0244a93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bad_residual = bad_fit_obj.residual.data\n",
    "# scipy.stats.probplot(bad_residual.flatten(), plot = plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e075be-9f7e-4901-9c7c-a364497be181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to https://jakevdp.github.io/PythonDataScienceHandbook/04.07-customizing-colorbars.html\n",
    "def grayscale_cmap(cmap):\n",
    "    \"\"\"Return a grayscale version of the given colormap\"\"\"\n",
    "    cmap = plt.cm.get_cmap(cmap)\n",
    "    colors = cmap(np.arange(cmap.N))\n",
    "    \n",
    "    # convert RGBA to perceived grayscale luminance\n",
    "    # cf. http://alienryderflex.com/hsp.html\n",
    "    RGB_weight = [0.299, 0.587, 0.114]\n",
    "    luminance = np.sqrt(np.dot(colors[:, :3] ** 2, RGB_weight))\n",
    "    colors[:, :3] = luminance[:, np.newaxis]\n",
    "        \n",
    "    return LinearSegmentedColormap.from_list(cmap.name + \"_gray\", colors, cmap.N)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
