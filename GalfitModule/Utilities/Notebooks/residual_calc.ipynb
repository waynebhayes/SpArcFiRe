{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4247750-5fc9-4be0-8102-06041cdb7c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --user astropy\n",
    "#!pip3 install --user kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58b85295-242d-405b-ba3a-260bf8f72535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy as ap\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "import scipy.linalg as slg\n",
    "from scipy.stats import norm\n",
    "import scipy.stats\n",
    "from math import ceil\n",
    "import csv\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import iplot\n",
    "import kaleido\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.colors as colors\n",
    "# from matplotlib.colors import LinearSegmentedColormap\n",
    "import glob\n",
    "import os\n",
    "# These are in Functions\n",
    "from os.path import join as pj\n",
    "# from os.path import abspath as absp\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import PIL\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "from collections import namedtuple as nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a7e0271-d54c-42e1-a9e5-9527b166c8d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"SPARCFIRE_HOME\"] = \"/home/portmanm/sparcfire_matt/\"\n",
    "\n",
    "_HOME_DIR = os.path.expanduser(\"~\")\n",
    "try:\n",
    "    _SPARCFIRE_DIR = os.environ[\"SPARCFIRE_HOME\"]\n",
    "    _MODULE_DIR = pj(_SPARCFIRE_DIR, \"GalfitModule\")\n",
    "except KeyError:\n",
    "    if __name__ == \"__main__\":\n",
    "        print(\"SPARCFIRE_HOME is not set. Please run 'setup.bash' inside SpArcFiRe directory if not done so already.\")\n",
    "        print(\"Checking the current directory for GalfitModule, otherwise quitting.\")\n",
    "            \n",
    "        _MODULE_DIR = pj(os.getcwd(), \"GalfitModule\")\n",
    "        \n",
    "        if not exists(_MODULE_DIR):\n",
    "            raise Exception(\"Could not find GalfitModule!\")\n",
    "    \n",
    "sys.path.append(_MODULE_DIR)\n",
    "from Classes.Components import *\n",
    "from Classes.Containers import *\n",
    "from Classes.FitsHandlers import *\n",
    "from Functions.helper_functions import *\n",
    "\n",
    "all_results = nt(\"all_results\", [\"full_df\", \"success_df\", \"not_success_df\", \"by_eye_success_df\", \"by_eye_not_success_df\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de93171e-4ad6-4e16-acd3-8c302cb5d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Defunct\n",
    "# def check_galfit_chi(gal_name, base_path):\n",
    "#     # An example line\n",
    "#     # # Chi^2/nu = 4.661,  Chi^2 = 12025.575,  Ndof = 2580\n",
    "    \n",
    "#     #galfit_txt_out = \"galfit.01\" # in the future galfit.01 may change\n",
    "#     filename = os.path.join(base_path, gal_name, galfit_txt_out)\n",
    "#     with open(filename, \"r\") as f:\n",
    "#         for line in f:\n",
    "#             if \"Chi\" in line:\n",
    "#                 chi_line = line.strip(\"# \")\n",
    "    \n",
    "#     # This also works but it's quite devious...\n",
    "#     # chi_line.replace(\"^\", \"\").replace(\"/\", \"_\").replace(\",  \", \"\\n\").lower()\n",
    "#     # exec(chi_line)\n",
    "    \n",
    "#     out_vals = chi_line.split(\",\")\n",
    "#     chi2_nu = float(out_vals[0].strip().split(\"=\")[-1])\n",
    "#     chi2 = float(out_vals[1].strip().split(\"=\")[-1])\n",
    "#     ndof = int(out_vals[2].strip().split(\"=\")[-1])\n",
    "    \n",
    "#     return chi2_nu, chi2, ndof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47be9c91-a9a6-4971-b9d2-3be76d4b9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_galaxies(in_dir = \"sparcfire-in\", out_dir = \"sparcfire-out\"):   \n",
    "    all_gnames_in  = find_files(in_dir, \"123*\", \"f\")\n",
    "    all_gnames_out = find_files(out_dir, \"123*\", \"d\")\n",
    "    total_galaxies = min(len(all_gnames_in), len(all_gnames_out))\n",
    "    if not total_galaxies:\n",
    "        total_galaxies  = max(len(all_gnames_in), len(all_gnames_out))\n",
    "        \n",
    "    return total_galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3852834-9d54-461c-a344-73cdd407ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_residual_df(\n",
    "    out_dir, \n",
    "    basename, \n",
    "    method = \"nmr_x_1-p\", \n",
    "    verbose = True\n",
    "):\n",
    "    \n",
    "    pickle_filename = pj(out_dir, basename, sorted(find_files(pj(out_dir, basename), f'{basename}_output_results*.pkl', \"f\"))[-1])\n",
    "    \n",
    "    residual_df  = pd.read_pickle(pickle_filename)\n",
    "    # temp_df = deepcopy(residual_df)\n",
    "    # Setting residual columns\n",
    "    #residual_df[\"KS_P\"] = 1 - residual_df[\"KS_P\"]\n",
    "    if method == \"nmr_x_1-p\":\n",
    "        result_of_method = (1 - residual_df[\"KS_P\"])*residual_df[\"NMR\"]\n",
    "    elif method == \"nmr_neg_log\":\n",
    "        result_of_method = residual_df[\"NMR\"]/-np.log(residual_df[\"KS_P\"] + 1e-10)\n",
    "    elif method == \"W_quality\":\n",
    "        result_of_method = residual_df[\"KS_P\"]/residual_df[\"W_NMR\"]\n",
    "    else:\n",
    "        raise Exception(f\"Method given: {method} is not a valid method (yet).\")\n",
    "    \n",
    "    residual_df[method] = result_of_method\n",
    "    \n",
    "    # Valid meaning NMR was successfully calculated\n",
    "    #cols_to_drop = [col for col in residual_df.columns if col.endswith(\"_sky_2\")]\n",
    "    #valid_spiral_df = residual_df.drop(columns = cols_to_drop).dropna()\n",
    "\n",
    "    # rename sky_2 to sky_3 for non-spirals to be inline with everything else\n",
    "    # this would be for potential comparison down the line\n",
    "    cols_to_merge = [col for col in residual_df.columns if col.endswith(\"_sky_3\") or col.endswith(\"_sky_4\")]\n",
    "    #_ = [residual_df[col].fillna(residual_df[f\"{col[:-1]}2\"], inplace = True) for col in cols_to_merge]\n",
    "    cols_to_drop  = [col for col in residual_df.columns if col.endswith(\"_sky_2\") or col.endswith(\"_sky_3\")]#  + [\"KS_STAT\"]\n",
    "    residual_df.drop(columns = cols_to_drop, inplace = True)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"{len(residual_df)} galaxy models generated.\")\n",
    "        cutoff_val = 0.007\n",
    "        residual_cutoff = residual_df[\"nmr_x_1-p\"] <= cutoff_val\n",
    "        print(f\"{sum(residual_cutoff)} models pass score cutoff.\")\n",
    "        \n",
    "    \n",
    "    return residual_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f5cd1a4-3cf8-4c58-9178-ce87b4cd9278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_galaxy_csv(out_dir, basename, pre_post):\n",
    "    \n",
    "    field = \" pa_alenWtd_avg_domChiralityOnly\"\n",
    "    # {basename}_ uneccessary because different *galfit* runs \n",
    "    # should have same sparcfire output\n",
    "    fname = pj(out_dir, basename, f\"{basename}_{pre_post}_galfit_galaxy.csv\")\n",
    "    sparc_output_csv = pd.read_csv(fname, #pj(out_dir, f\"pre_galfit_galaxy.csv\"),\n",
    "                                       index_col = \"name\",\n",
    "                                       on_bad_lines = \"warn\",\n",
    "                                       usecols   = [\"name\", field], # , \" iptSz\"],\n",
    "                                       #na_values = \"NaN\",\n",
    "                                       #dtype     = {field : float} #, \" iptSz\" : str}#, \"name\" : str}\n",
    "                                      )#.loc[:, field]\n",
    "    #sparc_output_csv.index.name = None\n",
    "    sparc_output_csv[field] = sparc_output_csv[field].astype(float)\n",
    "    sparc_output_csv.index = sparc_output_csv.index.map(str)\n",
    "    #sparc_output_csv[\" iptSz\"] = sparc_output_csv[\" iptSz\"].str.extract(r\"([0-9]+)\").astype(float)\n",
    "\n",
    "    #sparc_output_csv[\"pre_sign\"] = np.sign(sparc_output_csv[field])\n",
    "    sparc_output_csv.rename(columns = {field : f\"galaxy_{pre_post}_pa\"}, inplace = True)\n",
    "    \n",
    "    return sparc_output_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a5e2491-9d83-4573-8826-ba9d91f5b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_galaxy_arcs_csv(out_dir, basename, pre_post, **kwargs):\n",
    "    \n",
    "    field_pa   = kwargs.get(\"field_pa\"  , \"pitch_angle\")\n",
    "    field_alen = kwargs.get(\"field_alen\", \"arc_length\")\n",
    "    name_col   = kwargs.get(\"name_col\"  , \"gxyName\")\n",
    "\n",
    "    fname = pj(out_dir, basename, f\"{basename}_{pre_post}_galfit_galaxy_arcs.csv\")\n",
    "    sparc_output_arcs_csv = pd.read_csv(fname, \n",
    "                                       index_col = name_col,\n",
    "                                       usecols   = [name_col, field_pa, field_alen],\n",
    "                                       dtype     = {field_pa : float, field_alen : float} #, name_col : str}\n",
    "                                      )#.loc[:, field]\n",
    "    #sparc_output_csv.index.name = None\n",
    "    sparc_output_arcs_csv.index = sparc_output_arcs_csv.index.map(str)\n",
    "\n",
    "    # Filtering for pure circles and near circles\n",
    "    sparc_output_arcs_csv = sparc_output_arcs_csv[abs(sparc_output_arcs_csv[field_pa ]) > 1]\n",
    "\n",
    "    #sparc_output_arcs_csv = pd.concat([sparc_output_arcs_csv, pre_sparc_output_csv], axis = 1)\n",
    "    #sparc_output_arcs_csv[\"sign\"] = np.sign(sparc_output_arcs_csv[field])\n",
    "\n",
    "    # Keeps only arms which align with dom chirality only\n",
    "    # sparc_output_arcs_csv[\"check\"] = [\n",
    "    #     row[\"sign\"] + pre_sparc_output_csv.loc[i, \"pre_sign\"] \n",
    "    #     if i in pre_sparc_output_csv.index \n",
    "    #     else None \n",
    "    #     for i, row in sparc_output_arcs_csv.iterrows()\n",
    "    # ]\n",
    "\n",
    "    #sparc_output_arcs_csv = sparc_output_arcs_csv[abs(sparc_output_arcs_csv.loc[:, \"check\"]) == 2].drop(columns = [\"sign\", \"check\"])\n",
    "    sparc_output_arcs_top3 = sparc_output_arcs_csv.groupby(name_col).head(3).reset_index()\n",
    "    sparc_output_arcs_top3[f\"{pre_post}_sign\"] = np.sign(sparc_output_arcs_top3.pitch_angle)\n",
    "\n",
    "    dom_sign = np.sign(sparc_output_arcs_top3.groupby(name_col).sum()[f\"{pre_post}_sign\"])\n",
    "    sparc_output_arcs_top3 = sparc_output_arcs_top3.join(dom_sign, rsuffix = \"_dom\", on = name_col)\n",
    "\n",
    "    cond = sparc_output_arcs_top3[f\"{pre_post}_sign_dom\"] == sparc_output_arcs_top3[f\"{pre_post}_sign\"]\n",
    "    sparc_output_arcs_top2 = sparc_output_arcs_top3[cond].groupby(name_col).head(2).reset_index().drop(columns = [f\"{pre_post}_sign_dom\", \"index\"])\n",
    "\n",
    "    #pre_sparc_output_top2.rename(columns = {field : \"pre_pa\"}, inplace = True)\n",
    "    #pre_sparc_output_csv.dropna(inplace=True)\n",
    "    return sparc_output_arcs_top2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc9d4a2f-ad1d-465a-9de9-dab0ffec7ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_arcs_output(sparc_output_arcs_top2, pre_post, **kwargs):\n",
    "    \n",
    "    field_pa   = kwargs.get(\"field_pa\"  , \"pitch_angle\")\n",
    "    field_alen = kwargs.get(\"field_alen\", \"arc_length\")\n",
    "    name_col   = kwargs.get(\"name_col\"  , \"gxyName\")\n",
    "    \n",
    "    single_arm = sparc_output_arcs_top2[~sparc_output_arcs_top2.duplicated(name_col, keep = False)]\n",
    "    single_arm.loc[:, field_pa] = 0\n",
    "    #single_arm.loc[:, \"arc_length\"]  = 0\n",
    "\n",
    "    filled_in = pd.concat([sparc_output_arcs_top2, single_arm], ignore_index = True)\n",
    "    str_fill = [f\"{pre_post}_pa1\", f\"{pre_post}_pa2\"] * (len(filled_in) // 2)\n",
    "    filled_in[\"temp1\"] = str_fill\n",
    "\n",
    "    str_fill = [f\"{pre_post}_alen1\", f\"{pre_post}_alen2\"] * (len(filled_in) // 2)\n",
    "    filled_in[\"temp2\"] = str_fill\n",
    "\n",
    "    #filled_in = filled_in.reset_index().drop(columns = [\"index\"])\n",
    "    sp_out = filled_in.pivot_table(index = name_col, columns = [\"temp1\", \"temp2\"], values = [field_pa, field_alen])\n",
    "\n",
    "    sp_out = sp_out.droplevel(0, axis = 1).droplevel(0, axis = 1)\n",
    "    sp_out.columns = [f'{pre_post}_alen1', f'{pre_post}_alen2', f'{pre_post}_pa1', f'{pre_post}_pa2']\n",
    "    \n",
    "    return sp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07dbb8f0-f2fd-4c0e-a3cd-76597837bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def before_after_galfit_comparison(all_sparc_out, pre_sparc_output_csv, post_sparc_output_csv):\n",
    "    \n",
    "    before_after_galfit_df = deepcopy(all_sparc_out)#.dropna() #full_df.dropna(subset = [\"post_pa\"])\n",
    "    #before_after_galfit_df = before_after_galfit_df[np.sign(before_after_galfit_df.loc[:, \"pre_pa\"]) != np.sign(before_after_galfit_df.loc[:, \"post_pa\"])]\n",
    "\n",
    "    before_after_galfit_df[\"chiral_agreement\"] = np.sign(before_after_galfit_df[\"pre_pa1\"]) == np.sign(before_after_galfit_df[\"post_pa1\"])\n",
    "\n",
    "    before_after_galfit_df[\"pre_pa1\"]  = abs(before_after_galfit_df[\"pre_pa1\"])\n",
    "    before_after_galfit_df[\"pre_pa2\"]  = abs(before_after_galfit_df[\"pre_pa2\"])\n",
    "    before_after_galfit_df[\"post_pa1\"] = abs(before_after_galfit_df[\"post_pa1\"])\n",
    "    before_after_galfit_df[\"post_pa2\"] = abs(before_after_galfit_df[\"post_pa2\"])\n",
    "\n",
    "\n",
    "    before_after_galfit_df[\"1-1\"] = abs(before_after_galfit_df[\"pre_pa1\"] - before_after_galfit_df[\"post_pa1\"])\n",
    "    before_after_galfit_df[\"2-2\"] = abs(before_after_galfit_df[\"pre_pa2\"] - before_after_galfit_df[\"post_pa2\"])\n",
    "    before_after_galfit_df[\"1-2\"] = abs(before_after_galfit_df[\"pre_pa1\"] - before_after_galfit_df[\"post_pa2\"])\n",
    "    before_after_galfit_df[\"2-1\"] = abs(before_after_galfit_df[\"pre_pa2\"] - before_after_galfit_df[\"post_pa1\"])\n",
    "\n",
    "    before_after_galfit_df[\"mean-1122\"]  = before_after_galfit_df[[\"1-1\",\"2-2\"]].mean(axis = \"columns\")\n",
    "    before_after_galfit_df[\"mean-1221\"]  = before_after_galfit_df[[\"1-2\",\"2-1\"]].mean(axis = \"columns\")\n",
    "\n",
    "    before_after_galfit_df[\"min_diff\"]   = before_after_galfit_df[[\"mean-1122\", \"mean-1221\"]].min(axis = 1)\n",
    "\n",
    "    before_after_galfit_df[\"best_diffs\"] = [\n",
    "        (row[\"1-1\"], row[\"2-2\"]) if np.mean((row[\"1-1\"], row[\"2-2\"])) == row[\"min_diff\"] \n",
    "        else (row[\"1-2\"], row[\"2-1\"]) \n",
    "        for _, row in before_after_galfit_df.iterrows()\n",
    "    ]\n",
    "\n",
    "    before_after_galfit_df[\"pa_diff1\"], before_after_galfit_df[\"pa_diff2\"] = zip(*before_after_galfit_df[\"best_diffs\"])\n",
    "    #before_after_galfit_df[\"best_diff2\"] = [row[\"2-2\"] if np.mean((row[\"1-1\"], row[\"2-2\"])) == row[\"min_diff\"] else row[\"2-1\"] for _, row in before_after_galfit_df.iterrows()]\n",
    "    before_after_galfit_df[\"pa_diff_galaxy\"] = abs(abs(post_sparc_output_csv[\"galaxy_post_pa\"]) - abs(pre_sparc_output_csv[\"galaxy_pre_pa\"]))# < 15\n",
    "\n",
    "    # min(2_arm_length)/max(2_arm_length) > 0.7, verify that this is valid by eye\n",
    "    #before_after_galfit_df[\"alen_ratio\"] = post_sparc_output_csv[\" iptSz\"]*before_after_galfit_df[[\"pre_alen1\", \"pre_alen2\"]].min(axis = 1)/(pre_sparc_output_csv[\" iptSz\"]*before_after_galfit_df[[\"post_alen1\", \"post_alen2\"]].max(axis = 1))\n",
    "    before_after_galfit_df[\"alen_ratio\"] = before_after_galfit_df[[\"post_alen1\", \"post_alen2\"]].min(axis = 1)/before_after_galfit_df[[\"post_alen1\", \"post_alen2\"]].max(axis = 1)\n",
    "    #before_after_galfit_df.drop(columns = [\"pre_sign\", \"post_sign\"], inplace = True)\n",
    "\n",
    "    # before_after_galfit_df.loc[:, \"within_15_degrees_pre\"]  = before_after_galfit_df.loc[:, \"diff_pre\"] < 15\n",
    "    # before_after_galfit_df.loc[:, \"within_15_degrees_post\"] = before_after_galfit_df.loc[:, \"diff_post\"] < 15\n",
    "    #before_after_galfit_df.sort_values(by = [\"post_pa\"])\n",
    "    before_after_galfit_df = before_after_galfit_df.drop(columns = before_after_galfit_df.columns[9:-4])\n",
    "    \n",
    "    return before_after_galfit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16e8bd45-f542-48a8-8923-1e07f5cbb9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_everything(residual_df, before_after_galfit_df):\n",
    "    full_df = residual_df.join(before_after_galfit_df)\n",
    "    full_df = full_df[full_df.index.notnull()].sort_values(by = method)\n",
    "\n",
    "    full_df.dropna(subset = [\"pa_diff1\", \"pa_diff2\", \"pa_diff_galaxy\"], how = \"all\", inplace = True)\n",
    "    full_df[\"min_pa_diff\"] = full_df[[\"pa_diff1\", \"pa_diff2\", \"pa_diff_galaxy\"]].min(axis = 1)\n",
    "    \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "850f1b7e-eb54-45d1-b759-dbfffc197ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_success(full_df, in_dir = \"sparcfire-in\", out_dir = \"sparcfire-out\", verbose = True, flip_chiral_agreement = False):\n",
    "    cutoff_val = 0.007\n",
    "    residual_cutoff = full_df[\"nmr_x_1-p\"] <= cutoff_val\n",
    "    #pa_cutoff = (full_df[\"pa_diff1\"] < 10) | (full_df[\"pa_diff2\"] < 10)\n",
    "    pa_cutoff   = full_df[\"min_pa_diff\"] < 10\n",
    "    alen_cutoff = full_df[\"alen_ratio\"] > 0.5 #[True]\n",
    "    sign_cutoff = full_df[\"chiral_agreement\"].astype(bool)\n",
    "    if flip_chiral_agreement:\n",
    "        sign_cutoff = ~sign_cutoff\n",
    "\n",
    "    success_df     = full_df[residual_cutoff & pa_cutoff & alen_cutoff & sign_cutoff]\n",
    "    not_success_df = full_df[~(residual_cutoff & pa_cutoff & alen_cutoff & sign_cutoff)]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"{len(full_df)} processed by sparcfire\")\n",
    "        print(f\"{sum(residual_cutoff)} pass score cutoff\")\n",
    "        print(f\"{sum(pa_cutoff)} pass pitch angle cutoff\")\n",
    "        print(f\"{sum(alen_cutoff)} pass arm length ratio cutoff\")\n",
    "        print(f\"{sum(sign_cutoff)} pass chiral agreement\")\n",
    "        print(f\"{len(success_df)} or {100*len(success_df)/len(full_df):.2f}% ({len(success_df)}/{len(full_df)}) succeed by SpArcFiRe+Score\")\n",
    "        print(f\"{total_galaxies - len(full_df)}/{total_galaxies} models failed reprocessing by SpArcFiRe\")\n",
    "        \n",
    "        #print(f\"Total success less 24% false positive -- {len(success_df)*.76:.0f}\")\n",
    "        #print(f\"Total success less 24% false positive + 24% false negative -- {len(not_success_df)*0.24+len(success_df)*.76:.0f}\")\n",
    "        #print(f\"Estimated total success % -- {100*(len(not_success_df)*0.24+len(success_df)*.76)/len(full_df):.0f}%\")\n",
    "    \n",
    "    return success_df, not_success_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28a24bed-8970-4c51-b8a9-83d51e80bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_by_eye_data(out_dir, basename, residual_df, full_df, subset = None,  verbose = True):\n",
    "    \n",
    "    with open(f\"{pj(out_dir, basename, basename)}_by-eye_success.txt\", \"r\") as f:\n",
    "        raw_by_eye_success_galaxies = [i.split(\"_\")[0].strip() for i in f.readlines()]\n",
    "\n",
    "    with open(f\"{pj(out_dir, basename, basename)}_by-eye_not_success.txt\", \"r\") as f:\n",
    "        raw_by_eye_not_success_galaxies = [i.split(\"_\")[0].strip() for i in f.readlines()]\n",
    "        \n",
    "    by_eye_success_galaxies = [i for i in raw_by_eye_success_galaxies if i in full_df.index]\n",
    "    by_eye_not_success_galaxies = [i for i in raw_by_eye_not_success_galaxies if i in full_df.index]\n",
    "    \n",
    "    if verbose:\n",
    "        \n",
    "        total = len(residual_df)\n",
    "        if subset:\n",
    "            total = subset\n",
    "            print(f\"Working on a subset of {total} galaxies\")\n",
    "            \n",
    "        align = len(f\"{len(by_eye_success_galaxies)}/{len(raw_by_eye_success_galaxies)}\")\n",
    "        print(f\"Number of *total* by eye successful galaxies\")\n",
    "        print(f\"{len(raw_by_eye_success_galaxies):<{align}} => {len(raw_by_eye_success_galaxies)/total*100:.2f}%\")\n",
    "        print(f\"Number of by eye successful galaxies that SpArcFiRe *could* process\")\n",
    "        print(f\"{len(by_eye_success_galaxies)}/{len(raw_by_eye_success_galaxies)} => {len(by_eye_success_galaxies)/len(raw_by_eye_success_galaxies)*100:.2f}%\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        align = len(f\"{len(by_eye_not_success_galaxies)}/{len(raw_by_eye_not_success_galaxies)}\")\n",
    "        print(f\"Number of *total* by eye not successful galaxies\")\n",
    "        \n",
    "        print(f\"{len(raw_by_eye_not_success_galaxies):<{align}} => {len(raw_by_eye_not_success_galaxies)/total*100:.2f}%\")\n",
    "        print(f\"Number of by eye not successful galaxies that SpArcFiRe *could* process\")\n",
    "        print(f\"{len(by_eye_not_success_galaxies)}/{len(raw_by_eye_not_success_galaxies)} => {len(by_eye_not_success_galaxies)/len(raw_by_eye_not_success_galaxies)*100:.2f}%\")\n",
    "    \n",
    "    return by_eye_success_galaxies, by_eye_not_success_galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f49f540e-82da-4e7b-8c61-6779c16075a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_false_positive_negative(\n",
    "    by_eye_success_galaxies, \n",
    "    by_eye_not_success_galaxies, \n",
    "    success_df, \n",
    "    not_success_df, \n",
    "    full_df,\n",
    "    verbose = True\n",
    "):\n",
    "    \n",
    "    false_positive = set(by_eye_not_success_galaxies).intersection(set(success_df.index))\n",
    "    false_negative = set(by_eye_success_galaxies).intersection(set(not_success_df.index))\n",
    "\n",
    "    by_eye_success_df     = full_df.loc[by_eye_success_galaxies].sort_values(by = method)\n",
    "    by_eye_not_success_df = full_df.loc[by_eye_not_success_galaxies].sort_values(by = method)\n",
    "\n",
    "    FP_rate = f\"{len(false_positive)}/({len(false_positive)} + {len(by_eye_not_success_df)})\"\n",
    "    FN_rate = f\"{len(false_negative)}/({len(false_negative)} + {len(by_eye_success_df)})\"\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"False positive rate (by eye) -- {FP_rate} = {100*eval(FP_rate):.2f}%\")\n",
    "        print(f\"False negative rate (by eye) -- {FN_rate} = {100*eval(FN_rate):.2f}%\")\n",
    "\n",
    "    #print(f\"Total # of galaxies sorted by eye -- {len(raw_by_eye_success_galaxies) + len(raw_by_eye_not_success_galaxies)}\")\n",
    "    return by_eye_success_df, by_eye_not_success_df, FP_rate, FN_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec6fcd6b-d3b1-4e8a-a675-1d196bbe4d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "    in_dir = \"sparcfire-in\", \n",
    "    out_dir = \"sparcfire-out\", \n",
    "    basename = \"\", \n",
    "    method = \"nmr_x_1-p\", \n",
    "    flip_chiral_agreement = False,\n",
    "    incl_by_eye = True,\n",
    "    by_eye_subset = None\n",
    "):\n",
    "    \n",
    "    residual_df = load_residual_df(out_dir, basename, method = method)\n",
    "    \n",
    "    # field_pa   = \"pitch_angle\"\n",
    "    # field_alen = \"arc_length\"\n",
    "    # name_col   = \"gxyName\"\n",
    "\n",
    "    pre_sparc_output_csv        = load_galaxy_csv(out_dir,      basename, pre_post = \"pre\")\n",
    "    pre_sparc_output_arcs_top2  = load_galaxy_arcs_csv(out_dir, basename, pre_post = \"pre\")\n",
    "\n",
    "    post_sparc_output_csv       = load_galaxy_csv(out_dir,      basename, pre_post = \"post\")\n",
    "    post_sparc_output_arcs_top2 = load_galaxy_arcs_csv(out_dir, basename, pre_post = \"post\")\n",
    "\n",
    "# ====================================================================================================================\n",
    "\n",
    "    pre_sp_out    = prepare_arcs_output(pre_sparc_output_arcs_top2,  pre_post = \"pre\")\n",
    "    post_sp_out   = prepare_arcs_output(post_sparc_output_arcs_top2, pre_post = \"post\")\n",
    "\n",
    "    all_sparc_out = pd.concat([pre_sp_out, post_sp_out], axis = 1)\n",
    "    \n",
    "# ====================================================================================================================\n",
    "\n",
    "    before_after_galfit_df     = before_after_galfit_comparison(\n",
    "        all_sparc_out, \n",
    "        pre_sparc_output_csv, \n",
    "        post_sparc_output_csv\n",
    "    )\n",
    "    \n",
    "    full_df                    = gather_everything(residual_df, before_after_galfit_df)\n",
    "    \n",
    "    success_df, not_success_df = determine_success(full_df, in_dir = in_dir, out_dir = out_dir, flip_chiral_agreement = flip_chiral_agreement)\n",
    "    \n",
    "    full_df[\"success\"] = full_df.index.isin(success_df.index)\n",
    "    print()\n",
    "    \n",
    "# ====================================================================================================================\n",
    "    \n",
    "    by_eye_success_df     = None\n",
    "    by_eye_not_success_df = None\n",
    "    \n",
    "    if incl_by_eye:\n",
    "        by_eye_success_galaxies, by_eye_not_success_galaxies = extract_by_eye_data(out_dir, basename, residual_df, full_df, subset = by_eye_subset)\n",
    "        print()\n",
    "\n",
    "        # To resolve an occasional processing error...\n",
    "        by_eye_success_limited     = list(set(by_eye_success_galaxies).intersection(full_df.index))\n",
    "        by_eye_not_success_limited = list(set(by_eye_not_success_galaxies).intersection(full_df.index))\n",
    "\n",
    "        by_eye_success_df, by_eye_not_success_df, FP_rate, FN_rate = calculate_false_positive_negative(\n",
    "            by_eye_success_limited, \n",
    "            by_eye_not_success_limited, \n",
    "            success_df, \n",
    "            not_success_df, \n",
    "            full_df\n",
    "        )\n",
    "\n",
    "        full_df[\"by_eye_success\"] = full_df.index.isin(by_eye_success_df.index)\n",
    "    \n",
    "    return all_results(full_df, success_df, not_success_df, by_eye_success_df, by_eye_not_success_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e86d3aa8-f9c3-4490-9092-cc594f47de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_multi_run_results(\n",
    "    method, \n",
    "    *args, \n",
    "    df_names = [],\n",
    "    incl_by_eye = True,\n",
    "    verbose = True\n",
    "):\n",
    "    \n",
    "    print(f\"Joining {len(args)} attempts...\")\n",
    "    primary_full_df = deepcopy(args[0].full_df)\n",
    "    \n",
    "    num_dfs = len(args)\n",
    "    #alt_full_df     = deepcopy(args[1].full_df)\n",
    "    #alt_full_df.rename(columns = {method : f\"1_{method}\"}, inplace = True)\n",
    "\n",
    "    all_full_dfs = [primary_full_df]\n",
    "    all_methods  = [method]\n",
    "    \n",
    "    for i, arg in enumerate(args[1:]):\n",
    "        alt_method = f\"{i}_{method}\"\n",
    "        all_methods.append(alt_method)\n",
    "        all_full_dfs.append(arg.full_df.rename(columns = {method : alt_method}))\n",
    "\n",
    "    # BY RESIDUAL\n",
    "    #temp_bool_df = pd.concat([primary_full_df[method], alt_full_df[f\"1_{method}\"]], axis = 1)\n",
    "    combined_bool_df = pd.concat([df[method] for df, method in zip(all_full_dfs, all_methods)], axis = 1)\n",
    "\n",
    "    #combined_bool_df.drop(index = list(set(primary_full_df.index).difference(set(alt_full_df.index))), inplace = True)\n",
    "    #temp_bool_df[\"minima\"] = temp_bool_df.idxmin(axis = 1)\n",
    "    combined_bool_df[\"minima\"] = combined_bool_df.idxmin(axis = 1)\n",
    "    \n",
    "    #og_minima  = temp_bool_df.minima == method\n",
    "    #alt_minima = temp_bool_df.minima == f\"1_{method}\"\n",
    "    minima_conditions = [combined_bool_df.minima == method for method in all_methods]\n",
    "    \n",
    "    #og_success = temp_bool_df.index.isin(args[0].by_eye_success_df.index)\n",
    "    #alt_success = temp_bool_df.index.isin(args[1].by_eye_success_df.index)\n",
    "    #print(sum((og_minima & og_success) | (alt_minima & alt_success)))\n",
    "        \n",
    "    # By everything\n",
    "    eval_str = \" | \".join([f\"all_full_dfs[{i}].success\" for i in range(num_dfs)])\n",
    "    combined_bool_df[\"by_sparcfire_success\"] = eval(eval_str) #primary_full_df.success | alt_full_df.success # | combined_bool_df.residual_minima_success\n",
    "    \n",
    "    if incl_by_eye:\n",
    "        by_eye_success_conditions = [combined_bool_df.index.isin(df.by_eye_success_df.index) for df in args]\n",
    "\n",
    "        all_conditions = zip(minima_conditions, by_eye_success_conditions)\n",
    "        list_o_conditions = [cond_set[0] & cond_set[1] for cond_set in all_conditions]\n",
    "        eval_str = \" | \".join([f\"list_o_conditions[{i}]\" for i in range(num_dfs)])\n",
    "\n",
    "        combined_bool_df[\"residual_minima_success\"] = eval(eval_str) \n",
    "        # print(sum((minima_conditions[0] & by_eye_success_conditions[0]) | (minima_conditions[1] & by_eye_success_conditions[1])))\n",
    "        # print(sum(list_o_conditions[0] | list_o_conditions[1]))\n",
    "\n",
    "        #eval_str = \" | \".join([df.success for df in all_df])\n",
    "        combined_bool_df[\"by_minima_and_sparcfire_success\"] = combined_bool_df.by_sparcfire_success | combined_bool_df.residual_minima_success\n",
    "    \n",
    "        # by eye success for all labeled by df\n",
    "        best_fit_str_dict = {m : f\"df_{i}\" for i, m in enumerate(all_methods)}\n",
    "        combined_bool_df[\"best_fit\"] = None\n",
    "\n",
    "        for gname, row in combined_bool_df.iterrows():\n",
    "            best_method = [\n",
    "                (m, full_df.loc[gname, \"by_eye_success\"]) \n",
    "                for m, full_df in zip(all_methods, all_full_dfs)\n",
    "                if gname in full_df.index and full_df.loc[gname, \"by_eye_success\"]\n",
    "            ]\n",
    "\n",
    "            if len(best_method) > 1:\n",
    "                best_method = [(row.minima, None)]\n",
    "\n",
    "            elif not best_method:\n",
    "                best_method = [(None, None)]\n",
    "\n",
    "            if not combined_bool_df.loc[gname, \"best_fit\"]:\n",
    "                combined_bool_df.loc[gname, \"best_fit\"] = best_fit_str_dict.get(best_method[0][0], None)\n",
    "\n",
    "        #eval_str = \" | \".join([f\"all_full_dfs[{i}].by_eye_success\" for i, _ in enumerate(all_full_dfs)])\n",
    "        #combined_bool_df[\"by_eye_success\"] = eval(eval_str) #primary_full_df.by_eye_success | alt_full_df.by_eye_success\n",
    "        combined_bool_df[\"by_eye_success\"] = False | combined_bool_df.best_fit.str.contains(\"df\")\n",
    "\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Total success by combining SpArcFiRe + score: {sum(combined_bool_df.by_sparcfire_success)}/{total_galaxies}\")\n",
    "        \n",
    "        if incl_by_eye:\n",
    "            if df_names:\n",
    "                if len(df_names) != num_dfs: \n",
    "                    print(\"Length of dataframe names supplied should be equal to the number of dataframes supplied.\")\n",
    "                    print(\"Leaving current convention in the dataframe (df_0, df_1, ..., df_n)\")\n",
    "                else:\n",
    "                    combined_bool_df[\"best_fit\"]   = combined_bool_df.best_fit.replace({f\"df_{i}\" : name for i, name in enumerate(df_names)})\n",
    "                    \n",
    "            print(f\"Total success by best score: {sum(combined_bool_df.residual_minima_success)}/{total_galaxies}\")\n",
    "            print(f\"Total success by SpArcFiRe and best score between the two runs: {sum(combined_bool_df.by_minima_and_sparcfire_success)}/{total_galaxies}\")\n",
    "            print(f\"Total success by eye: {sum(combined_bool_df.by_eye_success)}/{total_galaxies}\")\n",
    "            print()\n",
    "\n",
    "            bss  = set(combined_bool_df[combined_bool_df[\"by_sparcfire_success\"]].index)\n",
    "            TP   = set(combined_bool_df[combined_bool_df[\"by_eye_success\"]].index)\n",
    "            bsns = set(combined_bool_df[~combined_bool_df[\"by_sparcfire_success\"]].index)\n",
    "            TN   = set(combined_bool_df[~combined_bool_df[\"by_eye_success\"]].index)\n",
    "\n",
    "            FP   = bss.intersection(TN)\n",
    "            FN   = bsns.intersection(TP)\n",
    "\n",
    "            sparc_positive = bss.intersection(TP)\n",
    "            fraction = len(sparc_positive)/sum(combined_bool_df.by_eye_success)\n",
    "            # FPR = FP/(FP + TN)\n",
    "            # FNR = FN/(FN + TP)\n",
    "            print(f\"By eye success found by SpArcFiRe+score:  {len(sparc_positive)}/{sum(combined_bool_df.by_eye_success)} = {100*fraction:.2f}%\")\n",
    "            FP_rate = f\"{len(FP)} / ({len(FP)} + {len(TN)})\"\n",
    "            FN_rate = f\"{len(FN)} / ({len(FN)} + {len(TP)})\"\n",
    "\n",
    "            print(f\"False positive rate (by eye) -- {FP_rate} = {100*eval(FP_rate):.2f}%\")\n",
    "            print(f\"False negative rate (by eye) -- {FN_rate} = {100*eval(FN_rate):.2f}%\")\n",
    "    \n",
    "    #combined_success_df = pd.concat\n",
    "    \n",
    "    return combined_bool_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "693a33b8-825d-40d2-88ec-906322df9ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_ecdf(x, runname, df, dict_o_kwargs):\n",
    "    \n",
    "    # for key, default in exec_kwargs().items():\n",
    "    #     exec(f\"{key} = kwargs.get({key}, {default})\")\n",
    "    # Yeesh https://stackoverflow.com/a/67367191\n",
    "    # Use frame(3) since these functions are nested\n",
    "    sys._getframe(3).f_locals.update(dict_o_kwargs)\n",
    "\n",
    "    fig = px.ecdf(df,\n",
    "                  x = x,\n",
    "                  markers = True, \n",
    "                  lines = False, \n",
    "                  marginal = \"histogram\",\n",
    "                  ecdfnorm = None,\n",
    "                  log_x    = log_x,\n",
    "                  log_y    = log_y\n",
    "                 ) \n",
    "\n",
    "    if add_vline:\n",
    "        fig.add_vline(x = cutoff_val, \n",
    "                      row = 1,\n",
    "                      line_color = \"cyan\",\n",
    "                      annotation_text= f\"{cutoff_val}\", \n",
    "                      annotation_position=\"bottom\")\n",
    "\n",
    "    if add_hline:\n",
    "        yval = sum(df.loc[:, x] < cutoff_val)\n",
    "        fig.add_hline(y = yval, \n",
    "                      row = 1,\n",
    "                      col = 1,\n",
    "                      line_color = \"magenta\",\n",
    "                      annotation_text=f\"{yval}\",\n",
    "                      annotation_position=\"bottom left\"\n",
    "                     )\n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8fe7455-01b0-477f-beb7-0d72b1af46db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_scatter(x, runname, df, dict_o_kwargs):\n",
    "    \n",
    "    sys._getframe(3).f_locals.update(dict_o_kwargs)\n",
    "        \n",
    "    fig = px.scatter(df, \n",
    "               x = x, \n",
    "               y = y, \n",
    "               color = color,\n",
    "               color_continuous_scale = \"Agsunset\",\n",
    "                    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbe217be-635a-4f9a-85d1-bf40d0bb4fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_histogram(x, runname, df, dict_o_kwargs, multi):\n",
    "    \n",
    "    sys._getframe(3).f_locals.update(dict_o_kwargs)\n",
    "    \n",
    "    fig = px.histogram(\n",
    "        df,\n",
    "        x         = x,\n",
    "        color     = color,\n",
    "        histnorm  = histnorm,\n",
    "        facet_col = facet_col,\n",
    "        facet_row = facet_row,\n",
    "        nbins     = nbins,\n",
    "        #hover_data = {'Galaxy ID': (\":c\", full_df.index)},\n",
    "        log_x     = log_x,\n",
    "        log_y     = log_y,\n",
    "    )\n",
    "    \n",
    "    if facet_col or facet_row:\n",
    "        fig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\n",
    "\n",
    "    if multi:\n",
    "        fig.update_layout(barmode = \"overlay\")\n",
    "        fig.update_traces(opacity = 0.75)\n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c26146b-9f20-456d-aa64-f0e0b56a6225",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_plot(x, runname, plot_type, df, output_image_dir = \"for_paper_images\", **kwargs):\n",
    "        \n",
    "    dict_o_kwargs = {\n",
    "        \"y\"               : None,\n",
    "        \"color\"           : None,\n",
    "        \n",
    "        \"xaxis_title\"     : \"\",\n",
    "        \"yaxis_title\"     : \"\",\n",
    "        \n",
    "        \"xaxis_range\"     : None,\n",
    "        \"yaxis_range\"     : None,\n",
    "        \n",
    "        \"log_x\"           : False,\n",
    "        \"log_y\"           : False,\n",
    "        \n",
    "        \"histnorm\"        : \"\",\n",
    "        \"facet_col\"       : None,\n",
    "        \"facet_row\"       : None,\n",
    "        \n",
    "        \"nbins\"           : 0,\n",
    "        \n",
    "        \"cutoff_val\"      : 0.007,\n",
    "        \"add_vline\"       : True,\n",
    "        \"add_hline\"       : True,\n",
    "        \n",
    "        \"title\"           : \"\",\n",
    "        \"title_x\"         : 0.9,\n",
    "        \"title_y\"         : 0.5,\n",
    "\n",
    "        \"paper_image_dir\" : paper_image_dir,\n",
    "        \"filetype\"        : \"png\",\n",
    "        \"show\"            : True,\n",
    "        \"write\"           : True\n",
    "    }\n",
    "    \n",
    "    # Updating with kwargs\n",
    "    dict_o_kwargs = {key : kwargs.get(key, default) for key, default in dict_o_kwargs.items()}\n",
    "    \n",
    "    plt.clf()\n",
    "    if plot_type == \"ecdf\":\n",
    "        fig = create_ecdf(x, runname, df, dict_o_kwargs)\n",
    "    elif plot_type == \"scatter\":\n",
    "        fig = create_scatter(x, runname, df, dict_o_kwargs)\n",
    "    elif plot_type == \"histogram\":\n",
    "        multi = kwargs.get(\"multi\", True)\n",
    "        fig = create_histogram(x, runname, df, dict_o_kwargs, multi)\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    sys._getframe(2).f_locals.update(dict_o_kwargs)\n",
    "    \n",
    "    if title:\n",
    "        fig.update_layout(\n",
    "            title_text = title, \n",
    "            title_x    = title_x, \n",
    "            title_y    = title_y\n",
    "        )\n",
    "        \n",
    "    if xaxis_title:\n",
    "        fig.update_layout(xaxis_title = xaxis_title)\n",
    "    if yaxis_title:\n",
    "        fig.update_layout(yaxis_title = yaxis_title)\n",
    "        \n",
    "    if xaxis_range:\n",
    "        fig.update_layout(xaxis_range = xaxis_range)\n",
    "    if yaxis_range:\n",
    "        fig.update_layout(yaxis_range = yaxis_range)\n",
    "    \n",
    "    if show:\n",
    "        fig.show()\n",
    "        \n",
    "    if write:\n",
    "        fig.write_image(f\"{output_image_dir}/{plot_type}_{runname}_{x}.{filetype}\", width = 1200)\n",
    "        \n",
    "    fig.data   = []\n",
    "    fig.layout = {}\n",
    "    \n",
    "    #return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "524b8133-afce-4840-9a24-9d145858b41f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_all_plots(\n",
    "    df_container, \n",
    "    method, \n",
    "    basename, \n",
    "    output_image_dir, \n",
    "    show = True, \n",
    "    write = True, \n",
    "    **kwargs\n",
    "):\n",
    "        \n",
    "    plot_df = df_container.full_df[df_container.full_df.loc[:, method] < kwargs.get(\"score_ecdf_cutoff\", 0.015)]\n",
    "\n",
    "    _ = create_plot(\n",
    "        x                = method,\n",
    "        runname          = basename,\n",
    "        plot_type        = \"ecdf\",\n",
    "        df               = plot_df,\n",
    "        output_image_dir = output_image_dir,\n",
    "        xaxis_title      = \"KStest+NMR\",\n",
    "        # title       = f\"1000 galaxies: ECDF for KStest+NMR on all models\",\n",
    "        # title_y     = 0.92\n",
    "        show             = show,\n",
    "        write            = write\n",
    "    )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# SERSIC INDEX HISTOGRAMS\n",
    "# ============================================================================================================================================================\n",
    "\n",
    "    x1   = \"sersic_index_sersic_1\"\n",
    "    x2   = \"sersic_index_sersic_2\"\n",
    "    x    = \"n\"\n",
    "    fcol = \"domain\"\n",
    "\n",
    "    # By eye success\n",
    "    plot_df = df_container.by_eye_success_df[[x1,x2]].rename(columns = {x1 : \"bulge\", x2 : \"disk\"})\n",
    "    plot_df = pd.melt(plot_df).rename(columns   = {\"value\" : x, \"variable\" : \"component\"})\n",
    "    plot_df[fcol] = \"by-eye success\"\n",
    "\n",
    "    plot_df1 = df_container.success_df[[x1,x2]].rename(columns = {x1 : \"bulge\", x2 : \"disk\"})\n",
    "    plot_df1 = pd.melt(plot_df1).rename(columns = {\"value\" : x, \"variable\" : \"component\"})\n",
    "    plot_df1[fcol] = \"success\"\n",
    "\n",
    "    plot_df2 = df_container.full_df[[x1,x2]].rename(columns = {x1 : \"bulge\", x2 : \"disk\"})\n",
    "    plot_df2 = pd.melt(plot_df2).rename(columns = {\"value\" : x, \"variable\" : \"component\"})\n",
    "    plot_df2[fcol] = \"all models\"\n",
    "\n",
    "    plot_df = pd.concat([plot_df, plot_df1, plot_df2], axis = 0)\n",
    "\n",
    "    _ = create_plot(\n",
    "        x                = x,\n",
    "        runname          = f\"{basename}_by-eye-vs-success-vs-all\",\n",
    "        plot_type        = \"histogram\",\n",
    "        df               = plot_df,\n",
    "        output_image_dir = output_image_dir,\n",
    "        histnorm         = \"probability\",\n",
    "        color            = \"component\",\n",
    "        nbins            = 40,\n",
    "        facet_col        = fcol,\n",
    "        xaxis_range      = kwargs.get(\"xaxis_range_sersic_hist\", None), # [10, 20],\n",
    "        yaxis_range      = kwargs.get(\"xaxis_range_sersic_hist\", None), # [0, 0.15],\n",
    "        # title       = f\"{runname} galaxies: distribution of magnitudes for by-eye successful models\"\n",
    "        # title_y     = 0.85\n",
    "        show             = show,\n",
    "        write            = write\n",
    "    )\n",
    "\n",
    "    # _ = create_plot(\n",
    "    #     x           = x,\n",
    "    #     runname     = \"1000_by-eye\",\n",
    "    #     plot_type   = \"histogram\",\n",
    "    #     df          = plot_df,\n",
    "    #     color       = \"component\",\n",
    "    #     # title       = f\"{runname} galaxies: distribution of Sérsic indices for by-eye successful models\"\n",
    "    #     # title_y     = 0.85\n",
    "    #     show        = show\n",
    "    # )\n",
    "\n",
    "    # # All results\n",
    "    # plot_df = full_df[[x1,x2]].rename(columns = {x1 : \"bulge\", x2 : \"disk\"})\n",
    "    # plot_df = pd.melt(plot_df).rename(columns = {\"value\" : x, \"variable\" : \"component\"})\n",
    "\n",
    "    # _ = create_plot(\n",
    "    #     x           = x,\n",
    "    #     runname     = \"1000\",\n",
    "    #     plot_type   = \"histogram\",\n",
    "    #     df          = plot_df,\n",
    "    #     color       = \"component\",\n",
    "    #     # title       = f\"{runname} galaxies: distribution of Sérsic indices for by-eye successful models\"\n",
    "    #     # title_y     = 0.85\n",
    "    #     show        = show\n",
    "    # )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# MAGNITUDE HISTOGRAMS \n",
    "# ============================================================================================================================================================\n",
    "    \n",
    "    # TODO: Combine these into one plot either using facet or go\n",
    "    # https://plotly.com/python/subplots/\n",
    "    # or https://plotly.com/python/facet-plots/\n",
    "\n",
    "    x1   = \"magnitude_sersic_1\"\n",
    "    x2   = \"magnitude_sersic_2\"\n",
    "    x    = \"m\"\n",
    "    fcol = \"domain\"\n",
    "\n",
    "    plot_df = df_container.by_eye_success_df[[x1,x2]].rename(columns = {x1 : \"bulge\", x2 : \"disk\"})\n",
    "    plot_df = pd.melt(plot_df).rename(columns   = {\"value\" : x, \"variable\" : \"component\"})\n",
    "    plot_df[fcol] = \"by-eye success\"\n",
    "\n",
    "    plot_df1 = df_container.success_df[[x1,x2]].rename(columns = {x1 : \"bulge\", x2 : \"disk\"})\n",
    "    plot_df1 = pd.melt(plot_df1).rename(columns = {\"value\" : x, \"variable\" : \"component\"})\n",
    "    plot_df1[fcol] = \"success\"\n",
    "\n",
    "    plot_df2 = df_container.full_df[[x1,x2]].rename(columns = {x1 : \"bulge\", x2 : \"disk\"})\n",
    "    plot_df2 = pd.melt(plot_df2).rename(columns = {\"value\" : x, \"variable\" : \"component\"})\n",
    "    plot_df2[fcol] = \"all models\"\n",
    "\n",
    "    plot_df = pd.concat([plot_df, plot_df1, plot_df2], axis = 0)\n",
    "\n",
    "    _ = create_plot(\n",
    "        x                = x,\n",
    "        runname          = f\"{basename}_by-eye-vs-success-vs-all\",\n",
    "        plot_type        = \"histogram\",\n",
    "        df               = plot_df,\n",
    "        output_image_dir = output_image_dir,\n",
    "        histnorm         = \"probability\",\n",
    "        color            = \"component\",\n",
    "        facet_col        = fcol,\n",
    "        xaxis_range      = kwargs.get(\"xaxis_range_mag_hist\", None), # [10, 20],\n",
    "        yaxis_range      = kwargs.get(\"yaxis_range_mag_hist\", None), # [0, 0.15],\n",
    "        # title       = f\"{runname} galaxies: distribution of magnitudes for by-eye successful models\"\n",
    "        # title_y     = 0.85\n",
    "        show             = show,\n",
    "        write            = write\n",
    "    )\n",
    "\n",
    "    # By eye\n",
    "    # figure1 = create_plot(\n",
    "    #     x           = x,\n",
    "    #     runname     = \"1000_by-eye\",\n",
    "    #     plot_type   = \"histogram\",\n",
    "    #     df          = plot_df,\n",
    "    #     color       = \"component\",\n",
    "    #     xaxis_range = [10, 17],\n",
    "    #     # title       = f\"{runname} galaxies: distribution of magnitudes for by-eye successful models\"\n",
    "    #     # title_y     = 0.85\n",
    "    #     show        = show,\n",
    "    #     write       = False\n",
    "    # )\n",
    "\n",
    "    # # All results\n",
    "    # plot_df = full_df[[x1,x2]].rename(columns = {x1 : \"bulge\", x2 : \"disk\"})\n",
    "    # plot_df = pd.melt(plot_df).rename(columns = {\"value\" : x, \"variable\" : \"component\"})\n",
    "\n",
    "    # figure2 = create_plot(\n",
    "    #     x           = x,\n",
    "    #     runname     = \"1000\",\n",
    "    #     plot_type   = \"histogram\",\n",
    "    #     df          = plot_df,\n",
    "    #     color       = \"component\",\n",
    "    #     xaxis_range = [10, 18],\n",
    "    #     # title       = f\"{runname} galaxies: distribution of magnitudes for by-eye successful models\"\n",
    "    #     # title_y     = 0.85\n",
    "    #     show        = show,\n",
    "    #     write       = False\n",
    "    # )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# ALEN HISTOGRAM\n",
    "# ============================================================================================================================================================\n",
    "    _ = create_plot(\n",
    "        x                = \"alen_ratio\",\n",
    "        runname          = basename,\n",
    "        plot_type        = \"histogram\",\n",
    "        df               = df_container.full_df,\n",
    "        output_image_dir = output_image_dir,\n",
    "        xaxis_title      = \"alen ratio\",\n",
    "        multi            = False,\n",
    "        # title       = f\"{runname} galaxies: distribution of alen ratios for all models\"\n",
    "        # title_y     = 0.85\n",
    "        show             = show,\n",
    "        write            = write\n",
    "    )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# ECDF OF BY EYE SCORE\n",
    "# ============================================================================================================================================================\n",
    "    \n",
    "    _ = create_plot(\n",
    "        x                = method,\n",
    "        runname          = f\"{basename}_by-eye\",\n",
    "        plot_type        = \"ecdf\",\n",
    "        df               = df_container.by_eye_success_df,\n",
    "        output_image_dir = output_image_dir,\n",
    "        xaxis_title      = \"KStest+NMR\",\n",
    "        add_hline        = False,\n",
    "        # title       = f\"1000 galaxies: ECDF for KStest+NMR on by-eye successful model fits\",\n",
    "        # title_y     = 0.92\n",
    "        show             = show,\n",
    "        write            = write\n",
    "    )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# SCATTER OF PITCH ANGLE DIFFERENCES\n",
    "# ============================================================================================================================================================\n",
    "    \n",
    "    x     = \"observation\"\n",
    "    y     = \"model\"\n",
    "    color = \"difference\"\n",
    "\n",
    "    pre_pa  = df_container.full_df[[\"pre_pa1\" , \"pre_pa2\"]].mean(axis = 1)\n",
    "    post_pa = df_container.full_df[[\"post_pa1\", \"post_pa2\"]].mean(axis = 1)\n",
    "    plot_df = pd.concat([pre_pa, post_pa], axis = 1).rename(columns = {0 : x, 1 : y})\n",
    "    plot_df[color] = abs(plot_df[x] - plot_df[y])\n",
    "\n",
    "    _ = create_plot(\n",
    "        x                = x,\n",
    "        y                = y,\n",
    "        runname          = f\"{basename}_pa_diff\",\n",
    "        plot_type        = \"scatter\",\n",
    "        df               = plot_df,\n",
    "        output_image_dir = output_image_dir,\n",
    "        color            = color,\n",
    "        # title     = \"Pitch angle difference reported by SpArcFiRe, model vs observation\"\n",
    "        # title_y   = 0.85\n",
    "        show             = show,\n",
    "        write            = write\n",
    "    )\n",
    "    \n",
    "# ============================================================================================================================================================\n",
    "# SCATTER OF PITCH ANGLE DIFFERENCES\n",
    "# ============================================================================================================================================================\n",
    "\n",
    "    _ = create_plot(\n",
    "        x                = \"pa_diff_galaxy\",\n",
    "        runname          = basename,\n",
    "        plot_type        = \"ecdf\",\n",
    "        df               = df_container.full_df,\n",
    "        output_image_dir = output_image_dir,\n",
    "        xaxis_title      = \"Pitch Angle Difference (deg)\",\n",
    "        cutoff_val       = kwargs.get(\"pa_cutoff_val\", 10),\n",
    "        # title       = f\"ECDF of pitch angle difference reported by SpArcFiRe, model vs observation\"\n",
    "        # title_y     = 0.85\n",
    "        show             = show,\n",
    "        write            = write\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7e2fb85a-eab6-4770-83d9-9e2daeaf8b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_path = \"testing_python_control\" #os.getcwd()\n",
    "    \n",
    "    if in_notebook():\n",
    "        run_path = run_path.replace(\"ics-home\", \"portmanm\")\n",
    "\n",
    "    in_dir  = pj(run_path, \"sparcfire-in\")\n",
    "    out_dir = pj(run_path, \"sparcfire-out\")\n",
    "    tmp_dir = pj(run_path, \"sparcfire-tmp\")\n",
    "\n",
    "    paper_image_dir = pj(run_path, \"for_paper_images\")\n",
    "    nmr             = \"norm_masked_residual\"\n",
    "    method          = \"nmr_x_1-p\"\n",
    "    show            = True\n",
    "    \n",
    "    global total_galaxies\n",
    "    total_galaxies = get_total_galaxies(in_dir = in_dir, out_dir = out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bac1ab1d-6aaf-4f02-bd09-740c3150ae52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x = FitsFile(pj(in_dir, \"1237648704595624148.fits\"))\n",
    "# print(x.header[\"PMAG_R\"])\n",
    "# y = OutputFits(pj(out_dir,\"1237648704595624148\", \"1237648704595624148_galfit_out.fits\"))\n",
    "# print(y.feedme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fc9055ae-3b17-4865-bf9e-a4d6552c556c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 galaxy models generated.\n",
      "14 processed by sparcfire\n",
      "14 pass residual cutoff\n",
      "12 pass pitch angle cutoff\n",
      "12 pass arm length ratio cutoff\n",
      "13 pass chiral agreement\n",
      "11 or 78.57% (11/14) succeed by SpArcFiRe metric\n",
      "1/15 models failed reprocessing by SpArcFiRe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # full_df, success_df, not_success_df, by_eye_success_df, by_eye_not_success_df\n",
    "    galaxy_set_14 = main(\n",
    "        in_dir = in_dir, \n",
    "        out_dir = out_dir, \n",
    "        basename = \"petromag_no_bulge_mask\", \n",
    "        method = method,\n",
    "        incl_by_eye = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f53e6ca-7316-4d47-901c-84a78a26cd29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_path = \"run13_for_paper\" #os.getcwd()\n",
    "    \n",
    "    if in_notebook():\n",
    "        run_path = run_path.replace(\"ics-home\", \"portmanm\")\n",
    "\n",
    "    in_dir  = pj(run_path, \"sparcfire-in\")\n",
    "    out_dir = pj(run_path, \"sparcfire-out\")\n",
    "    tmp_dir = pj(run_path, \"sparcfire-tmp\")\n",
    "\n",
    "    paper_image_dir = pj(run_path, \"for_paper_images\")\n",
    "    nmr             = \"norm_masked_residual\"\n",
    "    method          = \"nmr_x_1-p\"\n",
    "    \n",
    "    global total_galaxies\n",
    "    total_galaxies = get_total_galaxies(in_dir = in_dir, out_dir = out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32736e06-08ad-432f-bbe3-b6252134d8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 galaxy models generated.\n",
      "909 models pass score cutoff.\n",
      "932 processed by sparcfire\n",
      "850 pass score cutoff\n",
      "700 pass pitch angle cutoff\n",
      "745 pass arm length ratio cutoff\n",
      "664 pass chiral agreement\n",
      "437 or 46.89% (437/932) succeed by SpArcFiRe+Score\n",
      "68/1000 models failed reprocessing by SpArcFiRe\n",
      "\n",
      "Number of *total* by eye successful galaxies\n",
      "406     => 40.60%\n",
      "Number of by eye successful galaxies that SpArcFiRe *could* process\n",
      "406/406 => 100.00%\n",
      "\n",
      "Number of *total* by eye not successful galaxies\n",
      "594     => 59.40%\n",
      "Number of by eye not successful galaxies that SpArcFiRe *could* process\n",
      "526/594 => 88.55%\n",
      "\n",
      "False positive rate (by eye) -- 148/(148 + 526) = 21.96%\n",
      "False negative rate (by eye) -- 117/(117 + 406) = 22.37%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # full_df, success_df, not_success_df, by_eye_success_df, by_eye_not_success_df\n",
    "    NC2_1000 = main(\n",
    "        in_dir = in_dir, \n",
    "        out_dir = out_dir,\n",
    "        basename = \"1000_NC2\", \n",
    "        method = method, \n",
    "        #flip_chiral_agreement = True)\n",
    "        incl_by_eye = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9821adaf-8f7a-4988-b6c7-be8327665b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 galaxy models generated.\n",
      "896 models pass score cutoff.\n",
      "951 processed by sparcfire\n",
      "860 pass score cutoff\n",
      "732 pass pitch angle cutoff\n",
      "763 pass arm length ratio cutoff\n",
      "685 pass chiral agreement\n",
      "432 or 45.43% (432/951) succeed by SpArcFiRe+Score\n",
      "49/1000 models failed reprocessing by SpArcFiRe\n",
      "\n",
      "Number of *total* by eye successful galaxies\n",
      "422     => 42.20%\n",
      "Number of by eye successful galaxies that SpArcFiRe *could* process\n",
      "422/422 => 100.00%\n",
      "\n",
      "Number of *total* by eye not successful galaxies\n",
      "578     => 57.80%\n",
      "Number of by eye not successful galaxies that SpArcFiRe *could* process\n",
      "529/578 => 91.52%\n",
      "\n",
      "False positive rate (by eye) -- 140/(140 + 529) = 20.93%\n",
      "False negative rate (by eye) -- 130/(130 + 422) = 23.55%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # full_df, success_df, not_success_df, by_eye_success_df, by_eye_not_success_df\n",
    "    NC3_1000 = main(\n",
    "        in_dir = in_dir, \n",
    "        out_dir = out_dir,\n",
    "        basename = \"1000_NC3\", \n",
    "        method = method, \n",
    "        #flip_chiral_agreement = True)\n",
    "        incl_by_eye = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce43500d-07fd-459a-808a-7b08cdc61525",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining 2 attempts...\n",
      "Total success by combining SpArcFiRe + score: 586/1000\n",
      "Total success by best score: 478/1000\n",
      "Total success by SpArcFiRe and best score between the two runs: 688/1000\n",
      "Total success by eye: 569/1000\n",
      "\n",
      "By eye success found by SpArcFiRe+score:  441/569 = 77.50%\n",
      "False positive rate (by eye) -- 145 / (145 + 413) = 25.99%\n",
      "False negative rate (by eye) -- 128 / (128 + 569) = 18.36%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    combined_bool_df = combine_multi_run_results(\n",
    "        method, \n",
    "        NC2_1000, \n",
    "        NC3_1000,\n",
    "        df_names = [\"1000_NC2\", \"1000_NC3\"],\n",
    "        incl_by_eye = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e51930-79df-4336-bffc-94526573770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_df, success_df, not_success_df, by_eye_success_df, by_eye_not_success_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce6fdee-725a-4424-8149-21641b83336b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_all_plots(\n",
    "    NC2_1000, \n",
    "    method, \n",
    "    \"1000_NC2\", \n",
    "    paper_image_dir, \n",
    "    show = False,\n",
    "    xaxis_range_mag_hist = [10, 20],\n",
    "    yaxis_range_mag_hist = [0, 0.15]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe7cde9-d8fc-4f20-b789-232547171246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_all_plots(\n",
    "    NC3_1000, \n",
    "    method,\n",
    "    \"1000_NC3\",\n",
    "    paper_image_dir, \n",
    "    show = True,\n",
    "    xaxis_range_mag_hist = [10, 22],\n",
    "    yaxis_range_mag_hist = [0, 0.3]\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "73425808-b674-42c7-948f-543508a3a54e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Thanks! https://stackoverflow.com/a/72588847\n",
    "figures = [figure1, figure2]\n",
    "\n",
    "fig = make_subplots(rows = 1, cols = len(figures))\n",
    "\n",
    "for i, figure in enumerate(figures):\n",
    "    for trace in range(len(figure[\"data\"])):\n",
    "        fig.add_trace(figure[\"data\"][trace], row = 1, col = i + 1)\n",
    "        \n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fc0b8f1e-2f66-42cc-8cd5-4f6522c5afef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_path = \"29k_galaxies\" #os.getcwd()\n",
    "    \n",
    "    if in_notebook():\n",
    "        run_path = run_path.replace(\"ics-home\", \"portmanm\")\n",
    "\n",
    "    in_dir  = pj(run_path, \"sparcfire-in\")\n",
    "    out_dir = pj(run_path, \"sparcfire-out\")\n",
    "    tmp_dir = pj(run_path, \"sparcfire-tmp\")\n",
    "\n",
    "    paper_image_dir = \"for_paper_images\"\n",
    "    nmr             = \"norm_masked_residual\"\n",
    "    method          = \"nmr_x_1-p\"\n",
    "    \n",
    "    global total_galaxies\n",
    "    total_galaxies = get_total_galaxies(in_dir = in_dir, out_dir = out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fdbbb3aa-2657-4b96-9ab3-ff0e2e2b453e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28912 galaxy models generated.\n",
      "23119 processed by sparcfire\n",
      "19853 pass residual cutoff\n",
      "14957 pass pitch angle cutoff\n",
      "16186 pass arm length ratio cutoff\n",
      "20186 pass chiral agreement\n",
      "9173 or 39.68% (9173/23119) succeed by SpArcFiRe metric\n",
      "5793/28912 models failed reprocessing by SpArcFiRe\n",
      "\n",
      "Number of *total* by eye successful galaxies\n",
      "(on a subset of galaxies)\n",
      "383     => 38.30%\n",
      "Number of by eye successful galaxies that SpArcFiRe *could* process\n",
      "358/383 => 93.47%\n",
      "\n",
      "Number of *total* by eye not successful galaxies\n",
      "617     => 61.70%\n",
      "Number of by eye not successful galaxies that SpArcFiRe *could* process\n",
      "482/617 => 78.12%\n",
      "\n",
      "False positive rate (by eye) -- 132/(132 + 482) = 21.50%\n",
      "False negative rate (by eye) -- 177/(177 + 358) = 33.08%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # full_df, success_df, not_success_df, by_eye_success_df, by_eye_not_success_df\n",
    "    galaxy_set_29k_bulge_n_4 = main(\n",
    "        in_dir = in_dir, \n",
    "        out_dir = out_dir, \n",
    "        basename = \"bulge_n-4\", \n",
    "        method = method, \n",
    "        flip_chiral_agreement = True,\n",
    "        by_eye_subset = 1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf3a2ca-dd19-41a4-ad13-44896cbcbdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take human spirality (ranked) from 29k set in Kelly's file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dc25ab-d3f5-4569-918b-6a552087fd1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # full_df, success_df, not_success_df, by_eye_success_df, by_eye_not_success_df\n",
    "    galaxy_set_29k_NC3 = main(\n",
    "        in_dir = in_dir, \n",
    "        out_dir = out_dir, \n",
    "        basename = \"29k_NC3\", \n",
    "        method = method, \n",
    "        incl_by_eye = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2dbb77bd-d457-4008-968a-4be03f73f44c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('1237667485918560560', 0.0007797300000000003)\n",
      "0 ('1237671262273405158', 0.00109164)\n",
      "0 ('1237668494708506733', 0.0011923599999999997)\n",
      "0 ('1237671931209646271', 0.0012563200000000002)\n",
      "0 ('1237680240907124849', 0.0013035599999999998)\n",
      "0 ('1237678617433342002', 0.0013067999999999999)\n",
      "0 ('1237673704506130531', 0.0013611900000000002)\n",
      "0 ('1237671139873915058', 0.00224)\n",
      "20 ('1237668350285578377', 0.0044)\n",
      "20 ('1237671690689380567', 0.0044)\n",
      "20 ('1237667782849069253', 0.00442225)\n",
      "20 ('1237668350288527631', 0.00442845)\n",
      "20 ('1237668349757489490', 0.0044347499999999995)\n",
      "20 ('1237667783363133535', 0.0044556)\n",
      "20 ('1237667448346050677', 0.00445584)\n",
      "20 ('1237668625164140743', 0.0044621800000000005)\n",
      "40 ('1237671124294631633', 0.0047922)\n",
      "40 ('1237671124841529554', 0.0048)\n",
      "40 ('1237668495245508656', 0.00480396)\n",
      "40 ('1237679338960453694', 0.00482735)\n",
      "40 ('1237668331489591443', 0.00484398)\n",
      "40 ('1237668271904588024', 0.004856500000000001)\n",
      "40 ('1237671261737582774', 0.00488922)\n",
      "40 ('1237667549809672337', 0.0048975500000000005)\n",
      "60 ('1237668311624646961', 0.0051)\n",
      "60 ('1237667430632521980', 0.0051)\n",
      "60 ('1237667430096175277', 0.0051)\n",
      "60 ('1237671140406526255', 0.0051)\n",
      "60 ('1237667735056613594', 0.0051251199999999995)\n",
      "60 ('1237667782297321581', 0.00515736)\n",
      "60 ('1237667783387775140', 0.0051792)\n",
      "60 ('1237668496330260549', 0.00518856)\n",
      "80 ('1237667536403038497', 0.0056)\n",
      "80 ('1237673807579382444', 0.0056)\n",
      "80 ('1237671140946870394', 0.0056)\n",
      "80 ('1237668586507796629', 0.00564414)\n",
      "80 ('1237668297680879849', 0.00566138)\n",
      "80 ('1237674478124335260', 0.00569373)\n",
      "80 ('1237667731272892652', 0.0057)\n",
      "80 ('1237667538010046586', 0.0057)\n"
     ]
    }
   ],
   "source": [
    "#success_dir = pj(out_dir, 'galfit_png')\n",
    "success_dir = pj(out_dir, f'{basename}_galfit_png')\n",
    "quantile = [\"0\", \"20\", \"40\", \"60\", \"80\"]\n",
    "for q in quantile:\n",
    "    temp_str = \"{images/1000_galaxies/quantile_\"\n",
    "    initial_str = f\"\\includegraphics[height=0.19\\\\textheight]{temp_str}{q}/\"\n",
    "    end_str = \"} &\"\n",
    "    for count, i in enumerate(by_eye_success_df[method][by_eye_success_df[method] >= by_eye_success_df[method].quantile(0.01*float(q), interpolation='lower')].items()):\n",
    "        #if count < 5:\n",
    "        #    continue\n",
    "        if count == 8:\n",
    "            break\n",
    "        \n",
    "        if count == 7:\n",
    "            end_str = \"} \\\\\\\\\"\n",
    "            \n",
    "        gname = i[0]\n",
    "        #print(q, i)\n",
    "        print(f\"{initial_str}{gname + '_combined.png'}{end_str}\")\n",
    "        #sp(f\"cp {pj(success_dir, gname + '_combined.png')} {pj(success_dir, 'all_quantile', 'quantile_' + q)}\")\n",
    "        #sp(f\"cp {pj(out_dir, 'by_eye_success', gname + '_combined.png')} {pj(success_dir, 'all_quantile', 'quantile_' + q)}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0757c853-c5cf-4b4f-b71d-5fe552c60439",
   "metadata": {
    "tags": []
   },
   "source": [
    "success_dir = pj(out_dir, \"galfit_success\")\n",
    "if not exists(success_dir):\n",
    "    os.mkdir(success_dir)\n",
    "    \n",
    "png_dir = pj(out_dir, \"galfit_png\")\n",
    "suffix = \"_combined.png\"\n",
    "for gname, row in success_df.iterrows():\n",
    "    shutil.copy2(pj(png_dir, f\"{gname}{suffix}\"), success_dir)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55a60547-781f-428e-b16b-9beddd678acb",
   "metadata": {},
   "source": [
    "not_success_dir = pj(out_dir, \"galfit_not_success\")\n",
    "if not exists(not_success_dir):\n",
    "    os.mkdir(not_success_dir)\n",
    "    \n",
    "png_dir = pj(out_dir, \"galfit_png\")\n",
    "suffix = \"combined.png\"\n",
    "for gname, row in not_success_df.iterrows():\n",
    "    shutil.copy2(pj(png_dir, f\"{gname}_{suffix}\"), not_success_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98498552-b0d1-4461-b28a-6412e2cc2213",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_images_old(input_df, png_dir:str, variable_name:str, custom_range = None):\n",
    "    images_out = []\n",
    "    \n",
    "    if not custom_range:\n",
    "        custom_range = range(0, len(input_df), 50) \n",
    "        \n",
    "    count = 0\n",
    "    for index_num in custom_range:\n",
    "        g_variable = input_df.iloc[index_num]\n",
    "        gname = g_variable.name\n",
    "        variable_value = g_variable[variable_name]#.norm_masked_residual\n",
    "\n",
    "        height = 500\n",
    "        width = 500\n",
    "        size = (height, width)\n",
    "        #out_str = galaxy_info.name.replace(\"galfit_out.fits\", \"combined.png\").strip()\n",
    "        out_str = f\"{gname}_combined.png\"\n",
    "        #print(out_str)\n",
    "        \n",
    "        \n",
    "        images_out.append(Image(filename = pj(png_dir, out_str), width=width, height=height))\n",
    "            \n",
    "        print(f\"{gname}, sorted #: {index_num}\")\n",
    "        print(f\"{variable_name} = {variable_value:.6f}\")\n",
    "        #print(f\"Dim: {galaxy_info['image_size']}x{galaxy_info['image_size']}\")\n",
    "        print()\n",
    "        \n",
    "    return images_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb0dadf-10a4-4c06-bfac-5c5ca8168990",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_to_disp = generate_images_old(full_df, pj(out_dir, \"galfit_png\"), \"diff\") #, range(0,len(full_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c716159c-c1f4-4aa2-89e5-8a99a118d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(*images_to_disp)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70746b6a-4331-43af-9972-17511a378117",
   "metadata": {
    "tags": []
   },
   "source": [
    "for png in glob.glob(pj(out_dir, \"scatter_plots\", \"*.png\")):\n",
    "    gname = os.path.basename(png).rstrip(\".png\")\n",
    "    if gname not in success_df.index and gname in constrained_df.index:\n",
    "        print(constrained_df.loc[gname, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd73b55-2bc5-46a9-9d47-16f472f03d31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_images(input_df, png_dir:str, cutoff_val = 0.01, variable_name = \"norm_masked_residual\", custom_range = None):\n",
    "    images_below_cutoff = []\n",
    "    images_above_cutoff = []\n",
    "    \n",
    "    if not custom_range:\n",
    "        custom_range = range(0, len(input_df), 50) \n",
    "    count = 0\n",
    "    for index_num in custom_range:\n",
    "        g_variable = input_df.iloc[index_num]\n",
    "        gname = g_variable.name\n",
    "        variable_value = g_variable[variable_name]#.norm_masked_residual\n",
    "\n",
    "        # iloc returns a series, name returns the name of the row\n",
    "\n",
    "        \n",
    "        # print(f\"chi^2/nu = {galaxy_info['chi^2_nu']:.2f}\")\n",
    "        # print(f\"chi^2 = {galaxy_info['chi^2']:.2f}\")\n",
    "        #print(f\"Norm GALFIT residual = {norm_galfit_residual:.4f}\")\n",
    "\n",
    "\n",
    "        # galfit_cmap = grayscale_cmap('RdBu')\n",
    "        # residual_plot = plt.imshow(np.flipud(masked_residual[:,:])) #, norm=colors.LogNorm())\n",
    "        # residual_plot.set_cmap('Greys')\n",
    "        # residual_plot.set_cmap(galfit_cmap)\n",
    "        # cbar = plt.colorbar()\n",
    "\n",
    "        #plt.imshow(residual_plot)\n",
    "        #imgplot = plt.imshow(arr[:, :, 0])\n",
    "        height = 500\n",
    "        width = 500\n",
    "        size = (height, width)\n",
    "        #out_str = galaxy_info.name.replace(\"galfit_out.fits\", \"combined.png\").strip()\n",
    "        out_str = f\"{gname}_combined.png\"\n",
    "        #print(out_str)\n",
    "        \n",
    "        if variable_value < cutoff_val:\n",
    "            images_below_cutoff.append(Image(filename = pj(png_dir, out_str), width=width, height=height))\n",
    "            #images_below_cutoff.append(PIL.Image.open(pj(png_dir, out_str)).resize(size))\n",
    "        else:\n",
    "            count += 1\n",
    "            if count == 1:\n",
    "                print(\"=\"*80)\n",
    "            images_above_cutoff.append(Image(filename = pj(png_dir, out_str), width=width, height=height))\n",
    "            #images_above_cutoff.append(PIL.Image.open(pj(png_dir, out_str)).resize(size))\n",
    "\n",
    "            \n",
    "        print(f\"{gname}, sorted #: {index_num}\")\n",
    "        print(f\"{variable_name} = {variable_value:.6f}\")\n",
    "        #print(f\"Dim: {galaxy_info['image_size']}x{galaxy_info['image_size']}\")\n",
    "        print()\n",
    "        \n",
    "    return images_below_cutoff, images_above_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a95101-3702-4178-a85a-9d3115750838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_df = residual_df[residual_df.index.isin(vals_to_check)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eb7601-7697-47b6-b74b-8cc641b40f9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735ae92d-686a-4a90-96c7-e6bcc1e88321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "png_dir = os.path.join(run_path, out_dir, \"galfit_png\")\n",
    "#below, above = generate_images(plot_df, png_dir, cutoff_val = 0.007, variable_name = analysis_var, custom_range = range(600, len(plot_df), 5) )\n",
    "below, above = generate_images(full_df.sort_values(method), png_dir, cutoff_val = 0.007, variable_name = method, custom_range = range(850, len(full_df), 5) )\n",
    "#below, above = generate_images(check_df, png_dir, cutoff_val = cutoff_val, variable_name = analysis_var, custom_range = range(0, len(check_df), 5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8e8fb5-f0a6-4577-a7d4-5c8712d776cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(*below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81275a0e-b0d1-4da4-9005-7aaa26c3e567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(*above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa61e80e-f4c1-4c8c-b07f-f9ed0a1b56e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "png_dir = os.path.join(run_path, out_dir, \"galfit_png\")\n",
    "#below, above = generate_images(residual_df, png_dir, cutoff_val = 0.013342, variable_name = analysis_var, custom_range = range(700, len(residual_df), 10) )\n",
    "below, above = generate_images(residual_df, png_dir, cutoff_val = cutoff_val, variable_name = analysis_var, custom_range = range(800, len(residual_df), 10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c527023c-eec7-473c-b3b3-9f7bc51169b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(*below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10614ab0-ede7-400a-949c-09524e3e196d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(*above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd8d42f-85a3-41f3-bbbc-2c1a7d4446b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "png_dir = os.path.join(run_path, out_dir, \"galfit_png\")\n",
    "below, above = generate_images(fail_df, png_dir, cutoff_val = 1, variable_name = nmr)#, custom_range = range(650, len(residual_df), 30) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d88e511-d149-424d-8a7e-6e8f4fe51dc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(*below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630341ca-75b3-4dc6-91b6-b9929e4f01a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(*above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9901973e-ac6f-4700-aa25-c14eab1075a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_fit = \"1237671262278582530\"\n",
    "bad_fit = \"1237668366388756890\"\n",
    "\n",
    "good_fit_obj = OutputFits(pj(out_dir, good_fit, f\"{good_fit}_galfit_out.fits\"))\n",
    "bad_fit_obj = OutputFits(pj(out_dir, bad_fit, f\"{bad_fit}_galfit_out.fits\"))\n",
    "good_residual = good_fit_obj.residual.data\n",
    "\n",
    "scipy.stats.probplot(good_residual.flatten(), plot = plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ee8420-f01d-407b-a78f-7420e0244a93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bad_residual = bad_fit_obj.residual.data\n",
    "scipy.stats.probplot(bad_residual.flatten(), plot = plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e075be-9f7e-4901-9c7c-a364497be181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to https://jakevdp.github.io/PythonDataScienceHandbook/04.07-customizing-colorbars.html\n",
    "def grayscale_cmap(cmap):\n",
    "    \"\"\"Return a grayscale version of the given colormap\"\"\"\n",
    "    cmap = plt.cm.get_cmap(cmap)\n",
    "    colors = cmap(np.arange(cmap.N))\n",
    "    \n",
    "    # convert RGBA to perceived grayscale luminance\n",
    "    # cf. http://alienryderflex.com/hsp.html\n",
    "    RGB_weight = [0.299, 0.587, 0.114]\n",
    "    luminance = np.sqrt(np.dot(colors[:, :3] ** 2, RGB_weight))\n",
    "    colors[:, :3] = luminance[:, np.newaxis]\n",
    "        \n",
    "    return LinearSegmentedColormap.from_list(cmap.name + \"_gray\", colors, cmap.N)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d6a55c7-7464-492c-a61f-7275c3f53cbc",
   "metadata": {},
   "source": [
    "with open(\"top_500.txt\", \"w\") as f:\n",
    "    for i in range(0,500):\n",
    "        galaxy_info = norms_df.iloc[i]\n",
    "        galaxy_out_name = galaxy_info.name.replace(\"out.fits\", \"combined.png\")\n",
    "        f.write(galaxy_out_name)\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "with open(\"bot_500.txt\", \"w\") as f:\n",
    "    for i in range(500,len(norms_df)):\n",
    "        galaxy_info = norms_df.iloc[i]\n",
    "        galaxy_out_name = galaxy_info.name.replace(\"out.fits\", \"combined.png\")\n",
    "        f.write(galaxy_out_name)\n",
    "        f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
